#!/usr/bin/env python
"""
ë©€í‹°ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
============================

ì—¬ëŸ¬ Ollama ëª¨ë¸ ë˜ëŠ” Hugging Face ëª¨ë¸ë¡œ QA í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
ê¸°ë³¸ì ìœ¼ë¡œ í˜„ì¬ ì„¤ì¹˜ëœ ëª¨ë“  Ollama ëª¨ë¸ì„ ìë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ì„¤ì¹˜ëœ ëª¨ë“  Ollama ëª¨ë¸ ë¹„êµ (ê¸°ë³¸)
    python compare_models.py
    
    # íŠ¹ì • ëª¨ë¸ë§Œ ë¹„êµ (Ollama)
    python compare_models.py --models qwen2.5:7b llama3.1:8b

    # Hugging Face ëª¨ë¸ ë¹„êµ (ìë™ ê°ì§€)
    python compare_models.py --models snuh/hari-q2.5
    
    # ë‹¤ë¥¸ QA ë°ì´í„°ì…‹ ì‚¬ìš©
    python compare_models.py -i testdata/vitaldb_mid_qa_pairs.json

ê²°ê³¼ë¬¼:
    testdata/model_comparison/
    â”œâ”€â”€ comparison_summary_YYYYMMDD_HHMMSS.xlsx  # ì „ì²´ ë¹„êµí‘œ
    â”œâ”€â”€ results_qwen2.5_7b_YYYYMMDD_HHMMSS.xlsx
    â””â”€â”€ ...
"""

import os
import sys
import json
import logging
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Ollama Provider ê°•ì œ ì„¤ì • (ë‹¤ë¥¸ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ)
os.environ["LLM_PROVIDER"] = "ollama"

from shared.llm import (
    enable_llm_logging,
    switch_model,
    get_current_model_name,
    reset_llm_client
)
from test_qa_dataset import (
    load_qa_pairs,
    run_qa_test,
    setup_logging,
    save_results_to_xlsx
)
from OrchestrationAgent.src.orchestrator import Orchestrator


# ============================================================
# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ëª©ë¡
# ============================================================
# ê¸°ë³¸ê°’: None = í˜„ì¬ ì„¤ì¹˜ëœ ëª¨ë“  Ollama ëª¨ë¸ì„ ìë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
# íŠ¹ì • ëª¨ë¸ë§Œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”.
MODELS_TO_TEST = None  # ì„¤ì¹˜ëœ ëª¨ë“  ëª¨ë¸ ìë™ ê°ì§€

# ============================================================
# ì œì™¸í•  ëª¨ë¸ ëª©ë¡ (ì´ë¯¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œëœ ëª¨ë¸)
# ============================================================
MODELS_TO_EXCLUDE = [
    "codestral:22b",
    "qwen2.5-coder:14b",
    "gpt-oss:20b",
    "qwen2.5-coder:7b",
    "deepseek-coder-v2:16b",
    "starcoder2:7b",
]

# # === ì „ì²´ ì¶”ì²œ ëª¨ë¸ ëª©ë¡ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ) ===
# MODELS_TO_TEST = [
#     # === ì½”ë”© íŠ¹í™” ëª¨ë¸ ===
#     "qwen2.5-coder:7b",
#     "qwen2.5-coder:14b",
#     "codestral:22b",
#     "deepseek-coder-v2:16b",
#     "starcoder2:7b",
#     "codellama:7b",
#     
#     # === ë²”ìš© ëª¨ë¸ ===
#     "qwen2.5:7b",
#     "qwen2.5:14b",
#     "qwen2.5:32b",
#     "llama3.1:8b",
#     "mistral:7b",
#     "mixtral:8x7b",
#     "gpt-oss:20b",
# ]


def check_ollama_available() -> bool:
    """Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
    import urllib.request
    import urllib.error
    
    try:
        req = urllib.request.Request("http://localhost:11434/api/tags")
        with urllib.request.urlopen(req, timeout=5) as response:
            return response.status == 200
    except (urllib.error.URLError, urllib.error.HTTPError, TimeoutError):
        return False


def get_installed_models() -> List[str]:
    """ì„¤ì¹˜ëœ Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    import urllib.request
    import urllib.error
    
    try:
        req = urllib.request.Request("http://localhost:11434/api/tags")
        with urllib.request.urlopen(req, timeout=5) as response:
            data = json.loads(response.read().decode())
            return [model["name"] for model in data.get("models", [])]
    except Exception:
        return []


def filter_available_models(models: List[str]) -> List[str]:
    """ì„¤ì¹˜ëœ ëª¨ë¸ë§Œ í•„í„°ë§í•˜ê³ , ì œì™¸ ëª©ë¡ì— ìˆëŠ” ëª¨ë¸ì€ ìŠ¤í‚µ"""
    installed = get_installed_models()
    available = []
    unavailable = []
    excluded = []
    
    for model in models:
        # Hugging Face ëª¨ë¸ (ìŠ¬ë˜ì‹œ í¬í•¨)ì€ ì„¤ì¹˜ í™•ì¸ ì—†ì´ í†µê³¼
        if "/" in model:
            available.append(model)
            continue

        # ì œì™¸ ëª©ë¡ ì²´í¬
        if model in MODELS_TO_EXCLUDE or any(model in ex or ex in model for ex in MODELS_TO_EXCLUDE):
            excluded.append(model)
            continue
        
        # ëª¨ë¸ëª… ë§¤ì¹­ (íƒœê·¸ í¬í•¨/ë¯¸í¬í•¨ ëª¨ë‘ ì²´í¬)
        if model in installed or any(model in m or m in model for m in installed):
            available.append(model)
        else:
            unavailable.append(model)
    
    if excluded:
        print(f"\nâ­ï¸  ì´ë¯¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œëœ ëª¨ë¸ (ìŠ¤í‚µë¨): {len(excluded)}ê°œ")
        for model in excluded:
            print(f"   - {model}")
    
    if unavailable:
        print(f"\nâš ï¸  ì„¤ì¹˜ë˜ì§€ ì•Šì€ Ollama ëª¨ë¸ (ìŠ¤í‚µë¨):")
        for model in unavailable:
            print(f"   - {model}")
        print(f"   ì„¤ì¹˜: ollama pull <ëª¨ë¸ëª…>")
    
    return available


def run_single_model_test(
    model: str,
    qa_pairs: List[Dict[str, Any]],
    output_dir: Path,
    timestamp: str
) -> Optional[Dict[str, Any]]:
    """
    ë‹¨ì¼ ëª¨ë¸ë¡œ QA í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    Returns:
        ì„±ê³µ ì‹œ ìš”ì•½ ì •ë³´ dict, ì‹¤íŒ¨ ì‹œ None
    """
    print(f"\n{'='*60}")
    print(f"ğŸ”„ ëª¨ë¸ í…ŒìŠ¤íŠ¸: {model}")
    print(f"{'='*60}")
    
    try:
        # 1. ëª¨ë¸ ë³€ê²½ (ìë™ ê°ì§€: / í¬í•¨ ì‹œ HF, ì•„ë‹ˆë©´ Ollama)
        switch_model(model)
        current = get_current_model_name()
        print(f"   í˜„ì¬ ëª¨ë¸: {current}")
        
        # 2. Orchestrator ìƒì„± (ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ìºì‹œ ì´ˆê¸°í™”)
        orchestrator = Orchestrator()
        
        # 3. QA í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = run_qa_test(qa_pairs, orchestrator, verbose=True)
        
        # 4. ê°œë³„ ê²°ê³¼ ì €ì¥
        model_safe_name = model.replace(":", "_").replace("/", "_")
        result_file = output_dir / f"results_{model_safe_name}_{timestamp}.xlsx"
        save_results_to_xlsx(results, str(result_file))
        
        # 5. ìš”ì•½ ê³„ì‚°
        total = len(results)
        correct = sum(1 for r in results if r["ì ìˆ˜"] == 1)
        accuracy = (correct / total * 100) if total > 0 else 0
        failures = sum(1 for r in results if r["ì—ëŸ¬ë©”ì‹œì§€"])
        
        summary = {
            "ëª¨ë¸": model,
            "ì •í™•ë„(%)": round(accuracy, 2),
            "ì •ë‹µìˆ˜": correct,
            "ì´ë¬¸í•­": total,
            "ì‹¤íŒ¨ìˆ˜": failures,
            "ê²°ê³¼íŒŒì¼": result_file.name
        }
        
        print(f"\nâœ… {model}: ì •í™•ë„ {accuracy:.1f}% ({correct}/{total})")
        
        return summary
        
    except Exception as e:
        print(f"\nâŒ {model} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "ëª¨ë¸": model,
            "ì •í™•ë„(%)": "ERROR",
            "ì •ë‹µìˆ˜": 0,
            "ì´ë¬¸í•­": len(qa_pairs),
            "ì‹¤íŒ¨ìˆ˜": len(qa_pairs),
            "ê²°ê³¼íŒŒì¼": f"ERROR: {str(e)[:50]}"
        }


def run_model_comparison(
    qa_path: str,
    models: List[str],
    output_dir: str
) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ ëª¨ë¸ë¡œ QA í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ë¹„êµ
    
    Args:
        qa_path: QA ë°ì´í„°ì…‹ ê²½ë¡œ
        models: í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ëª©ë¡
        output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    
    Returns:
        ë¹„êµ ê²°ê³¼ dict
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # QA ë°ì´í„° ë¡œë“œ
    qa_pairs = load_qa_pairs(qa_path)
    print(f"\nğŸ“š {len(qa_pairs)}ê°œì˜ QA ìŒ ë¡œë“œ ì™„ë£Œ")
    
    # ì„¤ì¹˜ëœ ëª¨ë¸ë§Œ í•„í„°ë§
    available_models = filter_available_models(models)
    
    if not available_models:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ollama pull <ëª¨ë¸ëª…> ìœ¼ë¡œ ëª¨ë¸ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        return {"error": "No available models"}
    
    print(f"\nğŸ¤– í…ŒìŠ¤íŠ¸í•  ëª¨ë¸: {len(available_models)}ê°œ")
    for i, model in enumerate(available_models, 1):
        print(f"   {i}. {model}")
    
    # ëª¨ë¸ë³„ ê²°ê³¼ ìˆ˜ì§‘
    summary_rows = []
    
    for idx, model in enumerate(available_models, 1):
        print(f"\n[{idx}/{len(available_models)}] ", end="")
        
        summary = run_single_model_test(
            model=model,
            qa_pairs=qa_pairs,
            output_dir=output_path,
            timestamp=timestamp
        )
        
        if summary:
            summary_rows.append(summary)
    
    # ë¹„êµ ìš”ì•½ ì €ì¥
    if summary_rows:
        summary_df = pd.DataFrame(summary_rows)
        
        # ì •í™•ë„ ê¸°ì¤€ ì •ë ¬ (ERRORëŠ” ë§¨ ë’¤ë¡œ)
        def sort_key(x):
            if isinstance(x, (int, float)):
                return (0, -x)  # ìˆ«ìëŠ” ë‚´ë¦¼ì°¨ìˆœ
            return (1, 0)  # ERRORëŠ” ë§¨ ë’¤
        
        summary_df["_sort"] = summary_df["ì •í™•ë„(%)"].apply(sort_key)
        summary_df = summary_df.sort_values("_sort").drop(columns=["_sort"])
        
        summary_file = output_path / f"comparison_summary_{timestamp}.xlsx"
        summary_df.to_excel(summary_file, index=False)
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print_comparison_summary(summary_df)
        
        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print(f"ğŸ“Š ë¹„êµ ìš”ì•½: {summary_file.name}")
        
        return {
            "summary": summary_df,
            "summary_file": str(summary_file),
            "output_dir": str(output_path)
        }
    
    return {"error": "No results"}


def print_comparison_summary(summary_df: pd.DataFrame):
    """ë¹„êµ ê²°ê³¼ ì½˜ì†” ì¶œë ¥"""
    print("\n" + "=" * 70)
    print("ğŸ“Š ëª¨ë¸ ë¹„êµ ê²°ê³¼ (ì •í™•ë„ ìˆœ)")
    print("=" * 70)
    print(f"{'ëª¨ë¸':<28} | {'ì •í™•ë„':>10} | {'ì •ë‹µ':>6} | {'ì‹¤íŒ¨':>6}")
    print("-" * 70)
    
    for _, row in summary_df.iterrows():
        acc = row['ì •í™•ë„(%)']
        acc_str = f"{acc:.1f}%" if isinstance(acc, (int, float)) else str(acc)
        correct_str = f"{row['ì •ë‹µìˆ˜']}/{row['ì´ë¬¸í•­']}"
        
        print(f"{row['ëª¨ë¸']:<28} | {acc_str:>10} | {correct_str:>6} | {row['ì‹¤íŒ¨ìˆ˜']:>6}")
    
    print("=" * 70)
    
    # ë² ìŠ¤íŠ¸ ëª¨ë¸ í‘œì‹œ
    valid_rows = summary_df[summary_df['ì •í™•ë„(%)'].apply(lambda x: isinstance(x, (int, float)))]
    if not valid_rows.empty:
        best = valid_rows.iloc[0]
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best['ëª¨ë¸']} (ì •í™•ë„ {best['ì •í™•ë„(%)']}%)")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ë©€í‹°ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python compare_models.py                           # ì„¤ì¹˜ëœ ëª¨ë“  Ollama ëª¨ë¸ ë¹„êµ (ê¸°ë³¸)
  python compare_models.py --models qwen2.5:7b       # íŠ¹ì • ëª¨ë¸ë§Œ
  python compare_models.py --models snuh/hari-q2.5   # Hugging Face ëª¨ë¸
  python compare_models.py -i testdata/vitaldb_mid_qa_pairs.json  # ë‹¤ë¥¸ ë°ì´í„°ì…‹
        """
    )
    parser.add_argument(
        "--input", "-i",
        default="testdata/vitaldb_low_qa_pairs.json",
        help="QA ë°ì´í„°ì…‹ ê²½ë¡œ (default: testdata/vitaldb_low_qa_pairs.json)"
    )
    parser.add_argument(
        "--output-dir", "-o",
        default="testdata/model_comparison",
        help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (default: testdata/model_comparison)"
    )
    parser.add_argument(
        "--models", "-m",
        nargs="+",
        default=None,
        help="í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ëª©ë¡ (ë¯¸ì§€ì •ì‹œ ì„¤ì¹˜ëœ ëª¨ë“  ëª¨ë¸ ìë™ ê°ì§€)"
    )
    parser.add_argument(
        "--log-level", "-l",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="WARNING",
        help="ë¡œê·¸ ë ˆë²¨ (default: WARNING)"
    )
    parser.add_argument(
        "--no-llm-log",
        action="store_true",
        help="LLM í˜¸ì¶œ ë¡œê¹… ë¹„í™œì„±í™”"
    )
    parser.add_argument(
        "--ignore-ollama-check",
        action="store_true",
        help="Ollama ì„œë²„ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ ê±´ë„ˆë›°ê¸° (HF ëª¨ë¸ë§Œ í…ŒìŠ¤íŠ¸í•  ë•Œ ìœ ìš©)"
    )
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(args.log_level)
    
    # Ollama ì„œë²„ í™•ì¸ (HF ëª¨ë¸ë§Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²½ìš° ë¬´ì‹œ ê°€ëŠ¥)
    # ëª¨ë¸ ëª©ë¡ì— HF ëª¨ë¸('/')ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ Ollama ì²´í¬ë¥¼ ê°•ì œí•˜ì§€ ì•ŠìŒ
    has_hf_model = args.models and any("/" in m for m in args.models)
    
    if not args.ignore_ollama_check and not has_hf_model:
        if not check_ollama_available():
            print("âŒ Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print("   ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ 'ollama serve' ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            print("   (Hugging Face ëª¨ë¸ë§Œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ --ignore-ollama-check ì˜µì…˜ ì‚¬ìš©)")
            sys.exit(1)
    
    # LLM ë¡œê¹… ì„¤ì •
    if not args.no_llm_log:
        log_session_dir = enable_llm_logging("./data/llm_logs")
        logging.info(f"ğŸ“ LLM Logs: {log_session_dir}")
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    input_path = Path(project_root) / args.input
    if not input_path.exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
        sys.exit(1)
    
    # ëª¨ë¸ ëª©ë¡ ê²°ì •
    if args.models:
        # CLIì—ì„œ ì§€ì •í•œ ëª¨ë¸
        models = args.models
        model_source = "CLI ì§€ì •"
    elif MODELS_TO_TEST:
        # ì½”ë“œì—ì„œ ì§€ì •í•œ ëª¨ë¸
        models = MODELS_TO_TEST
        model_source = "ì‚¬ì „ ì •ì˜"
    else:
        # ì„¤ì¹˜ëœ ëª¨ë“  ëª¨ë¸ ìë™ ê°ì§€
        models = get_installed_models()
        model_source = "ìë™ ê°ì§€ (ì„¤ì¹˜ëœ ëª¨ë¸)"
        if not models:
            print("âŒ ì„¤ì¹˜ëœ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("   ollama pull <ëª¨ë¸ëª…> ìœ¼ë¡œ ëª¨ë¸ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
    
    # ì œì™¸ ëª©ë¡ ì ìš©
    # HF ëª¨ë¸ì€ ì œì™¸ ëª©ë¡ ë¡œì§ì„ íƒ€ì§€ ì•Šë„ë¡ ì£¼ì˜
    original_count = len(models)
    
    # HF ëª¨ë¸ì€ ì œì™¸ ë¡œì§ì—ì„œ ë³´í˜¸
    models = [
        m for m in models 
        if "/" in m or (m not in MODELS_TO_EXCLUDE and not any(m in ex or ex in m for ex in MODELS_TO_EXCLUDE))
    ]
    excluded_count = original_count - len(models)
    
    if excluded_count > 0:
        print(f"\nâ­ï¸  ì´ë¯¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œëœ ëª¨ë¸ ì œì™¸: {excluded_count}ê°œ")
        for ex in MODELS_TO_EXCLUDE:
            print(f"   - {ex}")
    
    if not models:
        print("âŒ í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  ëª¨ë¸ì´ ì œì™¸ë¨)")
        print("   MODELS_TO_EXCLUDE ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        sys.exit(1)
    
    print("=" * 60)
    print("ğŸ§ª ë©€í‹°ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"ğŸ“š QA ë°ì´í„°: {args.input}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output_dir}")
    print(f"ğŸ¤– ëª¨ë¸ ì„ íƒ: {model_source}")
    print(f"ğŸ¤– ëŒ€ìƒ ëª¨ë¸ ìˆ˜: {len(models)}ê°œ (ì œì™¸: {excluded_count}ê°œ)")
    print("=" * 60)
    
    # ë¹„êµ ì‹¤í–‰
    run_model_comparison(
        qa_path=str(input_path),
        models=models,
        output_dir=args.output_dir
    )
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
