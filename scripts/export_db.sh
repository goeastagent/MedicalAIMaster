#!/bin/bash
# export_db.sh
# IndexingAgent Í≤∞Í≥ºÎ¨º Export Ïä§ÌÅ¨Î¶ΩÌä∏
# PostgreSQL + Neo4j Îç∞Ïù¥ÌÑ∞Î•º dump ÌååÏùºÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞
#
# ÏÇ¨Ïö©Î≤ï: ./scripts/export_db.sh [output_dir]
# ÏòàÏãú:   ./scripts/export_db.sh ./db_dumps

set -e

# ===========================================
# Configuration (ÌôòÍ≤ΩÎ≥ÄÏàò ÎòêÎäî Í∏∞Î≥∏Í∞í)
# ===========================================
POSTGRES_HOST=${POSTGRES_HOST:-localhost}
POSTGRES_PORT=${POSTGRES_PORT:-5432}
POSTGRES_USER=${POSTGRES_USER:-postgres}
POSTGRES_DB=${POSTGRES_DB:-medical_data}

NEO4J_URI=${NEO4J_URI:-bolt://localhost:7687}
NEO4J_USER=${NEO4J_USER:-neo4j}
NEO4J_PASSWORD=${NEO4J_PASSWORD:-password}
NEO4J_DATABASE=${NEO4J_DATABASE:-neo4j}

# Output directory
OUTPUT_DIR=${1:-./db_export}
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
EXPORT_NAME="indexing_agent_export_${TIMESTAMP}"

echo "=========================================="
echo "üì¶ IndexingAgent Database Export"
echo "=========================================="
echo ""
echo "üìÖ Timestamp: $TIMESTAMP"
echo "üìÅ Output: $OUTPUT_DIR/$EXPORT_NAME"
echo ""

# Create output directory
mkdir -p "$OUTPUT_DIR/$EXPORT_NAME"

# ===========================================
# 1. PostgreSQL Export
# ===========================================
echo "1Ô∏è‚É£  Exporting PostgreSQL..."

PG_DUMP_FILE="$OUTPUT_DIR/$EXPORT_NAME/postgres_dump.sql"
PG_SCHEMA_FILE="$OUTPUT_DIR/$EXPORT_NAME/postgres_schema.sql"

# Check if PostgreSQL is accessible
if ! pg_isready -h $POSTGRES_HOST -p $POSTGRES_PORT > /dev/null 2>&1; then
    echo "‚ùå PostgreSQL is not running at $POSTGRES_HOST:$POSTGRES_PORT"
    echo "   Please start PostgreSQL first: ./IndexingAgent/run_postgres_neo4j.sh"
    exit 1
fi

# Check if database exists
if ! psql -h $POSTGRES_HOST -p $POSTGRES_PORT -U $POSTGRES_USER -lqt | cut -d \| -f 1 | grep -qw $POSTGRES_DB; then
    echo "‚ùå Database '$POSTGRES_DB' does not exist"
    exit 1
fi

# Export schema only
echo "   - Exporting schema..."
pg_dump -h $POSTGRES_HOST -p $POSTGRES_PORT -U $POSTGRES_USER \
    -d $POSTGRES_DB \
    --schema-only \
    --no-owner \
    --no-privileges \
    -f "$PG_SCHEMA_FILE"

# Export full dump (schema + data)
echo "   - Exporting data..."
pg_dump -h $POSTGRES_HOST -p $POSTGRES_PORT -U $POSTGRES_USER \
    -d $POSTGRES_DB \
    --no-owner \
    --no-privileges \
    -f "$PG_DUMP_FILE"

PG_SIZE=$(du -h "$PG_DUMP_FILE" | cut -f1)
echo "‚úÖ PostgreSQL exported: $PG_DUMP_FILE ($PG_SIZE)"

# ===========================================
# 2. Neo4j Export (using cypher-shell)
# ===========================================
echo ""
echo "2Ô∏è‚É£  Exporting Neo4j..."

NEO4J_DUMP_FILE="$OUTPUT_DIR/$EXPORT_NAME/neo4j_dump.cypher"

# Check if Neo4j is accessible
if ! nc -z localhost 7687 2>/dev/null; then
    echo "‚ö†Ô∏è  Neo4j is not running at port 7687"
    echo "   Skipping Neo4j export..."
    echo "   (If Neo4j is not used, this is expected)"
    touch "$NEO4J_DUMP_FILE"
    echo "// Neo4j was not running during export" > "$NEO4J_DUMP_FILE"
else
    # Check if cypher-shell is available
    if ! command -v cypher-shell &> /dev/null; then
        echo "‚ö†Ô∏è  cypher-shell not found. Trying alternative export..."
        
        # Alternative: Use Python with neo4j driver
        python3 << EOF
import sys
try:
    from neo4j import GraphDatabase
    
    driver = GraphDatabase.driver("$NEO4J_URI", auth=("$NEO4J_USER", "$NEO4J_PASSWORD"))
    
    with driver.session(database="$NEO4J_DATABASE") as session:
        # Export all nodes
        nodes = session.run("MATCH (n) RETURN n, labels(n) as labels, properties(n) as props").data()
        
        # Export all relationships
        rels = session.run("MATCH (a)-[r]->(b) RETURN type(r) as type, properties(r) as props, id(a) as start_id, id(b) as end_id, labels(a) as start_labels, labels(b) as end_labels, properties(a) as start_props, properties(b) as end_props").data()
        
        with open("$NEO4J_DUMP_FILE", "w") as f:
            f.write("// Neo4j Export - Generated by export_db.sh\\n")
            f.write("// Timestamp: $TIMESTAMP\\n\\n")
            
            # Create constraints and indexes first
            f.write("// === Constraints ===\\n")
            constraints = session.run("SHOW CONSTRAINTS").data()
            for c in constraints:
                if 'createStatement' in c:
                    f.write(f"{c['createStatement']};\\n")
            
            f.write("\\n// === Nodes ===\\n")
            for node in nodes:
                labels_str = ':'.join(node['labels'])
                props_str = str(node['props']).replace("'", '"')
                f.write(f"CREATE (:{labels_str} {props_str});\\n")
            
            f.write("\\n// === Relationships ===\\n")
            f.write("// Note: Relationships require MATCH on node properties\\n")
            for rel in rels:
                start_label = rel['start_labels'][0] if rel['start_labels'] else 'Node'
                end_label = rel['end_labels'][0] if rel['end_labels'] else 'Node'
                
                # Find unique identifier for start node
                start_key = list(rel['start_props'].keys())[0] if rel['start_props'] else 'id'
                start_val = list(rel['start_props'].values())[0] if rel['start_props'] else rel['start_id']
                
                # Find unique identifier for end node
                end_key = list(rel['end_props'].keys())[0] if rel['end_props'] else 'id'
                end_val = list(rel['end_props'].values())[0] if rel['end_props'] else rel['end_id']
                
                props_str = str(rel['props']).replace("'", '"') if rel['props'] else '{}'
                
                # Quote string values
                if isinstance(start_val, str):
                    start_val = f'"{start_val}"'
                if isinstance(end_val, str):
                    end_val = f'"{end_val}"'
                
                f.write(f"MATCH (a:{start_label} {{{start_key}: {start_val}}}), (b:{end_label} {{{end_key}: {end_val}}}) CREATE (a)-[:{rel['type']} {props_str}]->(b);\\n")
        
        driver.close()
        print("‚úÖ Neo4j exported using Python driver")
        
except ImportError:
    print("‚ö†Ô∏è  neo4j Python package not installed")
    print("   Run: pip install neo4j")
    with open("$NEO4J_DUMP_FILE", "w") as f:
        f.write("// Neo4j export failed - neo4j package not installed\\n")
except Exception as e:
    print(f"‚ö†Ô∏è  Neo4j export failed: {e}")
    with open("$NEO4J_DUMP_FILE", "w") as f:
        f.write(f"// Neo4j export failed: {e}\\n")
EOF
    else
        # Use cypher-shell with APOC export if available
        echo "   - Using cypher-shell..."
        
        # Try APOC export first (requires APOC plugin)
        cypher-shell -u "$NEO4J_USER" -p "$NEO4J_PASSWORD" -d "$NEO4J_DATABASE" \
            "CALL apoc.export.cypher.all(null, {format: 'cypher-shell', useOptimizations: {type: 'NONE'}}) YIELD cypherStatements RETURN cypherStatements" \
            2>/dev/null > "$NEO4J_DUMP_FILE" || {
            
            echo "   - APOC not available, using manual export..."
            
            # Manual export using basic Cypher
            cypher-shell -u "$NEO4J_USER" -p "$NEO4J_PASSWORD" -d "$NEO4J_DATABASE" << 'CYPHER' > "$NEO4J_DUMP_FILE"
// Export all nodes and relationships
CALL {
    MATCH (n)
    RETURN "CREATE " + toString(n) + ";" as statement
    UNION ALL
    MATCH (a)-[r]->(b)
    RETURN "MATCH (a), (b) WHERE id(a)=" + toString(id(a)) + " AND id(b)=" + toString(id(b)) + " CREATE (a)-[:" + type(r) + " " + toString(properties(r)) + "]->(b);" as statement
}
RETURN statement
CYPHER
        }
        echo "‚úÖ Neo4j exported using cypher-shell"
    fi
fi

NEO4J_SIZE=$(du -h "$NEO4J_DUMP_FILE" | cut -f1)
echo "‚úÖ Neo4j exported: $NEO4J_DUMP_FILE ($NEO4J_SIZE)"

# ===========================================
# 3. Create metadata file
# ===========================================
echo ""
echo "3Ô∏è‚É£  Creating metadata..."

METADATA_FILE="$OUTPUT_DIR/$EXPORT_NAME/metadata.json"

cat > "$METADATA_FILE" << EOF
{
    "export_timestamp": "$TIMESTAMP",
    "export_tool": "export_db.sh",
    "version": "1.0",
    "source": {
        "postgres": {
            "host": "$POSTGRES_HOST",
            "port": $POSTGRES_PORT,
            "database": "$POSTGRES_DB"
        },
        "neo4j": {
            "uri": "$NEO4J_URI",
            "database": "$NEO4J_DATABASE"
        }
    },
    "files": {
        "postgres_schema": "postgres_schema.sql",
        "postgres_dump": "postgres_dump.sql",
        "neo4j_dump": "neo4j_dump.cypher"
    },
    "tables": [
        "directory_catalog",
        "file_group",
        "file_catalog",
        "column_metadata",
        "parameter",
        "data_dictionary",
        "table_entities",
        "table_relationships",
        "ontology_subcategories",
        "semantic_edges",
        "medical_term_mappings",
        "cross_table_semantics"
    ],
    "neo4j_node_types": [
        "FileGroup",
        "RowEntity",
        "ConceptCategory",
        "Parameter",
        "SubCategory",
        "MedicalTerm"
    ]
}
EOF

echo "‚úÖ Metadata created: $METADATA_FILE"

# ===========================================
# 4. Create archive
# ===========================================
echo ""
echo "4Ô∏è‚É£  Creating archive..."

ARCHIVE_FILE="$OUTPUT_DIR/${EXPORT_NAME}.tar.gz"
cd "$OUTPUT_DIR"
tar -czvf "${EXPORT_NAME}.tar.gz" "$EXPORT_NAME" > /dev/null
cd - > /dev/null

ARCHIVE_SIZE=$(du -h "$ARCHIVE_FILE" | cut -f1)
echo "‚úÖ Archive created: $ARCHIVE_FILE ($ARCHIVE_SIZE)"

# ===========================================
# Summary
# ===========================================
echo ""
echo "=========================================="
echo "‚úÖ Export Complete!"
echo "=========================================="
echo ""
echo "üìÅ Export directory: $OUTPUT_DIR/$EXPORT_NAME/"
echo "   - postgres_schema.sql  (schema only)"
echo "   - postgres_dump.sql    (schema + data)"
echo "   - neo4j_dump.cypher    (graph data)"
echo "   - metadata.json        (export info)"
echo ""
echo "üì¶ Archive: $ARCHIVE_FILE ($ARCHIVE_SIZE)"
echo ""
echo "üöÄ To import on another server:"
echo "   1. Copy $ARCHIVE_FILE to target server"
echo "   2. Run: ./scripts/import_db.sh $ARCHIVE_FILE"
echo ""
