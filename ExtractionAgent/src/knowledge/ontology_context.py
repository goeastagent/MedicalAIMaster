# src/ontology_context.py
"""
ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ ë¹Œë”

IndexingAgentê°€ êµ¬ì¶•í•œ ì˜¨í†¨ë¡œì§€ ì •ë³´ë¥¼ ë¡œë“œí•˜ê³  í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
"""

from typing import Dict, List, Any
from ExtractionAgent.src.database.neo4j import Neo4jConnector


class OntologyContextBuilder:
    """ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ ë¹Œë”"""
    
    def __init__(self):
        self.neo4j_connector = Neo4jConnector()
        self._ontology_cache = None
    
    def load_ontology(self) -> Dict[str, Any]:
        """
        ì˜¨í†¨ë¡œì§€ ë¡œë“œ (ìºì‹± ì§€ì›)
        
        Returns:
            ì˜¨í†¨ë¡œì§€ ë”•ì…”ë„ˆë¦¬
        """
        if self._ontology_cache is not None:
            return self._ontology_cache
        
        ontology = self.neo4j_connector.get_ontology_context()
        self._ontology_cache = ontology
        return ontology
    
    def format_definitions_for_prompt(self, max_definitions: int = 50) -> str:
        """
        ìš©ì–´ ì •ì˜(Definitions)ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…
        
        Args:
            max_definitions: ìµœëŒ€ ì •ì˜ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        
        Returns:
            í¬ë§·íŒ…ëœ ì •ì˜ ë¬¸ìì—´
        """
        ontology = self.load_ontology()
        definitions = ontology.get("definitions", {})
        
        if not definitions:
            return "No definitions available."
        
        lines = []
        lines.append("=" * 80)
        lines.append("ONTOLOGY DEFINITIONS (Medical Terms)")
        lines.append("=" * 80)
        lines.append(f"\nTotal Definitions: {len(definitions)}")
        lines.append("")
        lines.append("These definitions help map natural language terms to database columns:")
        lines.append("")
        
        # ì¼ë¶€ë§Œ í‘œì‹œ (ë„ˆë¬´ ë§ìœ¼ë©´ í† í° ë‚­ë¹„)
        items = list(definitions.items())
        if max_definitions and len(items) > max_definitions:
            items = items[:max_definitions]
            lines.append(f"(Showing first {max_definitions} definitions)")
            lines.append("")
        
        for term, definition in items:
            # ì •ì˜ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
            def_short = definition[:200] + "..." if len(definition) > 200 else definition
            lines.append(f"  - {term}: {def_short}")
        
        if len(definitions) > max_definitions:
            lines.append(f"\n... and {len(definitions) - max_definitions} more definitions")
        
        return "\n".join(lines)
    
    def format_relationships_for_prompt(self) -> str:
        """
        í…Œì´ë¸” ê°„ ê´€ê³„(Relationships)ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…
        
        Returns:
            í¬ë§·íŒ…ëœ ê´€ê³„ ë¬¸ìì—´
        """
        ontology = self.load_ontology()
        relationships = ontology.get("relationships", [])
        
        if not relationships:
            return "No relationships defined."
        
        lines = []
        lines.append("=" * 80)
        lines.append("TABLE RELATIONSHIPS (Foreign Keys)")
        lines.append("=" * 80)
        lines.append(f"\nTotal Relationships: {len(relationships)}")
        lines.append("")
        lines.append("Use these relationships to join tables correctly:")
        lines.append("")
        
        for rel in relationships:
            source_table = rel.get("source_table", "?")
            target_table = rel.get("target_table", "?")
            source_column = rel.get("source_column", "?")
            target_column = rel.get("target_column", "?")
            relation_type = rel.get("relation_type", "?")
            confidence = rel.get("confidence", 0.0)
            
            lines.append(
                f"  - {source_table}.{source_column} â†’ {target_table}.{target_column} "
                f"({relation_type}, confidence: {confidence:.2%})"
            )
        
        return "\n".join(lines)
    
    def format_hierarchy_for_prompt(self) -> str:
        """
        ê³„ì¸µ êµ¬ì¡°(Hierarchy)ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…
        
        Returns:
            í¬ë§·íŒ…ëœ ê³„ì¸µ êµ¬ì¡° ë¬¸ìì—´
        """
        ontology = self.load_ontology()
        hierarchy = ontology.get("hierarchy", [])
        
        if not hierarchy:
            return "No hierarchy defined."
        
        lines = []
        lines.append("=" * 80)
        lines.append("DATA HIERARCHY (Anchor Levels)")
        lines.append("=" * 80)
        lines.append("")
        lines.append("Understanding the data hierarchy helps with JOIN strategies:")
        lines.append("")
        
        # ë ˆë²¨ë³„ë¡œ ì •ë ¬
        sorted_hierarchy = sorted(hierarchy, key=lambda x: x.get("level", 99))
        
        for h in sorted_hierarchy:
            level = h.get("level", "?")
            entity_name = h.get("entity_name", "?")
            anchor_column = h.get("anchor_column", "?")
            confidence = h.get("confidence", 0.0)
            
            lines.append(
                f"  Level {level}: {entity_name} (Anchor: {anchor_column}, confidence: {confidence:.2%})"
            )
        
        return "\n".join(lines)
    
    def format_full_ontology_for_prompt(self, max_definitions: int = 50) -> str:
        """
        ì „ì²´ ì˜¨í†¨ë¡œì§€ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…
        
        Args:
            max_definitions: ìµœëŒ€ ì •ì˜ ìˆ˜
        
        Returns:
            í¬ë§·íŒ…ëœ ì „ì²´ ì˜¨í†¨ë¡œì§€ ë¬¸ìì—´
        """
        parts = [
            self.format_definitions_for_prompt(max_definitions),
            "",
            self.format_relationships_for_prompt(),
            "",
            self.format_hierarchy_for_prompt()
        ]
        
        return "\n".join(parts)
    
    def get_relevant_definitions(self, query: str, top_k: int = 10, use_vector_search: bool = True) -> Dict[str, str]:
        """
        ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ì •ì˜ë§Œ ì¶”ì¶œ (VectorDB ì‹œë§¨í‹± ê²€ìƒ‰ ìš°ì„ )
        
        Args:
            query: ìì—°ì–´ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ì •ì˜ ìˆ˜
            use_vector_search: VectorDB ì‹œë§¨í‹± ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            ê´€ë ¨ ì •ì˜ ë”•ì…”ë„ˆë¦¬ {term: definition}
        """
        # VectorDB ì‹œë§¨í‹± ê²€ìƒ‰ ì‹œë„
        if use_vector_search:
            try:
                from ExtractionAgent.src.knowledge.vector_store import get_vector_store_reader
                vector_store = get_vector_store_reader()
                
                if vector_store.is_available():
                    results = vector_store.search_columns(query, n_results=top_k)
                    
                    if results:
                        relevant = {}
                        for result in results:
                            col_name = result.get("column_name", "")
                            full_name = result.get("full_name", col_name)
                            description = result.get("description", "")
                            unit = result.get("unit", "")
                            typical_range = result.get("typical_range", "")
                            
                            # í’ë¶€í•œ ì •ì˜ ìƒì„±
                            definition = f"{full_name}"
                            if description:
                                definition += f" - {description}"
                            if unit:
                                definition += f" (Unit: {unit})"
                            if typical_range:
                                definition += f" (Normal: {typical_range})"
                            
                            relevant[col_name] = definition
                        
                        print(f"âœ… [Ontology] VectorDB ì‹œë§¨í‹± ê²€ìƒ‰: {len(relevant)}ê°œ ê´€ë ¨ ì •ì˜ ì°¾ìŒ")
                        return relevant
            except Exception as e:
                print(f"âš ï¸ [Ontology] VectorDB ê²€ìƒ‰ ì‹¤íŒ¨, í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´: {e}")
        
        # Fallback: ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤ì¹­
        ontology = self.load_ontology()
        definitions = ontology.get("definitions", {})
        
        if not definitions:
            return {}
        
        query_lower = query.lower()
        relevant = {}
        
        for term, definition in definitions.items():
            # ì¿¼ë¦¬ì— ìš©ì–´ê°€ í¬í•¨ë˜ì–´ ìˆê±°ë‚˜, ì •ì˜ì— ì¿¼ë¦¬ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
            if term.lower() in query_lower or any(
                keyword in definition.lower() 
                for keyword in query_lower.split() 
                if len(keyword) > 3
            ):
                relevant[term] = definition
        
        # ìƒìœ„ kê°œë§Œ ë°˜í™˜
        return dict(list(relevant.items())[:top_k])
    
    def format_column_metadata_for_prompt(self, max_columns_per_table: int = 20) -> str:
        """
        ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…
        
        LLMì´ ì•½ì–´ë¥¼ ì´í•´í•˜ê³  ë‹¨ìœ„/ë²”ìœ„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸ ì •ë³´ ì œê³µ
        
        Args:
            max_columns_per_table: í…Œì´ë¸”ë‹¹ í‘œì‹œí•  ìµœëŒ€ ì»¬ëŸ¼ ìˆ˜
        
        Returns:
            í¬ë§·íŒ…ëœ ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„° ë¬¸ìì—´
        """
        ontology = self.load_ontology()
        column_metadata = ontology.get("column_metadata", {})
        
        if not column_metadata:
            return ""
        
        lines = []
        lines.append("=" * 80)
        lines.append("COLUMN METADATA (Abbreviations, Units, Ranges)")
        lines.append("=" * 80)
        lines.append("")
        lines.append("Use this information to understand column meanings and data formats:")
        lines.append("")
        
        for table_name, columns in column_metadata.items():
            lines.append(f"ğŸ“Š Table: {table_name}")
            
            # ì»¬ëŸ¼ ìˆ˜ ì œí•œ
            col_items = list(columns.items())[:max_columns_per_table]
            
            for col_name, col_info in col_items:
                full_name = col_info.get("full_name") or col_name
                unit = col_info.get("unit")
                typical_range = col_info.get("typical_range")
                description = col_info.get("description", "")
                description_kr = col_info.get("description_kr", "")
                
                # ê¸°ë³¸ ì •ë³´
                line = f"   â€¢ {col_name}"
                
                # ì•½ì–´ í’€ì´ (ë‹¤ë¥¸ ê²½ìš°ë§Œ)
                if full_name and full_name.lower() != col_name.lower():
                    line += f" â†’ {full_name}"
                
                # ë‹¨ìœ„
                if unit:
                    line += f" [{unit}]"
                
                # ì •ìƒ ë²”ìœ„
                if typical_range:
                    line += f" (normal: {typical_range})"
                
                lines.append(line)
                
                # ì„¤ëª… (ìˆìœ¼ë©´)
                if description:
                    desc_short = description[:80] + "..." if len(description) > 80 else description
                    lines.append(f"       {desc_short}")
                
                # í•œê¸€ ì„¤ëª… (ìˆìœ¼ë©´)
                if description_kr:
                    lines.append(f"       (í•œê¸€: {description_kr[:50]})")
            
            # í‘œì‹œë˜ì§€ ì•Šì€ ì»¬ëŸ¼ ìˆ˜
            if len(columns) > max_columns_per_table:
                lines.append(f"   ... and {len(columns) - max_columns_per_table} more columns")
            
            lines.append("")
        
        return "\n".join(lines)
    
    def get_column_info(self, table_name: str, column_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í…Œì´ë¸”ì˜ íŠ¹ì • ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        
        Args:
            table_name: í…Œì´ë¸”ëª…
            column_name: ì»¬ëŸ¼ëª…
        
        Returns:
            ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        ontology = self.load_ontology()
        column_metadata = ontology.get("column_metadata", {})
        
        table_cols = column_metadata.get(table_name, {})
        return table_cols.get(column_name, {})
    
    def clear_cache(self):
        """ì˜¨í†¨ë¡œì§€ ìºì‹œ ì´ˆê¸°í™”"""
        self._ontology_cache = None

