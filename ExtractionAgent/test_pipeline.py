#!/usr/bin/env python3
"""
VitalExtractionAgent - Full Pipeline Test (Debug Mode)
=======================================================

ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ë””ë²„ê¹… ì¶œë ¥ í¬í•¨)

Pipeline:
    [100] QueryUnderstandingNode
        â†“
    [200] ParameterResolverNode
        â†“
    [300] PlanBuilderNode

Usage:
    cd ExtractionAgent
    python test_pipeline.py              # ê¸°ë³¸ ì‹¤í–‰
    python test_pipeline.py --verbose    # ìƒì„¸ ì¶œë ¥
    python test_pipeline.py --json       # JSON ì „ì²´ ì¶œë ¥
"""

import sys
import json
import time
import argparse
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(Path(__file__).parent))


# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜
TEST_QUERIES = [
    {
        "name": "í•œêµ­ì–´ ë³µí•© ì¿¼ë¦¬",
        "query": "ìœ„ì•” í™˜ìì˜ ìˆ˜ìˆ  ì¤‘ ì‹¬ë°•ìˆ˜ì™€ í˜ˆì•• ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì¤˜",
        "expected": {
            "intent": "data_retrieval",
            "min_parameters": 2,
            "temporal_type": "procedure_window"
        }
    },
    {
        "name": "ì˜ì–´ í•„í„° ì¿¼ë¦¬",
        "query": "Extract SpO2 data for patients diagnosed with gastric cancer",
        "expected": {
            "intent": "data_retrieval",
            "min_parameters": 1,
            "temporal_type": "full_record"
        }
    },
    {
        "name": "ì‹œê°„ í•„í„° ì¿¼ë¦¬",
        "query": "2020ë…„ 1ì›”ë¶€í„° 2023ë…„ 12ì›”ê¹Œì§€ ìˆ˜ìˆ ë°›ì€ í™˜ìë“¤ì˜ ì¹˜ë£Œ ì¤‘ ì²´ì˜¨ê³¼ ì‹¬ë°•ìˆ˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì¤˜",
        "expected": {
            "intent": "data_retrieval",
            "min_parameters": 2,  # ì²´ì˜¨, ì‹¬ë°•ìˆ˜
            "temporal_type": "treatment_window"
        }
    }
]


def print_header(text: str, char: str = "=", width: int = 80):
    """í—¤ë” ì¶œë ¥"""
    line = char * width
    print(f"\n{line}")
    print(f"  {text}")
    print(f"{line}\n")


def print_subheader(text: str, char: str = "-", width: int = 70):
    """ì„œë¸Œ í—¤ë” ì¶œë ¥"""
    line = char * width
    print(f"\n{line}")
    print(f"  {text}")
    print(f"{line}")


def print_json_block(data: dict, title: str = None, indent: int = 2):
    """JSON ë¸”ë¡ ì¶œë ¥"""
    if title:
        print(f"\nğŸ“¦ {title}:")
    print(json.dumps(data, indent=indent, ensure_ascii=False, default=str))


def print_node_result_detail(result: dict, node_name: str):
    """ê°œë³„ ë…¸ë“œ ê²°ê³¼ ìƒì„¸ ì¶œë ¥"""
    
    if node_name == "query_understanding":
        print_subheader("ğŸ” [100] QueryUnderstandingNode ê²°ê³¼", "â”€")
        
        # Schema Context ìš”ì•½
        schema_ctx = result.get("schema_context", {})
        print("\nğŸ“Š Schema Context:")
        print(f"   â€¢ Cohort Sources: {len(schema_ctx.get('cohort_sources', []))}")
        for cs in schema_ctx.get('cohort_sources', []):
            print(f"      - {cs.get('file_name')} (entity: {cs.get('entity_identifier')})")
        
        print(f"   â€¢ Signal Groups: {len(schema_ctx.get('signal_groups', []))}")
        for sg in schema_ctx.get('signal_groups', []):
            print(f"      - {sg.get('group_name')} (pattern: {sg.get('file_pattern')})")
        
        print(f"   â€¢ Parameter Categories: {len(schema_ctx.get('parameters', {}))}")
        for cat, params in schema_ctx.get('parameters', {}).items():
            print(f"      - {cat}: {len(params)} params")
        
        print(f"   â€¢ Relationships: {len(schema_ctx.get('relationships', []))}")
        for rel in schema_ctx.get('relationships', []):
            from_str = f"{rel.get('from_table')}.{rel.get('from_column')}"
            to_str = f"{rel.get('to_table')}.{rel.get('to_column')}"
            cardinality = rel.get('cardinality', 'N/A')
            print(f"      - {from_str} â†’ {to_str} ({cardinality})")
        
        # Intent
        print(f"\nğŸ¯ Intent: {result.get('intent', 'N/A')}")
        
        # Requested Parameters
        print("\nğŸ“‹ Requested Parameters:")
        for i, param in enumerate(result.get('requested_parameters', []), 1):
            print(f"   [{i}] term: \"{param.get('term')}\"")
            print(f"       normalized: \"{param.get('normalized')}\"")
            print(f"       candidates: {param.get('candidates', [])}")
        
        # Cohort Filters
        print("\nğŸ” Cohort Filters:")
        filters = result.get('cohort_filters', [])
        if filters:
            for f in filters:
                print(f"   â€¢ {f.get('column')} {f.get('operator')} \"{f.get('value')}\"")
        else:
            print("   (ì—†ìŒ)")
        
        # Temporal Context
        temporal = result.get('temporal_context', {})
        print("\nâ° Temporal Context:")
        print(f"   â€¢ type: {temporal.get('type', 'N/A')}")
        print(f"   â€¢ margin_seconds: {temporal.get('margin_seconds', 0)}")
        if temporal.get('start_column'):
            print(f"   â€¢ start_column: {temporal.get('start_column')}")
            print(f"   â€¢ end_column: {temporal.get('end_column')}")
        
        # Node result metadata
        node_result = result.get('query_understanding_result', {})
        if node_result:
            print("\nğŸ“ Node Metadata:")
            print(f"   â€¢ status: {node_result.get('status')}")
            print(f"   â€¢ context_loaded: {node_result.get('context_loaded')}")
            if node_result.get('llm_reasoning'):
                reasoning = node_result.get('llm_reasoning', '')
                print(f"   â€¢ llm_reasoning:")
                # ê¸´ í…ìŠ¤íŠ¸ë¥¼ 80ìì”© ì¤„ë°”ê¿ˆí•´ì„œ ì¶œë ¥
                for i in range(0, len(reasoning), 80):
                    print(f"     {reasoning[i:i+80]}")
    
    elif node_name == "parameter_resolver":
        print_subheader("ğŸ”— [200] ParameterResolverNode ê²°ê³¼", "â”€")
        
        # Resolved Parameters
        print("\nâœ… Resolved Parameters:")
        for idx, param in enumerate(result.get('resolved_parameters', []), 1):
            print(f"\n   {'='*60}")
            print(f"   [{idx}] term: \"{param.get('term')}\"")
            print(f"   {'='*60}")
            
            # Search info
            search_candidates = param.get('search_candidates', [])
            print(f"\n       ğŸ” Search:")
            print(f"          candidates: {search_candidates}")
            
            # DB Matches (ì¤‘ìš”!)
            db_matches = param.get('db_matches', [])
            print(f"\n       ğŸ“Š DB Matches ({len(db_matches)}):")
            if db_matches:
                for j, match in enumerate(db_matches, 1):
                    print(f"          [{j}] param_key: {match.get('param_key')}")
                    print(f"              semantic_name: {match.get('semantic_name')}")
                    print(f"              unit: {match.get('unit')}")
                    print(f"              concept_category: {match.get('concept_category')}")
            else:
                print("          (ì—†ìŒ)")
            
            # Resolution Result
            print(f"\n       ğŸ¯ Resolution Result:")
            print(f"          resolution_mode: {param.get('resolution_mode')}")
            print(f"          confidence: {param.get('confidence', 0):.2f}")
            print(f"          semantic_name: {param.get('semantic_name')}")
            print(f"          unit: {param.get('unit')}")
            print(f"          concept_category: {param.get('concept_category')}")
            
            # Selected param_keys
            param_keys = param.get('param_keys', [])
            print(f"\n       âœ… Selected param_keys ({len(param_keys)}):")
            for key in param_keys:
                # ì´ keyê°€ db_matchesì˜ ì–´ë–¤ í•­ëª©ê³¼ ë§¤ì¹­ë˜ëŠ”ì§€ í‘œì‹œ
                match_info = next((m for m in db_matches if m.get('param_key') == key), None)
                if match_info:
                    print(f"          â€¢ {key} â†’ {match_info.get('semantic_name')} ({match_info.get('unit')})")
                else:
                    print(f"          â€¢ {key}")
            
            # Reasoning
            if param.get('reasoning'):
                reasoning = param.get('reasoning', '')
                print(f"\n       ğŸ’­ LLM Reasoning:")
                for i in range(0, len(reasoning), 70):
                    print(f"          {reasoning[i:i+70]}")
        
        # Ambiguities
        ambiguities = result.get('ambiguities', [])
        print(f"\nâ“ Ambiguities: {len(ambiguities)}")
        if ambiguities:
            for a in ambiguities:
                print(f"   â€¢ term: \"{a.get('term')}\"")
                print(f"     question: {a.get('question')}")
                print(f"     candidates: {a.get('candidates', [])}")
        
        print(f"\nâš ï¸ Has Ambiguity: {result.get('has_ambiguity', False)}")
        
        # Node result metadata
        node_result = result.get('parameter_resolver_result', {})
        if node_result:
            print("\nğŸ“ Node Metadata:")
            print(f"   â€¢ status: {node_result.get('status')}")
            print(f"   â€¢ resolved_count: {node_result.get('resolved_count')}")
            print(f"   â€¢ ambiguity_count: {node_result.get('ambiguity_count')}")
    
    elif node_name == "plan_builder":
        print_subheader("ğŸ“¦ [300] PlanBuilderNode ê²°ê³¼", "â”€")
        
        # Execution Plan
        plan = result.get('execution_plan', {})
        exec_plan = plan.get('execution_plan', {})
        
        print(f"\n{'='*70}")
        print(f"   ğŸ“‹ EXECUTION PLAN OVERVIEW")
        print(f"{'='*70}")
        print(f"   Version: {plan.get('version', '?')}")
        print(f"   Generated at: {plan.get('generated_at')}")
        print(f"   Agent: {plan.get('agent')}")
        print(f"   Original Query: {plan.get('original_query', 'N/A')}")
        
        # Cohort Source ìƒì„¸
        cohort = exec_plan.get('cohort_source', {})
        print(f"\n{'â”€'*70}")
        print(f"   ğŸ¥ COHORT SOURCE (í™˜ì/ì¼€ì´ìŠ¤ ë°ì´í„°)")
        print(f"{'â”€'*70}")
        if cohort:
            print(f"   file_id: {cohort.get('file_id')}")
            print(f"   file_name: {cohort.get('file_name')}")
            print(f"   entity_identifier: {cohort.get('entity_identifier')}")
            print(f"   row_represents: {cohort.get('row_represents')}")
            
            filters = cohort.get('filters', [])
            print(f"\n   Filters ({len(filters)}):")
            if filters:
                for idx, f in enumerate(filters, 1):
                    print(f"      [{idx}] {f.get('column')} {f.get('operator')} \"{f.get('value')}\"")
                    if f.get('validated'):
                        print(f"          validated: {f.get('validated')}")
            else:
                print(f"      (ì—†ìŒ - ì „ì²´ ë°ì´í„° ì‚¬ìš©)")
        else:
            print(f"   âš ï¸ Cohort source not configured")
        
        # Signal Source ìƒì„¸
        signal = exec_plan.get('signal_source', {})
        print(f"\n{'â”€'*70}")
        print(f"   ğŸ“ˆ SIGNAL SOURCE (ì‹œê³„ì—´ ì‹ í˜¸ ë°ì´í„°)")
        print(f"{'â”€'*70}")
        if signal:
            print(f"   group_id: {signal.get('group_id')}")
            print(f"   group_name: {signal.get('group_name')}")
            print(f"   file_pattern: {signal.get('file_pattern')}")
            
            # Parameters ìƒì„¸
            params = signal.get('parameters', [])
            print(f"\n   Parameters ({len(params)}):")
            for idx, p in enumerate(params, 1):
                print(f"\n      [{idx}] term: \"{p.get('term')}\"")
                print(f"          resolution_mode: {p.get('resolution_mode')}")
                print(f"          semantic_name: {p.get('semantic_name')}")
                print(f"          unit: {p.get('unit')}")
                print(f"          confidence: {p.get('confidence', 'N/A')}")
                
                param_keys = p.get('param_keys', [])
                print(f"          param_keys ({len(param_keys)}):")
                for key in param_keys:
                    print(f"             â€¢ {key}")
            
            # Temporal Alignment ìƒì„¸
            temporal = signal.get('temporal_alignment', {})
            print(f"\n   Temporal Alignment:")
            print(f"      type: {temporal.get('type')}")
            print(f"      margin_seconds: {temporal.get('margin_seconds')}")
            if temporal.get('start_column'):
                print(f"      start_column: {temporal.get('start_column')}")
                print(f"      end_column: {temporal.get('end_column')}")
            
            # Temporal type ì„¤ëª…
            temporal_type = temporal.get('type', '')
            if temporal_type == 'full_record':
                print(f"      ğŸ“ (ì „ì²´ ê¸°ë¡ - ì‹œê°„ í•„í„° ì—†ìŒ)")
            elif temporal_type == 'procedure_window':
                print(f"      ğŸ“ (ì‹œìˆ /ìˆ˜ìˆ  ì‹œê°„ êµ¬ê°„ ë‚´ ë°ì´í„°ë§Œ)")
            elif temporal_type == 'treatment_window':
                print(f"      ğŸ“ (ì¹˜ë£Œ ì‹œê°„ êµ¬ê°„ ë‚´ ë°ì´í„°ë§Œ)")
        else:
            print(f"   âš ï¸ Signal source not configured")
        
        # Join Specification ìƒì„¸
        join = exec_plan.get('join_specification', {})
        print(f"\n{'â”€'*70}")
        print(f"   ğŸ”— JOIN SPECIFICATION (ë°ì´í„° ì—°ê²°)")
        print(f"{'â”€'*70}")
        if join:
            print(f"   type: {join.get('type')}")
            print(f"   cohort_key: {join.get('cohort_key')}")
            print(f"   signal_key: {join.get('signal_key')}")
            print(f"   cardinality: {join.get('cardinality')}")
            
            # Join ì„¤ëª…
            cohort_key = join.get('cohort_key', '')
            signal_key = join.get('signal_key', '')
            cardinality = join.get('cardinality', '')
            print(f"\n   ğŸ“ JOIN ì„¤ëª…:")
            print(f"      {cohort.get('file_name', 'cohort')}.{cohort_key}")
            print(f"         â†“ {join.get('type', 'inner')} join ({cardinality})")
            print(f"      {signal.get('group_name', 'signal')}.{signal_key}")
        else:
            print(f"   âš ï¸ Join specification not configured")
        
        # Validation ìƒì„¸
        validation = result.get('validation', {})
        print(f"\n{'â”€'*70}")
        print(f"   âœ“ VALIDATION (ê²€ì¦ ê²°ê³¼)")
        print(f"{'â”€'*70}")
        is_valid = validation.get('is_valid', False)
        confidence = validation.get('confidence', 0)
        
        status_icon = "âœ…" if is_valid else "âŒ"
        conf_bar = "â–ˆ" * int(confidence * 10) + "â–‘" * (10 - int(confidence * 10))
        
        print(f"   is_valid: {status_icon} {is_valid}")
        print(f"   confidence: [{conf_bar}] {confidence:.2f}")
        print(f"   validated_at: {validation.get('validated_at')}")
        
        warnings = validation.get('warnings', [])
        if warnings:
            print(f"\n   Warnings ({len(warnings)}):")
            for w in warnings:
                print(f"      âš ï¸ {w}")
        else:
            print(f"\n   Warnings: (ì—†ìŒ)")
        
        # Full JSON ì¶œë ¥
        print(f"\n{'â”€'*70}")
        print(f"   ğŸ“„ FULL EXECUTION PLAN JSON")
        print(f"{'â”€'*70}")
        print(json.dumps(plan, indent=2, ensure_ascii=False, default=str))
        
        # Node result metadata
        node_result = result.get('plan_builder_result', {})
        if node_result:
            print("\nğŸ“ Node Metadata:")
            print(f"   â€¢ status: {node_result.get('status')}")
            print(f"   â€¢ confidence: {node_result.get('confidence')}")
            print(f"   â€¢ warning_count: {node_result.get('warning_count')}")


def print_logs(result: dict):
    """ë¡œê·¸ ì¶œë ¥"""
    logs = result.get('logs', [])
    if logs:
        print_subheader(f"ğŸ“ Pipeline Logs ({len(logs)} entries)", "â”€")
        for log in logs:
            print(f"   {log}")


def run_test(workflow, query_info: dict, verbose: bool = False, show_json: bool = False) -> tuple:
    """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    query = query_info["query"]
    expected = query_info["expected"]
    
    print(f"\nğŸ“ Query: {query}")
    print(f"â³ Running pipeline...\n")
    
    start_time = time.time()
    
    try:
        # ì´ˆê¸° ìƒíƒœ
        initial_state = {
            "user_query": query,
            "logs": []
        }
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = workflow.invoke(initial_state)
        
        elapsed = time.time() - start_time
        print(f"\nâœ… Completed in {elapsed:.2f}s")
        
        # ìƒì„¸ ì¶œë ¥ ëª¨ë“œ
        if verbose:
            print_node_result_detail(result, "query_understanding")
            print_node_result_detail(result, "parameter_resolver")
            print_node_result_detail(result, "plan_builder")
            # print_logs(result)  # ì¤‘ë³µ ì¶œë ¥ ë°©ì§€ - ë…¸ë“œì—ì„œ ì´ë¯¸ ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ë¨
        
        # JSON ì „ì²´ ì¶œë ¥ ëª¨ë“œ
        if show_json:
            print_subheader("ğŸ“„ Full Result JSON", "â”€")
            # ë¯¼ê° ì •ë³´ ì œì™¸í•œ ë³µì‚¬ë³¸
            result_copy = {k: v for k, v in result.items() if k != 'schema_context'}
            print(json.dumps(result_copy, indent=2, ensure_ascii=False, default=str))
        
        # ê²€ì¦
        checks = validate_result(result, expected)
        
        # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        print_subheader("âœ“ Validation Checks", "â”€")
        print(f"   Intent Match: {'âœ…' if checks['intent_match'] else 'âŒ'} (expected: {expected.get('intent')}, got: {result.get('intent')})")
        print(f"   Min Params Met: {'âœ…' if checks['min_params_met'] else 'âŒ'} (expected: >={expected.get('min_parameters')}, got: {len(result.get('resolved_parameters', []))})")
        print(f"   Temporal Match: {'âœ…' if checks['temporal_match'] else 'âŒ'} (expected: {expected.get('temporal_type')}, got: {result.get('temporal_context', {}).get('type')})")
        print(f"   Plan Valid: {'âœ…' if checks['is_valid'] else 'âŒ'} (confidence: {result.get('validation', {}).get('confidence', 0):.2f})")
        
        return True, result, checks, elapsed
        
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"âŒ Failed after {elapsed:.2f}s: {e}")
        import traceback
        traceback.print_exc()
        return False, None, {}, elapsed


def validate_result(result: dict, expected: dict) -> dict:
    """ê²°ê³¼ ê²€ì¦"""
    checks = {
        "intent_match": False,
        "min_params_met": False,
        "temporal_match": False,
        "is_valid": False
    }
    
    checks["intent_match"] = result.get("intent") == expected.get("intent")
    
    resolved = result.get("resolved_parameters", [])
    checks["min_params_met"] = len(resolved) >= expected.get("min_parameters", 1)
    
    temporal = result.get("temporal_context", {})
    checks["temporal_match"] = temporal.get("type") == expected.get("temporal_type")
    
    validation = result.get("validation", {})
    checks["is_valid"] = validation.get("is_valid", False)
    
    return checks


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    # ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='VitalExtractionAgent Pipeline Test')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ì¶œë ¥ ëª¨ë“œ')
    parser.add_argument('--json', '-j', action='store_true', help='JSON ì „ì²´ ì¶œë ¥')
    parser.add_argument('--query', '-q', type=int, help='íŠ¹ì • ì¿¼ë¦¬ë§Œ í…ŒìŠ¤íŠ¸ (1 or 2)')
    args = parser.parse_args()
    
    # ê¸°ë³¸ê°’: verbose ëª¨ë“œ
    verbose = args.verbose if args.verbose else True  # ê¸°ë³¸ìœ¼ë¡œ ìƒì„¸ ì¶œë ¥
    show_json = args.json
    
    print_header("VitalExtractionAgent - Full Pipeline Test (Debug Mode)", "=", 80)
    
    if verbose:
        print("ğŸ”§ Mode: VERBOSE (ìƒì„¸ ì¶œë ¥)")
    if show_json:
        print("ğŸ”§ Mode: JSON (ì „ì²´ JSON ì¶œë ¥)")
    
    # íŒŒì´í”„ë¼ì¸ ë¹Œë“œ
    print("\nğŸ”§ Building pipeline...")
    
    try:
        from src.agents.graph import build_agent
        workflow = build_agent()
    except Exception as e:
        print(f"âŒ Failed to build pipeline: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # í…ŒìŠ¤íŠ¸í•  ì¿¼ë¦¬ ì„ íƒ
    queries_to_test = TEST_QUERIES
    if args.query:
        if 1 <= args.query <= len(TEST_QUERIES):
            queries_to_test = [TEST_QUERIES[args.query - 1]]
        else:
            print(f"âŒ Invalid query number: {args.query}")
            return False
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = []
    total_time = 0
    
    for i, query_info in enumerate(queries_to_test, 1):
        print_header(f"Test {i}/{len(queries_to_test)}: {query_info['name']}", "â•", 80)
        
        success, result, checks, elapsed = run_test(
            workflow, 
            query_info, 
            verbose=verbose, 
            show_json=show_json
        )
        total_time += elapsed
        
        results.append({
            "name": query_info["name"],
            "success": success,
            "checks": checks,
            "elapsed": elapsed,
            "result": result
        })
    
    # ìµœì¢… ìš”ì•½
    print_header("TEST SUMMARY", "â•", 80)
    
    passed = 0
    for r in results:
        name = r["name"]
        success = r["success"]
        checks = r["checks"]
        elapsed = r["elapsed"]
        
        if success:
            all_passed = all(checks.values())
            status = "âœ… PASS" if all_passed else "âš ï¸ PARTIAL"
            if all_passed:
                passed += 1
        else:
            status = "âŒ FAIL"
        
        print(f"  {status} | {name} | {elapsed:.2f}s")
        if success:
            for check_name, check_value in checks.items():
                icon = "âœ“" if check_value else "âœ—"
                print(f"         | {icon} {check_name}")
        print()
    
    # ìµœì¢… ê²°ê³¼
    print("â”€" * 80)
    print(f"  Total: {passed}/{len(results)} tests passed")
    print(f"  Total time: {total_time:.2f}s")
    if len(results) > 0:
        print(f"  Avg time per query: {total_time/len(results):.2f}s")
    print("â”€" * 80)
    
    if passed == len(results):
        print("\nğŸ‰ All tests passed! VitalExtractionAgent is ready.")
    else:
        print("\nâš ï¸ Some tests need attention. Review results above.")
    
    return passed == len(results)


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
