#!/usr/bin/env python3
"""
ExtractionAgent + DataContext í†µí•© í…ŒìŠ¤íŠ¸
==========================================

ExtractionAgentê°€ ìƒì„±í•œ execution_planì„ DataContextê°€
ì˜¬ë°”ë¥´ê²Œ íŒŒì‹±í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

Usage:
    cd /path/to/MedicalAIMaster
    python ExtractionAgent/test_integration.py
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "ExtractionAgent"))

print("=" * 70)
print("  ExtractionAgent + DataContext í†µí•© í…ŒìŠ¤íŠ¸")
print("=" * 70)


def test_pipeline_to_datacontext():
    """ExtractionAgent íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í›„ DataContextë¡œ ì „ë‹¬ í…ŒìŠ¤íŠ¸"""
    print("\n[Test] ExtractionAgent â†’ DataContext ì—°ë™")
    print("-" * 50)
    
    try:
        # 1. ExtractionAgent íŒŒì´í”„ë¼ì¸ ë¹Œë“œ
        print("\n  ğŸ“¦ ExtractionAgent íŒŒì´í”„ë¼ì¸ ë¹Œë“œ ì¤‘...")
        from src.agents.graph import build_agent
        
        agent = build_agent()
        print("  âœ… íŒŒì´í”„ë¼ì¸ ë¹Œë“œ ì„±ê³µ")
        
        # 2. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
        test_query = "ìœ„ì•” í™˜ìì˜ ìˆ˜ìˆ  ì¤‘ ì‹¬ë°•ìˆ˜ì™€ í˜ˆì•• ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì¤˜"
        print(f"\n  ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: \"{test_query}\"")
        
        initial_state = {
            "user_query": test_query,
            "schema_context": None,
            "intent": None,
            "requested_parameters": None,
            "cohort_filters": None,
            "temporal_context": None,
            "resolved_parameters": None,
            "ambiguities": None,
            "has_ambiguity": None,
            "execution_plan": None,
            "validation": None,
            "logs": [],
            "error_message": None
        }
        
        print("  ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
        result = agent.invoke(initial_state)
        print("  âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
        
        # 3. execution_plan í™•ì¸
        execution_plan = result.get("execution_plan")
        if not execution_plan:
            print("  âŒ execution_planì´ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        print(f"\n  ğŸ“‹ Execution Plan ìƒì„±ë¨:")
        print(f"     - version: {execution_plan.get('version')}")
        print(f"     - agent: {execution_plan.get('agent')}")
        
        plan = execution_plan.get("execution_plan", {})
        cohort = plan.get("cohort_source", {})
        signals = plan.get("signal_source", {})
        
        print(f"     - cohort_source.file_id: {cohort.get('file_id')}")
        print(f"     - cohort_source.filters: {len(cohort.get('filters', []))}ê°œ")
        print(f"     - signal_source.group_id: {signals.get('group_id')}")
        print(f"     - signal_source.parameters: {len(signals.get('parameters', []))}ê°œ")
        
        # 4. DataContextì— Plan ë¡œë“œ
        print("\n  ğŸ“¦ DataContextì— Plan ë¡œë“œ ì¤‘...")
        from shared.data.context import DataContext
        
        ctx = DataContext()
        ctx.load_from_plan(execution_plan, preload_cohort=False)
        
        if ctx.is_loaded():
            print("  âœ… DataContext Plan ë¡œë“œ ì„±ê³µ")
        else:
            print("  âŒ DataContext Plan ë¡œë“œ ì‹¤íŒ¨")
            return False
        
        # 5. DataContext ìƒíƒœ í™•ì¸
        print(f"\n  ğŸ“Š DataContext ìƒíƒœ:")
        print(f"     - cohort_file_id: {ctx._cohort_file_id}")
        print(f"     - signal_group_id: {ctx._signal_group_id}")
        print(f"     - param_keys: {ctx._param_keys}")
        print(f"     - temporal_config: {ctx._temporal_config}")
        print(f"     - cohort_filters: {ctx._cohort_filters}")
        
        # 6. Analysis Context ìƒì„±
        print("\n  ğŸ“‹ Analysis Context ìƒì„±...")
        analysis_ctx = ctx.get_analysis_context()
        
        print(f"     - description: {analysis_ctx['description'][:80]}...")
        print(f"     - original_query: {analysis_ctx['original_query']}")
        print(f"     - cohort.total_cases: {analysis_ctx['cohort']['total_cases']}")
        print(f"     - cohort.entity_identifier: {analysis_ctx['cohort']['entity_identifier']}")
        print(f"     - signals.param_keys: {len(analysis_ctx['signals']['param_keys'])}ê°œ")
        print(f"     - signals.temporal_setting.type: {analysis_ctx['signals']['temporal_setting']['type']}")
        
        # 7. Parameter Info í™•ì¸
        print("\n  ğŸ“‹ Parameter Info í™•ì¸...")
        available_params = ctx.get_available_parameters()
        print(f"     - ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {available_params}")
        
        for pk in available_params[:2]:  # ì²˜ìŒ 2ê°œë§Œ
            info = ctx.get_parameter_info(pk)
            if info:
                print(f"     - {pk}:")
                print(f"       term: {info.get('term')}")
                print(f"       semantic_name: {info.get('semantic_name')}")
        
        # 8. Validation ê²°ê³¼ í™•ì¸
        validation = result.get("validation", {})
        print(f"\n  ğŸ“Š Validation:")
        print(f"     - confidence: {validation.get('confidence', 0):.2f}")
        print(f"     - warnings: {validation.get('warnings', [])}")
        
        print("\n  âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        return True
        
    except Exception as e:
        print(f"\n  âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_datacontext_summary():
    """DataContext summary ë©”ì„œë“œ í…ŒìŠ¤íŠ¸ (DB ì—†ì´ íŒŒì‹±ë§Œ)"""
    print("\n[Test] DataContext Summary (íŒŒì‹± ì „ìš©)")
    print("-" * 50)
    
    try:
        from shared.data.context import DataContext
        
        # ìƒ˜í”Œ planìœ¼ë¡œ í…ŒìŠ¤íŠ¸ (DB ì ‘ê·¼ ì—†ì´)
        sample_plan = {
            "version": "1.0",
            "original_query": "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
            "execution_plan": {
                "cohort_source": {
                    "file_id": "00000000-0000-0000-0000-000000000001",  # Valid UUID format
                    "filters": [{"column": "dept", "operator": "=", "value": "GS"}]
                },
                "signal_source": {
                    "group_id": "00000000-0000-0000-0000-000000000002",  # Valid UUID format
                    "parameters": [
                        {"term": "HR", "param_keys": ["Solar8000/HR"], "semantic_name": "Heart Rate", "unit": "bpm"}
                    ],
                    "temporal_alignment": {
                        "type": "surgery_window",
                        "margin_seconds": 300
                    }
                }
            }
        }
        
        ctx = DataContext()
        
        # ì§ì ‘ íŒŒì‹± (DB ì ‘ê·¼ ì—†ì´)
        ctx._plan = sample_plan
        plan = sample_plan.get("execution_plan", {})
        
        cohort_source = plan.get("cohort_source", {})
        ctx._cohort_file_id = cohort_source.get("file_id")
        ctx._cohort_entity_id = cohort_source.get("entity_identifier", "caseid")
        ctx._cohort_filters = cohort_source.get("filters", [])
        
        signal_source = plan.get("signal_source", {})
        ctx._signal_group_id = signal_source.get("group_id")
        ctx._temporal_config = signal_source.get("temporal_alignment", {})
        
        parameters = signal_source.get("parameters", [])
        ctx._param_info = parameters
        ctx._param_keys = []
        for p in parameters:
            ctx._param_keys.extend(p.get("param_keys", []))
        
        ctx._loaded_at = None
        
        summary = ctx.summary()
        print(f"\n  ğŸ“Š Summary:")
        print(f"     - loaded_at: {summary['loaded_at']}")
        print(f"     - cohort.file_id: {summary['cohort']['file_id']}")
        print(f"     - cohort.filters_count: {summary['cohort']['filters_count']}")
        print(f"     - cohort.loaded: {summary['cohort']['loaded']}")
        print(f"     - signals.group_id: {summary['signals']['group_id']}")
        print(f"     - signals.param_keys: {summary['signals']['param_keys']}")
        print(f"     - signals.temporal_type: {summary['signals']['temporal_type']}")
        
        print("\n  âœ… Summary í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        return True
        
    except Exception as e:
        print(f"\n  âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    results = {}
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results["test_pipeline_to_datacontext"] = test_pipeline_to_datacontext()
    results["test_datacontext_summary"] = test_datacontext_summary()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {status} - {name}")
    
    print(f"\n  ì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
    print("=" * 70)
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

