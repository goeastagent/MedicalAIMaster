#!/usr/bin/env python3
"""
IndexingAgent ì „ì²´ ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸

- PostgreSQL: ëª¨ë“  í…Œì´ë¸” ì‚­ì œ (file_catalog, column_metadata í¬í•¨)
- Neo4j: ëª¨ë“  ë…¸ë“œ/ê´€ê³„ ì‚­ì œ
- VectorDB: ChromaDB ì»¬ë ‰ì…˜ ì‚­ì œ
- ì˜¨í†¨ë¡œì§€ JSON: ì´ˆê¸°í™”
- LLM ìºì‹œ: ì‚­ì œ

ì‚¬ìš©ë²•:
    python reset_all.py              # í™•ì¸ í›„ ì‚­ì œ (ìºì‹œ ì œì™¸)
    python reset_all.py -y           # í™•ì¸ ì—†ì´ ì‚­ì œ (ìºì‹œ ì œì™¸)
    python reset_all.py --clear-cache   # ìºì‹œë„ ì‚­ì œ (í™•ì¸ í•„ìš”)
    python reset_all.py --all -y     # ì „ì²´ ì‚­ì œ (ìºì‹œ í¬í•¨, í™•ì¸ ì—†ì´)
"""

import sys
import os

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from dotenv import load_dotenv
load_dotenv()


def reset_postgres(recreate_tables=True):
    """PostgreSQL ëª¨ë“  í…Œì´ë¸” ì‚­ì œ ë° ì¬ìƒì„±
    
    FK ì°¸ì¡° ê´€ê³„ë¡œ ì¸í•´ ì‚­ì œ/ìƒì„± ìˆœì„œê°€ ì¤‘ìš”:
    - ì‚­ì œ: Ontology â†’ Dictionary â†’ Catalog (ì°¸ì¡°í•˜ëŠ” ê²ƒ ë¨¼ì €)
    - ìƒì„±: Catalog â†’ Dictionary â†’ Ontology (ì°¸ì¡°ë˜ëŠ” ê²ƒ ë¨¼ì €)
    
    Args:
        recreate_tables: Trueë©´ ì‚­ì œ í›„ ë¹ˆ í…Œì´ë¸” ì¬ìƒì„±
    """
    print("\n" + "=" * 60)
    print("ğŸ—„ï¸  [PostgreSQL] ì´ˆê¸°í™” ì¤‘...")
    print("=" * 60)
    
    try:
        from database.schema_catalog import CatalogSchemaManager
        from database.schema_dictionary import DictionarySchemaManager
        from database.schema_ontology import OntologySchemaManager
        from database.schema_directory import DirectorySchemaManager
        
        # í˜„ì¬ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        from database.connection import get_db_manager
        db = get_db_manager()
        conn = db.get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_type = 'BASE TABLE'
        """)
        tables = [row[0] for row in cursor.fetchall()]
        
        if tables:
            print(f"   - ì‚­ì œ ëŒ€ìƒ í…Œì´ë¸”: {len(tables)}ê°œ")
            for table in tables:
                print(f"     â€¢ {table}")
        else:
            print("   - ì‚­ì œí•  í…Œì´ë¸” ì—†ìŒ")
        
        # 1. ì‚­ì œ: FK ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸” ë¨¼ì € (ì—­ìˆœ)
        # ìˆœì„œ: Ontology â†’ Dictionary â†’ Catalog â†’ Directory
        print("\n   ğŸ“¤ í…Œì´ë¸” ì‚­ì œ (FK ì°¸ì¡° ìˆœì„œ)...")
        try:
            OntologySchemaManager().drop_tables(confirm=True)
        except Exception as e:
            print(f"      âš ï¸ Ontology: {e}")
        
        try:
            DictionarySchemaManager().drop_tables(confirm=True)
        except Exception as e:
            print(f"      âš ï¸ Dictionary: {e}")
        
        try:
            CatalogSchemaManager().drop_tables(confirm=True)
        except Exception as e:
            print(f"      âš ï¸ Catalog: {e}")
        
        try:
            DirectorySchemaManager().drop_tables(confirm=True)
        except Exception as e:
            print(f"      âš ï¸ Directory: {e}")
        
        # 2. ìƒì„±: FK ì°¸ì¡°ë˜ëŠ” í…Œì´ë¸” ë¨¼ì € (ì •ìˆœ)
        # ìˆœì„œ: Directory â†’ Catalog â†’ Dictionary â†’ Ontology
        if recreate_tables:
            print("\n   ğŸ“¥ í…Œì´ë¸” ìƒì„± (FK ì°¸ì¡° ìˆœì„œ)...")
            try:
                DirectorySchemaManager().create_tables()
            except Exception as e:
                print(f"      âš ï¸ Directory: {e}")
            
            try:
                CatalogSchemaManager().create_tables()
            except Exception as e:
                print(f"      âš ï¸ Catalog: {e}")
            
            try:
                DictionarySchemaManager().create_tables()
            except Exception as e:
                print(f"      âš ï¸ Dictionary: {e}")
            
            try:
                OntologySchemaManager().create_tables()
            except Exception as e:
                print(f"      âš ï¸ Ontology: {e}")
        
        print("âœ… [PostgreSQL] ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ [PostgreSQL] ì˜¤ë¥˜: {e}")


def reset_neo4j():
    """Neo4j ëª¨ë“  ë…¸ë“œ/ê´€ê³„ ì‚­ì œ"""
    print("\n" + "=" * 60)
    print("ğŸ”— [Neo4j] ì´ˆê¸°í™” ì¤‘...")
    print("=" * 60)
    
    try:
        from database.neo4j_connection import get_neo4j_connection
        
        neo4j = get_neo4j_connection()
        neo4j.connect()
        
        # ë…¸ë“œ ìˆ˜ í™•ì¸
        result = neo4j.execute_query("MATCH (n) RETURN count(n) as count")
        node_count = result[0]["count"] if result else 0
        
        result = neo4j.execute_query("MATCH ()-[r]->() RETURN count(r) as count")
        rel_count = result[0]["count"] if result else 0
        
        print(f"   - ì‚­ì œ ëŒ€ìƒ: ë…¸ë“œ {node_count}ê°œ, ê´€ê³„ {rel_count}ê°œ")
        
        if node_count > 0 or rel_count > 0:
            # ëª¨ë“  ë…¸ë“œì™€ ê´€ê³„ ì‚­ì œ
            neo4j.execute_query("MATCH (n) DETACH DELETE n")
            print("   âœ… ëª¨ë“  ë…¸ë“œ/ê´€ê³„ ì‚­ì œë¨")
        else:
            print("   - ì‚­ì œí•  ë°ì´í„° ì—†ìŒ")
        
        print("âœ… [Neo4j] ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ [Neo4j] ì˜¤ë¥˜: {e}")


def reset_ontology_json():
    """ì˜¨í†¨ë¡œì§€ JSON íŒŒì¼ ì´ˆê¸°í™”"""
    print("\n" + "=" * 60)
    print("ğŸ“š [ì˜¨í†¨ë¡œì§€ JSON] ì´ˆê¸°í™” ì¤‘...")
    print("=" * 60)
    
    ontology_path = os.path.join(
        os.path.dirname(__file__), 
        "data", "processed", "ontology_db.json"
    )
    
    if os.path.exists(ontology_path):
        os.remove(ontology_path)
        print(f"   âœ… ì‚­ì œë¨: {ontology_path}")
    else:
        print(f"   - íŒŒì¼ ì—†ìŒ: {ontology_path}")
    
    print("âœ… [ì˜¨í†¨ë¡œì§€ JSON] ì´ˆê¸°í™” ì™„ë£Œ")


def reset_vector_db():
    """VectorDB (ChromaDB) ì´ˆê¸°í™”"""
    print("\n" + "=" * 60)
    print("ğŸ”¢ [VectorDB] ì´ˆê¸°í™” ì¤‘...")
    print("=" * 60)
    
    import shutil
    
    vector_db_path = os.path.join(
        os.path.dirname(__file__), 
        "data", "processed", "vector_db"
    )
    
    if os.path.exists(vector_db_path):
        file_count = sum(1 for _ in os.scandir(vector_db_path) if _.is_file())
        shutil.rmtree(vector_db_path)
        os.makedirs(vector_db_path, exist_ok=True)
        print(f"   âœ… ì‚­ì œë¨: {vector_db_path} ({file_count}ê°œ íŒŒì¼)")
    else:
        print(f"   - í´ë” ì—†ìŒ: {vector_db_path}")
    
    print("âœ… [VectorDB] ì´ˆê¸°í™” ì™„ë£Œ")


def reset_llm_cache(confirm=False):
    """LLM ìºì‹œ ì‚­ì œ (JSON ìºì‹œ + diskcache ëª¨ë‘ ì‚­ì œ)"""
    print("\n" + "=" * 60)
    print("ğŸ§  [LLM ìºì‹œ] ì´ˆê¸°í™” ì¤‘...")
    print("=" * 60)
    
    import shutil
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ ëª©ë¡ (JSON ìºì‹œ + diskcache)
    cache_dirs = [
        os.path.join(os.path.dirname(__file__), "data", "cache", "llm"),       # ì˜› JSON ìºì‹œ
        os.path.join(os.path.dirname(__file__), "data", "cache", "llm_disk"),  # diskcache
    ]
    
    total_deleted = 0
    
    for cache_dir in cache_dirs:
        dir_name = os.path.basename(cache_dir)
        
        if os.path.exists(cache_dir):
            cache_files = os.listdir(cache_dir)
            print(f"   - [{dir_name}] ìºì‹œ íŒŒì¼: {len(cache_files)}ê°œ")
            
            if confirm:
                shutil.rmtree(cache_dir)
                os.makedirs(cache_dir)
                print(f"   âœ… [{dir_name}] ì‚­ì œë¨")
                total_deleted += len(cache_files)
            else:
                print(f"   âš ï¸  [{dir_name}] ì‚­ì œ ìŠ¤í‚µ (--clear-cache ì˜µì…˜ìœ¼ë¡œ ì‚­ì œ)")
        else:
            print(f"   - [{dir_name}] í´ë” ì—†ìŒ")
    
    if confirm and total_deleted > 0:
        print(f"   ğŸ“Š ì´ {total_deleted}ê°œ ìºì‹œ í•­ëª© ì‚­ì œë¨")
    
    print("âœ… [LLM ìºì‹œ] ì²˜ë¦¬ ì™„ë£Œ")


def print_help():
    """ë„ì›€ë§ ì¶œë ¥"""
    print("""
ì‚¬ìš©ë²•: python reset_all.py [ì˜µì…˜]

ì˜µì…˜:
    -y, --yes          í™•ì¸ ì—†ì´ ì‹¤í–‰
    --clear-cache      LLM ìºì‹œë„ ì‚­ì œ
    --all              ì „ì²´ ì‚­ì œ (ìºì‹œ í¬í•¨)
    --no-recreate      í…Œì´ë¸” ì‚­ì œë§Œ (ì¬ìƒì„± ì•ˆ í•¨)
    -h, --help         ë„ì›€ë§ ì¶œë ¥

ì˜ˆì‹œ:
    python reset_all.py              # í™•ì¸ í›„ ì‚­ì œ/ì¬ìƒì„± (ìºì‹œ ì œì™¸)
    python reset_all.py -y           # í™•ì¸ ì—†ì´ ì‚­ì œ/ì¬ìƒì„± (ìºì‹œ ì œì™¸)
    python reset_all.py --all -y     # ì „ì²´ ì‚­ì œ/ì¬ìƒì„± (ìºì‹œ í¬í•¨, í™•ì¸ ì—†ì´)
    python reset_all.py --no-recreate -y  # í…Œì´ë¸” ì‚­ì œë§Œ (ì¬ìƒì„± ì•ˆ í•¨)
""")


def main():
    print("\n" + "=" * 60)
    print("ğŸ”„ IndexingAgent ì „ì²´ ì´ˆê¸°í™”")
    print("=" * 60)
    
    # ë„ì›€ë§
    if "-h" in sys.argv or "--help" in sys.argv:
        print_help()
        return
    
    # ì˜µì…˜ íŒŒì‹±
    clear_all = "--all" in sys.argv
    clear_cache = "--clear-cache" in sys.argv or clear_all
    skip_confirm = "-y" in sys.argv or "--yes" in sys.argv
    no_recreate = "--no-recreate" in sys.argv
    
    if not skip_confirm:
        print("\nâš ï¸  ê²½ê³ : ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤!")
        print("   - PostgreSQL í…Œì´ë¸” (file_catalog, column_metadata ë“±)")
        if no_recreate:
            print("     â†’ í…Œì´ë¸” ì‚­ì œë§Œ (ì¬ìƒì„± ì•ˆ í•¨)")
        else:
            print("     â†’ ì‚­ì œ í›„ ë¹ˆ í…Œì´ë¸” ì¬ìƒì„±")
        print("   - Neo4j ë…¸ë“œ/ê´€ê³„")
        print("   - VectorDB (ChromaDB)")
        print("   - ì˜¨í†¨ë¡œì§€ JSON")
        if clear_cache:
            print("   - LLM ìºì‹œ âœ“")
        else:
            print("   - LLM ìºì‹œ (--all ë˜ëŠ” --clear-cacheë¡œ ì‚­ì œ)")
        
        confirm = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if confirm != 'y':
            print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
    
    # ì´ˆê¸°í™” ì‹¤í–‰
    reset_postgres(recreate_tables=not no_recreate)
    reset_neo4j()
    reset_vector_db()
    reset_ontology_json()
    reset_llm_cache(confirm=clear_cache)
    
    print("\n" + "=" * 60)
    print("âœ… ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ!")
    print("=" * 60)
    print("\nì´ì œ IndexingAgentë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("  python test_full_pipeline_results.py")
    print()


if __name__ == "__main__":
    main()

