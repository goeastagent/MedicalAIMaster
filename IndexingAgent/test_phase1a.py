#!/usr/bin/env python
"""
Phase 1A í…ŒìŠ¤íŠ¸: MetaData Semantic Analysis

metadata íŒŒì¼ì—ì„œ key-desc-unitì„ ì¶”ì¶œí•˜ì—¬ data_dictionaryì— ì €ìž¥í•˜ëŠ” ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

Usage:
    python test_phase1a.py [--reset]

Options:
    --reset: DB í…Œì´ë¸” ì´ˆê¸°í™” í›„ ì‹¤í–‰
"""

import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.agents.graph import build_phase1a_agent
from src.database.schema_catalog import init_catalog_schema
from src.database.schema_dictionary import init_dictionary_schema, DictionarySchemaManager


def get_test_files():
    """í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ëª©ë¡ ë°˜í™˜ (Open_VitalDBë§Œ ì‚¬ìš©)"""
    base_path = os.path.join(os.path.dirname(__file__), "data/raw/Open_VitalDB_1.0.0")
    
    files = [
        os.path.join(base_path, "clinical_parameters.csv"),
        os.path.join(base_path, "clinical_data.csv"),
        os.path.join(base_path, "lab_parameters.csv"),
        os.path.join(base_path, "lab_data.csv"),
        os.path.join(base_path, "track_names.csv"),
    ]
    
    # ì¡´ìž¬í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
    existing_files = [f for f in files if os.path.exists(f)]
    
    if not existing_files:
        print("âŒ No Open_VitalDB test files found!")
        print(f"   Expected path: {base_path}")
    
    return existing_files


def print_file_catalog_table():
    """file_catalog í…Œì´ë¸” ì¶œë ¥"""
    from src.database.connection import get_db_manager
    
    db = get_db_manager()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    print("\n" + "=" * 100)
    print("ðŸ“ FILE_CATALOG TABLE")
    print("=" * 100)
    
    cursor.execute("""
        SELECT file_name, processor_type, is_metadata, llm_confidence, 
               file_metadata->>'row_count' as row_count,
               file_metadata->>'column_count' as col_count
        FROM file_catalog
        ORDER BY is_metadata DESC, file_name
    """)
    
    rows = cursor.fetchall()
    if not rows:
        print("   (No entries found)")
        return
    
    print(f"{'File Name':<35} {'Type':<10} {'Is Meta':<10} {'Rows':<10} {'Cols':<8} {'Conf':<6}")
    print("-" * 100)
    
    for row in rows:
        file_name, proc_type, is_meta, conf, row_count, col_count = row
        meta_str = "âœ… YES" if is_meta else "âŒ NO"
        conf_str = f"{conf:.2f}" if conf else "-"
        row_str = str(row_count) if row_count else "-"
        col_str = str(col_count) if col_count else "-"
        
        print(f"{file_name:<35} {proc_type or '-':<10} {meta_str:<10} {row_str:<10} {col_str:<8} {conf_str:<6}")
    
    print("-" * 100)
    print(f"Total files: {len(rows)}")


def print_column_metadata_table():
    """column_metadata í…Œì´ë¸” ì¶œë ¥ (íŒŒì¼ë³„ ê·¸ë£¹í•‘)"""
    from src.database.connection import get_db_manager
    
    db = get_db_manager()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    print("\n" + "=" * 100)
    print("ðŸ“‹ COLUMN_METADATA TABLE")
    print("=" * 100)
    
    # íŒŒì¼ë³„ë¡œ ê·¸ë£¹í•‘
    cursor.execute("""
        SELECT fc.file_name, cm.original_name, cm.column_type, cm.data_type, 
               cm.semantic_name, cm.unit, cm.column_info
        FROM column_metadata cm
        JOIN file_catalog fc ON cm.file_id = fc.file_id
        ORDER BY fc.file_name, cm.col_id
    """)
    
    rows = cursor.fetchall()
    if not rows:
        print("   (No entries found)")
        return
    
    # íŒŒì¼ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ì¶œë ¥
    current_file = None
    file_count = 0
    
    for row in rows:
        file_name, original_name, col_type, data_type, semantic_name, unit, column_info = row
        
        if file_name != current_file:
            if current_file is not None:
                print()
            current_file = file_name
            file_count = 0
            print(f"\nðŸ“„ {file_name}")
            print("-" * 95)
            print(f"  {'Column':<20} {'Col Type':<12} {'Data Type':<10} {'Semantic':<15} {'Unit':<10}")
            print("  " + "-" * 93)
        
        file_count += 1
        col_str = original_name[:19] if original_name else "-"
        col_type_str = col_type[:11] if col_type else "-"
        dtype_str = data_type[:9] if data_type else "-"
        sem_str = (semantic_name[:14] if semantic_name else "-")
        unit_str = (unit[:9] if unit else "-")
        
        print(f"  {col_str:<20} {col_type_str:<12} {dtype_str:<10} {sem_str:<15} {unit_str:<10}")
    
    # ì „ì²´ ì»¬ëŸ¼ ìˆ˜
    cursor.execute("SELECT COUNT(*) FROM column_metadata")
    total = cursor.fetchone()[0]
    print("\n" + "-" * 100)
    print(f"Total columns: {total}")


def print_data_dictionary_table():
    """data_dictionary í…Œì´ë¸” ì „ì²´ ì¶œë ¥ (íŒŒì¼ë³„ë¡œ ê·¸ë£¹í•‘)"""
    from src.database.connection import get_db_manager
    
    db = get_db_manager()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    print("\n" + "=" * 100)
    print("ðŸ“– DATA_DICTIONARY TABLE")
    print("=" * 100)
    
    # íŒŒì¼ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ì¡°íšŒ
    cursor.execute("""
        SELECT DISTINCT source_file_name FROM data_dictionary ORDER BY source_file_name
    """)
    files = [row[0] for row in cursor.fetchall()]
    
    if not files:
        print("   (No entries found)")
        return
    
    total_entries = 0
    
    for file_name in files:
        cursor.execute("""
            SELECT parameter_key, parameter_desc, parameter_unit, extra_info, llm_confidence
            FROM data_dictionary
            WHERE source_file_name = %s
            ORDER BY parameter_key
        """, (file_name,))
        
        rows = cursor.fetchall()
        total_entries += len(rows)
        
        print(f"\nðŸ“„ {file_name} ({len(rows)} entries)")
        print("-" * 95)
        print(f"  {'Key':<20} {'Description':<35} {'Unit':<15} {'Extra Info':<20}")
        print("  " + "-" * 93)
        
        for row in rows:
            key, desc, unit, extra_info, conf = row
            key_str = (key[:19] if key else "-")
            desc_str = (desc[:34] if desc else "-")
            unit_str = (unit[:14] if unit else "-")
            
            # extra_infoëŠ” dictë¡œ ì €ìž¥ë¨
            extra_str = ""
            if extra_info and isinstance(extra_info, dict):
                extra_parts = [f"{k}={v}" for k, v in list(extra_info.items())[:2]]
                extra_str = ", ".join(extra_parts)[:19]
            
            print(f"  {key_str:<20} {desc_str:<35} {unit_str:<15} {extra_str:<20}")
    
    print("\n" + "-" * 100)
    print(f"Total entries across all files: {total_entries}")


def print_dictionary_sample():
    """data_dictionary í…Œì´ë¸”ì˜ ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥ (ê°„ëžµ ë²„ì „)"""
    from src.database.connection import get_db_manager
    
    db = get_db_manager()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    print("\nðŸ“– Data Dictionary Sample (first 10 entries):")
    print("-" * 80)
    
    cursor.execute("""
        SELECT source_file_name, parameter_key, parameter_desc, parameter_unit, llm_confidence
        FROM data_dictionary
        ORDER BY source_file_name, parameter_key
        LIMIT 10
    """)
    
    rows = cursor.fetchall()
    if not rows:
        print("   (No entries found)")
        return
    
    print(f"{'File':<25} {'Key':<15} {'Description':<25} {'Unit':<10} {'Conf':<5}")
    print("-" * 80)
    
    for row in rows:
        file_name, key, desc, unit, conf = row
        file_short = file_name[:24] if file_name else "?"
        key_short = key[:14] if key else "?"
        desc_short = (desc[:24] if desc else "")
        unit_short = (unit[:9] if unit else "")
        conf_str = f"{conf:.2f}" if conf else "?"
        
        print(f"{file_short:<25} {key_short:<15} {desc_short:<25} {unit_short:<10} {conf_str:<5}")
    
    # ì „ì²´ ê°œìˆ˜
    cursor.execute("SELECT COUNT(*) FROM data_dictionary")
    total = cursor.fetchone()[0]
    print("-" * 80)
    print(f"Total entries: {total}")


def main(reset: bool = False):
    """Phase 1A í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 70)
    print("ðŸ§ª Phase 1A Test: MetaData Semantic Analysis")
    print("=" * 70)
    
    # 1. DB ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”
    print("\nðŸ“¦ Initializing database schema...")
    init_catalog_schema(reset=reset)
    init_dictionary_schema(reset=reset)
    
    # 2. í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸
    test_files = get_test_files()
    if not test_files:
        print("âŒ No test files found!")
        return
    
    print(f"\nðŸ“‚ Test files ({len(test_files)}):")
    for f in test_files:
        print(f"   - {os.path.basename(f)}")
    
    # 3. ì›Œí¬í”Œë¡œìš° ë¹Œë“œ ë° ì‹¤í–‰
    print("\nðŸš€ Building Phase 1A workflow...")
    agent = build_phase1a_agent()
    
    # ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "current_dataset_id": "test_dataset",
        "input_files": test_files,
        "data_catalog": {},
        "logs": [],
        # Phase 0 ê²°ê³¼ (ë¹ˆ ìƒíƒœë¡œ ì‹œìž‘)
        "phase0_result": None,
        "phase0_file_ids": [],
        # Phase 0.5 ê²°ê³¼
        "phase05_result": None,
        "unique_columns": [],
        "unique_files": [],
        "column_batches": [],
        "file_batches": [],
        # Phase 0.7 ê²°ê³¼
        "phase07_result": None,
        "metadata_files": [],
        "data_files": [],
        # Phase 1A ê²°ê³¼
        "phase1a_result": None,
        "data_dictionary_entries": [],
    }
    
    print("\nðŸ”„ Running workflow (Phase 0 â†’ 0.5 â†’ 0.7 â†’ 1A)...")
    print("-" * 70)
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = agent.invoke(initial_state)
    
    print("-" * 70)
    
    # 4. ê²°ê³¼ ì¶œë ¥
    print("\nðŸ“Š Results:")
    
    # Phase 0.7 ê²°ê³¼
    phase07_result = result.get("phase07_result", {})
    metadata_files = result.get("metadata_files", [])
    data_files = result.get("data_files", [])
    
    print(f"\n   ðŸ·ï¸  Phase 0.7 Classification:")
    print(f"      Metadata files: {len(metadata_files)}")
    print(f"      Data files: {len(data_files)}")
    
    # Phase 1A ê²°ê³¼
    phase1a_result = result.get("phase1a_result", {})
    entries = result.get("data_dictionary_entries", [])
    
    print(f"\n   ðŸ“– Phase 1A MetaData Semantic:")
    print(f"      Processed files: {phase1a_result.get('processed_files', 0)}")
    print(f"      Total entries extracted: {phase1a_result.get('total_entries_extracted', 0)}")
    print(f"      LLM calls: {phase1a_result.get('llm_calls', 0)}")
    
    if phase1a_result.get('entries_by_file'):
        print(f"\n      Entries by file:")
        for fname, count in phase1a_result.get('entries_by_file', {}).items():
            print(f"         - {fname}: {count} entries")
    
    # 5. ë¡œê·¸ ì¶œë ¥
    print("\nðŸ“œ Logs:")
    for log in result.get("logs", []):
        print(f"   {log}")
    
    # 6. DB í…Œì´ë¸” ì¶œë ¥
    print("\n" + "=" * 100)
    print("ðŸ’¾ DATABASE TABLES")
    print("=" * 100)
    
    # file_catalog í…Œì´ë¸” ì¶œë ¥
    print_file_catalog_table()
    
    # column_metadata í…Œì´ë¸” ì¶œë ¥
    print_column_metadata_table()
    
    # data_dictionary í…Œì´ë¸” ì „ì²´ ì¶œë ¥
    print_data_dictionary_table()
    
    # 7. ìµœì¢… í†µê³„
    schema_manager = DictionarySchemaManager()
    stats = schema_manager.get_stats()
    print("\n" + "=" * 100)
    print("ðŸ“Š FINAL STATISTICS")
    print("=" * 100)
    print(f"   Total dictionary entries: {stats.get('total_entries', 0)}")
    print(f"   Entries with unit: {stats.get('entries_with_unit', 0)}")
    if stats.get('entries_by_file'):
        print(f"   Entries by file:")
        for fname, count in stats.get('entries_by_file', {}).items():
            print(f"      - {fname}: {count}")
    
    print("\n" + "=" * 100)
    print("âœ… Phase 1A Test Complete!")
    print("=" * 100)
    
    return result


if __name__ == "__main__":
    reset = "--reset" in sys.argv
    main(reset=reset)

