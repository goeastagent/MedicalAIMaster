# src/database/version_manager.py
"""
Dataset-First Architecture: í…Œì´ë¸” ë²„ì „ ê´€ë¦¬

ì¸ë±ì‹± íˆìŠ¤í† ë¦¬ë¥¼ ì¶”ì í•˜ê³  ìŠ¤í‚¤ë§ˆ ë³€ê²½ì„ ê°ì§€í•©ë‹ˆë‹¤.
"""

import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from psycopg2.extras import Json


class VersionManager:
    """í…Œì´ë¸” ë²„ì „ ê´€ë¦¬ì"""
    
    def __init__(self, db_manager):
        """
        Args:
            db_manager: DatabaseManager ì¸ìŠ¤í„´ìŠ¤
        """
        self.db = db_manager
        self._ensure_version_table()
    
    def _ensure_version_table(self):
        """ë²„ì „ ê´€ë¦¬ í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)"""
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            # ë²„ì „ ê´€ë¦¬ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS _table_versions (
                    id SERIAL PRIMARY KEY,
                    table_id VARCHAR(500) NOT NULL,
                    dataset_id VARCHAR(255) NOT NULL,
                    table_name VARCHAR(255) NOT NULL,
                    original_filename VARCHAR(255),
                    original_filepath VARCHAR(1000),
                    row_count INTEGER,
                    column_count INTEGER,
                    schema_hash VARCHAR(64),
                    version INTEGER DEFAULT 1,
                    indexed_at TIMESTAMP DEFAULT NOW(),
                    is_current BOOLEAN DEFAULT TRUE,
                    previous_version_id INTEGER REFERENCES _table_versions(id),
                    metadata JSONB DEFAULT '{}'::jsonb
                );
                
                -- ì¸ë±ìŠ¤ ìƒì„± (ì—†ìœ¼ë©´)
                CREATE INDEX IF NOT EXISTS idx_versions_table_id 
                    ON _table_versions(table_id);
                CREATE INDEX IF NOT EXISTS idx_versions_dataset 
                    ON _table_versions(dataset_id);
                CREATE INDEX IF NOT EXISTS idx_versions_current 
                    ON _table_versions(is_current) WHERE is_current = TRUE;
            """)
            
            # ë°ì´í„°ì…‹ ì •ë³´ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS _datasets (
                    dataset_id VARCHAR(255) PRIMARY KEY,
                    dataset_name VARCHAR(255),
                    source_path VARCHAR(1000),
                    version VARCHAR(50),
                    master_anchor VARCHAR(255),
                    table_count INTEGER DEFAULT 0,
                    total_rows BIGINT DEFAULT 0,
                    created_at TIMESTAMP DEFAULT NOW(),
                    last_indexed_at TIMESTAMP,
                    metadata JSONB DEFAULT '{}'::jsonb
                );
            """)
            
            conn.commit()
            print("âœ… [VersionManager] ë²„ì „ ê´€ë¦¬ í…Œì´ë¸” ì¤€ë¹„ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ [VersionManager] í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜ (ì´ë¯¸ ì¡´ì¬í•  ìˆ˜ ìˆìŒ): {e}")
            conn.rollback()
        finally:
            cursor.close()
    
    def record_indexing(
        self,
        table_id: str,
        dataset_id: str,
        table_name: str,
        original_filename: str,
        original_filepath: str,
        row_count: int,
        column_count: int,
        schema_hash: str,
        metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ì¸ë±ì‹± ê¸°ë¡ (ë²„ì „ ì¦ê°€)
        
        Returns:
            ë²„ì „ ì •ë³´ ë”•ì…”ë„ˆë¦¬ {id, version, is_schema_changed}
        """
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            # 1. ì´ì „ ë²„ì „ ì¡°íšŒ
            cursor.execute("""
                SELECT id, version, schema_hash 
                FROM _table_versions 
                WHERE table_id = %s AND is_current = TRUE
            """, (table_id,))
            
            prev_row = cursor.fetchone()
            prev_version_id = None
            new_version = 1
            is_schema_changed = False
            
            if prev_row:
                prev_version_id = prev_row[0]
                new_version = prev_row[1] + 1
                is_schema_changed = prev_row[2] != schema_hash
                
                # ì´ì „ ë²„ì „ì„ is_current = FALSEë¡œ ë³€ê²½
                cursor.execute("""
                    UPDATE _table_versions 
                    SET is_current = FALSE 
                    WHERE id = %s
                """, (prev_version_id,))
            
            # 2. ìƒˆ ë²„ì „ ì‚½ì… (metadataëŠ” Json ì–´ëŒ‘í„°ë¡œ ë³€í™˜)
            cursor.execute("""
                INSERT INTO _table_versions 
                (table_id, dataset_id, table_name, original_filename, original_filepath,
                 row_count, column_count, schema_hash, version, is_current, 
                 previous_version_id, metadata)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, TRUE, %s, %s)
                RETURNING id
            """, (
                table_id, dataset_id, table_name, original_filename, original_filepath,
                row_count, column_count, schema_hash, new_version,
                prev_version_id, 
                Json(metadata) if metadata else Json({})
            ))
            
            new_id = cursor.fetchone()[0]
            
            # 3. ë°ì´í„°ì…‹ ì •ë³´ ì—…ë°ì´íŠ¸
            self._update_dataset_stats(cursor, dataset_id)
            
            conn.commit()
            
            print(f"ğŸ“ [Version] {table_name} v{new_version} ê¸°ë¡ ì™„ë£Œ")
            if is_schema_changed:
                print(f"   âš ï¸ ìŠ¤í‚¤ë§ˆ ë³€ê²½ ê°ì§€!")
            
            return {
                "id": new_id,
                "version": new_version,
                "is_schema_changed": is_schema_changed,
                "previous_version_id": prev_version_id
            }
            
        except Exception as e:
            conn.rollback()
            print(f"âŒ [Version] ê¸°ë¡ ì‹¤íŒ¨: {e}")
            raise
        finally:
            cursor.close()
    
    def _update_dataset_stats(self, cursor, dataset_id: str):
        """ë°ì´í„°ì…‹ í†µê³„ ì—…ë°ì´íŠ¸"""
        cursor.execute("""
            INSERT INTO _datasets (dataset_id, last_indexed_at)
            VALUES (%s, NOW())
            ON CONFLICT (dataset_id) DO UPDATE SET
                last_indexed_at = NOW(),
                table_count = (
                    SELECT COUNT(DISTINCT table_name) 
                    FROM _table_versions 
                    WHERE dataset_id = %s AND is_current = TRUE
                ),
                total_rows = (
                    SELECT COALESCE(SUM(row_count), 0) 
                    FROM _table_versions 
                    WHERE dataset_id = %s AND is_current = TRUE
                )
        """, (dataset_id, dataset_id, dataset_id))
    
    def register_dataset(
        self,
        dataset_id: str,
        dataset_name: str,
        source_path: str,
        version: str,
        master_anchor: Optional[str] = None
    ):
        """ë°ì´í„°ì…‹ ì •ë³´ ë“±ë¡/ì—…ë°ì´íŠ¸"""
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                INSERT INTO _datasets 
                (dataset_id, dataset_name, source_path, version, master_anchor, created_at)
                VALUES (%s, %s, %s, %s, %s, NOW())
                ON CONFLICT (dataset_id) DO UPDATE SET
                    dataset_name = EXCLUDED.dataset_name,
                    source_path = EXCLUDED.source_path,
                    version = EXCLUDED.version,
                    master_anchor = COALESCE(EXCLUDED.master_anchor, _datasets.master_anchor)
            """, (dataset_id, dataset_name, source_path, version, master_anchor))
            
            conn.commit()
            print(f"ğŸ“ [Dataset] {dataset_name} ({dataset_id}) ë“±ë¡ë¨")
            
        except Exception as e:
            conn.rollback()
            print(f"âŒ [Dataset] ë“±ë¡ ì‹¤íŒ¨: {e}")
        finally:
            cursor.close()
    
    def update_dataset_master_anchor(self, dataset_id: str, master_anchor: str):
        """ë°ì´í„°ì…‹ì˜ Master Anchor ì—…ë°ì´íŠ¸"""
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                UPDATE _datasets 
                SET master_anchor = %s 
                WHERE dataset_id = %s
            """, (master_anchor, dataset_id))
            
            conn.commit()
            print(f"ğŸ‘‘ [Dataset] {dataset_id} Master Anchor: {master_anchor}")
            
        except Exception as e:
            conn.rollback()
            print(f"âŒ [Dataset] Master Anchor ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        finally:
            cursor.close()
    
    def get_table_history(self, table_id: str) -> List[Dict]:
        """í…Œì´ë¸” ì¸ë±ì‹± íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT id, version, row_count, column_count, schema_hash, 
                       indexed_at, is_current, previous_version_id
                FROM _table_versions 
                WHERE table_id = %s 
                ORDER BY version DESC
            """, (table_id,))
            
            columns = ['id', 'version', 'row_count', 'column_count', 'schema_hash',
                       'indexed_at', 'is_current', 'previous_version_id']
            
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
            
        finally:
            cursor.close()
    
    def get_dataset_info(self, dataset_id: str) -> Optional[Dict]:
        """ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ"""
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT dataset_id, dataset_name, source_path, version, 
                       master_anchor, table_count, total_rows, 
                       created_at, last_indexed_at
                FROM _datasets 
                WHERE dataset_id = %s
            """, (dataset_id,))
            
            row = cursor.fetchone()
            if row:
                columns = ['dataset_id', 'dataset_name', 'source_path', 'version',
                           'master_anchor', 'table_count', 'total_rows',
                           'created_at', 'last_indexed_at']
                return dict(zip(columns, row))
            return None
            
        finally:
            cursor.close()
    
    def get_all_datasets(self) -> List[Dict]:
        """ëª¨ë“  ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ"""
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT dataset_id, dataset_name, source_path, version,
                       master_anchor, table_count, total_rows,
                       created_at, last_indexed_at
                FROM _datasets
                ORDER BY created_at DESC
            """)
            
            columns = ['dataset_id', 'dataset_name', 'source_path', 'version',
                       'master_anchor', 'table_count', 'total_rows',
                       'created_at', 'last_indexed_at']
            
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
            
        finally:
            cursor.close()
    
    def get_current_tables(self, dataset_id: Optional[str] = None) -> List[Dict]:
        """í˜„ì¬ ë²„ì „ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        try:
            query = """
                SELECT table_id, dataset_id, table_name, original_filename,
                       row_count, column_count, version, indexed_at
                FROM _table_versions
                WHERE is_current = TRUE
            """
            params = []
            
            if dataset_id:
                query += " AND dataset_id = %s"
                params.append(dataset_id)
            
            query += " ORDER BY indexed_at DESC"
            
            cursor.execute(query, params)
            
            columns = ['table_id', 'dataset_id', 'table_name', 'original_filename',
                       'row_count', 'column_count', 'version', 'indexed_at']
            
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
            
        finally:
            cursor.close()


# ì „ì—­ ì‹±ê¸€í†¤
_global_version_manager = None

def get_version_manager(db_manager=None):
    """ì „ì—­ VersionManager ë°˜í™˜"""
    global _global_version_manager
    
    if _global_version_manager is None:
        if db_manager is None:
            from database.connection import get_db_manager
            db_manager = get_db_manager()
        _global_version_manager = VersionManager(db_manager)
    
    return _global_version_manager

