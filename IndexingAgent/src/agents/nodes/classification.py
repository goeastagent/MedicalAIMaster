# src/agents/nodes/classification.py
"""
Phase 4: File Classification Node

íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
- metadata: ë°ì´í„° ì‚¬ì „, íŒŒë¼ë¯¸í„° ì •ì˜ íŒŒì¼ (clinical_parameters.csv ë“±)
- data: ì‹¤ì œ ì¸¡ì •/ê¸°ë¡ ë°ì´í„° íŒŒì¼ (clinical_data.csv ë“±)

âœ… LLM ì‚¬ìš©: is_metadata íŒë‹¨
"""

import json
from typing import Dict, Any, List, Optional
from datetime import datetime

from src.agents.state import AgentState
from src.database import FileRepository
from src.config import Phase5Config, LLMConfig
from src.agents.models.llm_responses import (
    FileClassificationItem,
    FileClassificationResponse,
    FileClassificationResult,
)


from src.utils.llm_client import get_llm_client


# Repository ì¸ìŠ¤í„´ìŠ¤ (ëª¨ë“ˆ ë ˆë²¨ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±)
_file_repo = None

def _get_file_repo() -> FileRepository:
    """FileRepository ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _file_repo
    if _file_repo is None:
        _file_repo = FileRepository()
    return _file_repo


# =============================================================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# =============================================================================

FILE_CLASSIFICATION_PROMPT = """You are a Medical Data Expert specializing in healthcare informatics.

[Task]
Classify each file as "metadata" or "data":

**metadata** files:
- Data dictionaries, codebooks, parameter definitions, lookup tables
- Typically contain columns like: Parameter, Description, Unit, Code, Category
- Values are mostly text descriptions, definitions, or codes
- Purpose: Define or describe what data means
- Examples: clinical_parameters.csv, lab_parameters.csv, track_names.csv

**data** files:
- Actual measurements, patient records, lab results, vital signs
- Typically contain columns like: patient_id, timestamp, measured values
- Values are mostly numbers, IDs, dates, measurements
- Purpose: Store actual recorded data
- Examples: clinical_data.csv, lab_data.csv, vitals.csv

[Files to Classify]
{files_info}

[Output Format]
Return ONLY valid JSON (no markdown, no explanation):
{{
  "classifications": [
    {{
      "file_name": "example.csv",
      "is_metadata": true,
      "confidence": 0.95,
      "reasoning": "Contains Parameter, Description, Unit columns typical of a data dictionary"
    }}
  ]
}}
"""


# =============================================================================
# íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ (Repository ì‚¬ìš©)
# =============================================================================

def _get_files_info_for_classification(file_ids: List[str]) -> List[Dict[str, Any]]:
    """
    DBì—ì„œ ì—¬ëŸ¬ íŒŒì¼ ì •ë³´ ì¡°íšŒ (ë¶„ë¥˜ìš©) - Repository ì‚¬ìš©
    
    Args:
        file_ids: ì¡°íšŒí•  íŒŒì¼ ID ëª©ë¡
    
    Returns:
        [
            {
                "file_id": str,
                "file_name": str,
                "file_path": str,
                "row_count": int,
                "column_count": int,
                "columns": [
                    {
                        "name": str,
                        "dtype": str,
                        "column_type": str,
                        "unique_values": List[str],
                        "n_unique": int
                    }
                ]
            }
        ]
    """
    file_repo = _get_file_repo()
    
    try:
        return file_repo.get_files_with_classification_info(file_ids)
    except Exception as e:
        print(f"   âŒ Error getting files info: {e}")
        return []


def _build_files_info_text(file_infos: List[Dict[str, Any]]) -> str:
    """
    íŒŒì¼ ì •ë³´ë¥¼ LLM í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    ì˜ˆì‹œ ì¶œë ¥:
    1. "clinical_parameters.csv" [tabular, 4 columns, 82 rows]
       Columns: Parameter, Data Source, Description, Unit
       Sample values per column:
       - Parameter: ["age", "sex", "height", "weight", "bmi"]
       - Description: ["Age", "Sex", "Height", "Weight", "Body mass index"]
       - Unit: ["years", "M/F", "cm", "kg", "kg/m2"]
    """
    lines = []
    
    for i, info in enumerate(file_infos, 1):
        file_name = info.get('file_name', '?')
        col_count = info.get('column_count', 0)
        row_count = info.get('row_count', 0)
        columns = info.get('columns', [])
        
        # íŒŒì¼ í—¤ë”
        lines.append(f'{i}. "{file_name}" [tabular, {col_count} columns, {row_count} rows]')
        
        # ì»¬ëŸ¼ëª… ëª©ë¡
        col_names = [c['name'] for c in columns]
        lines.append(f"   Columns: {', '.join(col_names[:15])}")
        if len(col_names) > 15:
            lines.append(f"            ... and {len(col_names) - 15} more columns")
        
        # ì»¬ëŸ¼ë³„ ìƒ˜í”Œ ê°’ (ìµœëŒ€ 5ê°œ ì»¬ëŸ¼ë§Œ)
        lines.append("   Sample values per column:")
        for col in columns[:5]:
            col_name = col['name']
            unique_vals = col.get('unique_values', [])
            # ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ìµœëŒ€ 5ê°œë§Œ
            vals_str = [str(v)[:30] for v in unique_vals[:5]]
            lines.append(f"   - {col_name}: {vals_str}")
        
        if len(columns) > 5:
            lines.append(f"   ... and {len(columns) - 5} more columns")
        
        lines.append("")  # ë¹ˆ ì¤„
    
    return "\n".join(lines)


# =============================================================================
# LLM í˜¸ì¶œ
# =============================================================================

def _call_llm_for_classification(
    file_infos: List[Dict[str, Any]]
) -> List[FileClassificationItem]:
    """
    LLMì„ í˜¸ì¶œí•˜ì—¬ íŒŒì¼ ë¶„ë¥˜
    
    Returns:
        List[FileClassificationItem]
    """
    llm = get_llm_client()
    
    files_info_text = _build_files_info_text(file_infos)
    prompt = FILE_CLASSIFICATION_PROMPT.format(files_info=files_info_text)
    
    try:
        data = llm.ask_json(prompt, max_tokens=LLMConfig.MAX_TOKENS)
        
        if data.get("error"):
            print(f"   âŒ LLM returned error: {data.get('error')}")
            return []
        
        classifications = []
        for item in data.get('classifications', []):
            try:
                classification = FileClassificationItem(**item)
                classifications.append(classification)
            except Exception as e:
                print(f"   âš ï¸ Failed to parse classification for {item.get('file_name', '?')}: {e}")
        
        return classifications
        
    except Exception as e:
        print(f"   âŒ LLM call error: {e}")
        return []


# =============================================================================
# DB ì—…ë°ì´íŠ¸ (Repository ì‚¬ìš©)
# =============================================================================

def _update_file_is_metadata(file_name: str, is_metadata: bool, confidence: float):
    """file_catalog.is_metadata ì—…ë°ì´íŠ¸ - Repository ì‚¬ìš©"""
    file_repo = _get_file_repo()
    return file_repo.update_is_metadata(file_name, is_metadata, confidence)


# =============================================================================
# LangGraph Node Function
# =============================================================================

def phase4_classification_node(state: AgentState) -> Dict[str, Any]:
    """
    Phase 4: íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜
    
    ì…ë ¥: state.phase2_file_ids (Phase 2ì—ì„œ ì²˜ë¦¬ëœ íŒŒì¼ë“¤)
    
    ì²˜ë¦¬:
    1. ê° íŒŒì¼ì˜ ì •ë³´ ìˆ˜ì§‘ (ì»¬ëŸ¼ëª…, unique values)
    2. LLM í˜¸ì¶œ â†’ is_metadata íŒë‹¨
    3. file_catalog.is_metadata ì—…ë°ì´íŠ¸
    
    ì¶œë ¥:
    - phase4_result: ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½
    - metadata_files: is_metadata=true íŒŒì¼ ê²½ë¡œ ëª©ë¡
    - data_files: is_metadata=false íŒŒì¼ ê²½ë¡œ ëª©ë¡
    """
    print("\n" + "=" * 60)
    print("ğŸ·ï¸  Phase 4: File Classification (metadata vs data)")
    print("=" * 60)
    
    started_at = datetime.now()
    
    # Phase 2ì—ì„œ ì²˜ë¦¬ëœ íŒŒì¼ IDë“¤
    file_ids = state.get("phase2_file_ids", [])
    
    if not file_ids:
        print("   âš ï¸ No files to classify")
        return {
            "phase4_result": {
                "total_files": 0,
                "metadata_files": [],
                "data_files": [],
                "error": "No files to classify"
            },
            "metadata_files": [],
            "data_files": [],
            "logs": ["âš ï¸ [Phase 4] No files to classify"]
        }
    
    print(f"   ğŸ“‚ Files to classify: {len(file_ids)}")
    
    # 1. íŒŒì¼ ì •ë³´ ìˆ˜ì§‘ (Repository ì‚¬ìš© - ì¼ê´„ ì¡°íšŒ)
    print("\n   ğŸ“Š Collecting file information...")
    file_infos = _get_files_info_for_classification(file_ids)
    
    # file_name â†’ file_path ë§¤í•‘ ìƒì„±
    file_id_to_path = {info['file_name']: info['file_path'] for info in file_infos}
    
    for info in file_infos:
        print(f"      âœ… {info['file_name']} ({info['column_count']} cols, {info['row_count']} rows)")
    
    if len(file_infos) < len(file_ids):
        print(f"      âš ï¸ Failed to get info for {len(file_ids) - len(file_infos)} files")
    
    if not file_infos:
        print("   âŒ No file info collected")
        return {
            "phase4_result": {"error": "No file info collected"},
            "metadata_files": [],
            "data_files": [],
            "logs": ["âŒ [Phase 4] No file info collected"]
        }
    
    # 2. LLM í˜¸ì¶œ
    print(f"\n   ğŸ¤– Calling LLM for classification...")
    classifications = _call_llm_for_classification(file_infos)
    
    if not classifications:
        print("   âŒ LLM classification failed")
        return {
            "phase4_result": {"error": "LLM classification failed"},
            "metadata_files": [],
            "data_files": [],
            "logs": ["âŒ [Phase 4] LLM classification failed"]
        }
    
    # 3. ê²°ê³¼ ì²˜ë¦¬ ë° DB ì—…ë°ì´íŠ¸
    print(f"\n   ğŸ“ Processing {len(classifications)} classifications...")
    
    metadata_files = []
    data_files = []
    classifications_dict = {}
    
    for clf in classifications:
        file_name = clf.file_name
        is_metadata = clf.is_metadata
        confidence = clf.confidence
        reasoning = clf.reasoning
        
        # file_path ì°¾ê¸°
        file_path = file_id_to_path.get(file_name, file_name)
        
        # DB ì—…ë°ì´íŠ¸
        updated = _update_file_is_metadata(file_name, is_metadata, confidence)
        
        # ê²°ê³¼ ë¶„ë¥˜
        if is_metadata:
            metadata_files.append(file_path)
            marker = "ğŸ“‹ metadata"
        else:
            data_files.append(file_path)
            marker = "ğŸ“Š data"
        
        print(f"      {marker}: {file_name} (conf={confidence:.2f})")
        
        classifications_dict[file_name] = {
            "file_path": file_path,
            "is_metadata": is_metadata,
            "confidence": confidence,
            "reasoning": reasoning
        }
    
    # 4. ê²°ê³¼ ìš”ì•½
    completed_at = datetime.now()
    duration = (completed_at - started_at).total_seconds()
    
    result = FileClassificationResult(
        total_files=len(file_infos),
        metadata_files=metadata_files,
        data_files=data_files,
        classifications=classifications_dict,
        llm_calls=1,
        started_at=started_at.isoformat(),
        completed_at=completed_at.isoformat()
    )
    
    print(f"\nâœ… Phase 4 Complete!")
    print(f"   ğŸ“‹ Metadata files: {len(metadata_files)}")
    for f in metadata_files:
        print(f"      - {f.split('/')[-1]}")
    print(f"   ğŸ“Š Data files: {len(data_files)}")
    for f in data_files:
        print(f"      - {f.split('/')[-1]}")
    print(f"   â±ï¸  Duration: {duration:.1f}s")
    print("=" * 60 + "\n")
    
    return {
        "phase4_result": result.model_dump(),
        "metadata_files": metadata_files,
        "data_files": data_files,
        "logs": [
            f"ğŸ·ï¸ [Phase 4] Classified {len(file_infos)} files: "
            f"{len(metadata_files)} metadata, {len(data_files)} data"
        ]
    }


# =============================================================================
# í¸ì˜ í•¨ìˆ˜
# =============================================================================

def run_classification_standalone(file_ids: List[str] = None) -> Dict[str, Any]:
    """
    Phase 4 ë…ë¦½ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
    
    Args:
        file_ids: ë¶„ë¥˜í•  íŒŒì¼ ID ëª©ë¡ (Noneì´ë©´ DBì—ì„œ ëª¨ë“  íŒŒì¼ ì¡°íšŒ)
    
    Returns:
        ë¶„ë¥˜ ê²°ê³¼
    """
    if file_ids is None:
        # DBì—ì„œ ëª¨ë“  íŒŒì¼ ID ì¡°íšŒ (Repository ì‚¬ìš©)
        file_repo = _get_file_repo()
        file_ids = file_repo.get_all_file_ids()
    
    # State ì‹œë®¬ë ˆì´ì…˜
    state = {
        "phase2_file_ids": file_ids
    }
    
    return phase4_classification_node(state)


# =============================================================================
# Class-based Node (for NodeRegistry)
# =============================================================================

from ..base import BaseNode, LLMMixin, DatabaseMixin
from ..registry import register_node


@register_node
class FileClassificationNode(BaseNode, LLMMixin, DatabaseMixin):
    """
    File Classification Node (LLM-based)
    
    íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    - metadata: ë°ì´í„° ì‚¬ì „, íŒŒë¼ë¯¸í„° ì •ì˜ íŒŒì¼
    - data: ì‹¤ì œ ì¸¡ì •/ê¸°ë¡ ë°ì´í„° íŒŒì¼
    """
    
    name = "file_classification"
    description = "íŒŒì¼ ë¶„ë¥˜ (metadata vs data)"
    order = 400
    requires_llm = True
    
    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ì¡´ í•¨ìˆ˜ ìœ„ì„"""
        return phase4_classification_node(state)