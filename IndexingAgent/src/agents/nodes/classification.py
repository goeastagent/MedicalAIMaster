# src/agents/nodes/classification.py
"""
Phase 0.7: File Classification Node

íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
- metadata: ë°ì´í„° ì‚¬ì „, íŒŒë¼ë¯¸í„° ì •ì˜ íŒŒì¼ (clinical_parameters.csv ë“±)
- data: ì‹¤ì œ ì¸¡ì •/ê¸°ë¡ ë°ì´í„° íŒŒì¼ (clinical_data.csv ë“±)

âœ… LLM ì‚¬ìš©: is_metadata íŒë‹¨
"""

import json
from typing import Dict, Any, List, Optional
from datetime import datetime

from src.agents.state import AgentState
from src.database.connection import get_db_manager
from src.config import Phase5Config, LLMConfig
from src.agents.models.llm_responses import (
    FileClassificationItem,
    FileClassificationResponse,
    FileClassificationResult,
)


from src.utils.llm_client import get_llm_client


# =============================================================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# =============================================================================

FILE_CLASSIFICATION_PROMPT = """You are a Medical Data Expert specializing in healthcare informatics.

[Task]
Classify each file as "metadata" or "data":

**metadata** files:
- Data dictionaries, codebooks, parameter definitions, lookup tables
- Typically contain columns like: Parameter, Description, Unit, Code, Category
- Values are mostly text descriptions, definitions, or codes
- Purpose: Define or describe what data means
- Examples: clinical_parameters.csv, lab_parameters.csv, track_names.csv

**data** files:
- Actual measurements, patient records, lab results, vital signs
- Typically contain columns like: patient_id, timestamp, measured values
- Values are mostly numbers, IDs, dates, measurements
- Purpose: Store actual recorded data
- Examples: clinical_data.csv, lab_data.csv, vitals.csv

[Files to Classify]
{files_info}

[Output Format]
Return ONLY valid JSON (no markdown, no explanation):
{{
  "classifications": [
    {{
      "file_name": "example.csv",
      "is_metadata": true,
      "confidence": 0.95,
      "reasoning": "Contains Parameter, Description, Unit columns typical of a data dictionary"
    }}
  ]
}}
"""


# =============================================================================
# íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
# =============================================================================

def _get_file_info_for_classification(file_id: str) -> Optional[Dict[str, Any]]:
    """
    DBì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ (ë¶„ë¥˜ìš©)
    
    Returns:
        {
            "file_id": str,
            "file_name": str,
            "file_path": str,
            "row_count": int,
            "column_count": int,
            "columns": [
                {
                    "name": str,
                    "dtype": str,
                    "unique_values": List[str],  # ìƒ˜í”Œ
                    "n_unique": int
                }
            ]
        }
    """
    db = get_db_manager()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    try:
        # íŒŒì¼ ê¸°ë³¸ ì •ë³´
        cursor.execute("""
            SELECT file_id, file_name, file_path, file_metadata, raw_stats
            FROM file_catalog
            WHERE file_id = %s
        """, (file_id,))
        
        row = cursor.fetchone()
        if not row:
            return None
        
        file_id, file_name, file_path, file_metadata, raw_stats = row
        
        # row_count, column_count ì¶”ì¶œ
        metadata = file_metadata if isinstance(file_metadata, dict) else {}
        row_count = metadata.get('row_count', 0)
        column_count = metadata.get('column_count', 0)
        
        # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
        cursor.execute("""
            SELECT original_name, data_type, column_type, value_distribution
            FROM column_metadata
            WHERE file_id = %s
            ORDER BY col_id
        """, (file_id,))
        
        columns = []
        for col_row in cursor.fetchall():
            col_name, dtype, col_type, value_dist = col_row
            
            # value_distributionì—ì„œ unique_values ì¶”ì¶œ
            dist = value_dist if isinstance(value_dist, dict) else {}
            unique_values = dist.get('unique_values', [])
            samples = dist.get('samples', [])
            
            # unique_valuesê°€ ì—†ìœ¼ë©´ samples ì‚¬ìš©
            if not unique_values and samples:
                unique_values = samples
            
            # ìµœëŒ€ 10ê°œë§Œ
            unique_values = unique_values[:10] if unique_values else []
            
            columns.append({
                "name": col_name,
                "dtype": dtype or "unknown",
                "column_type": col_type or "unknown",
                "unique_values": unique_values,
                "n_unique": len(unique_values)
            })
        
        return {
            "file_id": str(file_id),
            "file_name": file_name,
            "file_path": file_path,
            "row_count": row_count,
            "column_count": column_count or len(columns),
            "columns": columns
        }
        
    except Exception as e:
        print(f"   âŒ Error getting file info: {e}")
        return None


def _build_files_info_text(file_infos: List[Dict[str, Any]]) -> str:
    """
    íŒŒì¼ ì •ë³´ë¥¼ LLM í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    ì˜ˆì‹œ ì¶œë ¥:
    1. "clinical_parameters.csv" [tabular, 4 columns, 82 rows]
       Columns: Parameter, Data Source, Description, Unit
       Sample values per column:
       - Parameter: ["age", "sex", "height", "weight", "bmi"]
       - Description: ["Age", "Sex", "Height", "Weight", "Body mass index"]
       - Unit: ["years", "M/F", "cm", "kg", "kg/m2"]
    """
    lines = []
    
    for i, info in enumerate(file_infos, 1):
        file_name = info.get('file_name', '?')
        col_count = info.get('column_count', 0)
        row_count = info.get('row_count', 0)
        columns = info.get('columns', [])
        
        # íŒŒì¼ í—¤ë”
        lines.append(f'{i}. "{file_name}" [tabular, {col_count} columns, {row_count} rows]')
        
        # ì»¬ëŸ¼ëª… ëª©ë¡
        col_names = [c['name'] for c in columns]
        lines.append(f"   Columns: {', '.join(col_names[:15])}")
        if len(col_names) > 15:
            lines.append(f"            ... and {len(col_names) - 15} more columns")
        
        # ì»¬ëŸ¼ë³„ ìƒ˜í”Œ ê°’ (ìµœëŒ€ 5ê°œ ì»¬ëŸ¼ë§Œ)
        lines.append("   Sample values per column:")
        for col in columns[:5]:
            col_name = col['name']
            unique_vals = col.get('unique_values', [])
            # ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ìµœëŒ€ 5ê°œë§Œ
            vals_str = [str(v)[:30] for v in unique_vals[:5]]
            lines.append(f"   - {col_name}: {vals_str}")
        
        if len(columns) > 5:
            lines.append(f"   ... and {len(columns) - 5} more columns")
        
        lines.append("")  # ë¹ˆ ì¤„
    
    return "\n".join(lines)


# =============================================================================
# LLM í˜¸ì¶œ
# =============================================================================

def _call_llm_for_classification(
    file_infos: List[Dict[str, Any]]
) -> List[FileClassificationItem]:
    """
    LLMì„ í˜¸ì¶œí•˜ì—¬ íŒŒì¼ ë¶„ë¥˜
    
    Returns:
        List[FileClassificationItem]
    """
    llm = get_llm_client()
    
    files_info_text = _build_files_info_text(file_infos)
    prompt = FILE_CLASSIFICATION_PROMPT.format(files_info=files_info_text)
    
    try:
        data = llm.ask_json(prompt, max_tokens=LLMConfig.MAX_TOKENS)
        
        if data.get("error"):
            print(f"   âŒ LLM returned error: {data.get('error')}")
            return []
        
        classifications = []
        for item in data.get('classifications', []):
            try:
                classification = FileClassificationItem(**item)
                classifications.append(classification)
            except Exception as e:
                print(f"   âš ï¸ Failed to parse classification for {item.get('file_name', '?')}: {e}")
        
        return classifications
        
    except Exception as e:
        print(f"   âŒ LLM call error: {e}")
        return []


# =============================================================================
# DB ì—…ë°ì´íŠ¸
# =============================================================================

def _update_file_is_metadata(file_name: str, is_metadata: bool, confidence: float):
    """file_catalog.is_metadata ì—…ë°ì´íŠ¸"""
    db = get_db_manager()
    conn = db.get_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute("""
            UPDATE file_catalog
            SET is_metadata = %s, llm_confidence = %s, llm_analyzed_at = NOW()
            WHERE file_name = %s
        """, (is_metadata, confidence, file_name))
        
        conn.commit()
        return cursor.rowcount
        
    except Exception as e:
        conn.rollback()
        print(f"   âŒ Error updating is_metadata: {e}")
        return 0


# =============================================================================
# LangGraph Node Function
# =============================================================================

def phase4_classification_node(state: AgentState) -> Dict[str, Any]:
    """
    Phase 0.7: íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜
    
    ì…ë ¥: state.phase0_file_ids (Phase 0ì—ì„œ ì²˜ë¦¬ëœ íŒŒì¼ë“¤)
    
    ì²˜ë¦¬:
    1. ê° íŒŒì¼ì˜ ì •ë³´ ìˆ˜ì§‘ (ì»¬ëŸ¼ëª…, unique values)
    2. LLM í˜¸ì¶œ â†’ is_metadata íŒë‹¨
    3. file_catalog.is_metadata ì—…ë°ì´íŠ¸
    
    ì¶œë ¥:
    - phase07_result: ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½
    - metadata_files: is_metadata=true íŒŒì¼ ê²½ë¡œ ëª©ë¡
    - data_files: is_metadata=false íŒŒì¼ ê²½ë¡œ ëª©ë¡
    """
    print("\n" + "=" * 60)
    print("ğŸ·ï¸  Phase 4: File Classification (metadata vs data)")
    print("=" * 60)
    
    started_at = datetime.now()
    
    # Phase 2ì—ì„œ ì²˜ë¦¬ëœ íŒŒì¼ IDë“¤
    file_ids = state.get("phase2_file_ids", [])
    
    if not file_ids:
        print("   âš ï¸ No files to classify")
        return {
            "phase4_result": {
                "total_files": 0,
                "metadata_files": [],
                "data_files": [],
                "error": "No files to classify"
            },
            "metadata_files": [],
            "data_files": [],
            "logs": ["âš ï¸ [Phase 4] No files to classify"]
        }
    
    print(f"   ğŸ“‚ Files to classify: {len(file_ids)}")
    
    # 1. íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
    print("\n   ğŸ“Š Collecting file information...")
    file_infos = []
    file_id_to_path = {}  # file_id â†’ file_path ë§¤í•‘
    
    for file_id in file_ids:
        info = _get_file_info_for_classification(file_id)
        if info:
            file_infos.append(info)
            file_id_to_path[info['file_name']] = info['file_path']
            print(f"      âœ… {info['file_name']} ({info['column_count']} cols, {info['row_count']} rows)")
        else:
            print(f"      âŒ Failed to get info for file_id: {file_id[:8]}...")
    
    if not file_infos:
        print("   âŒ No file info collected")
        return {
            "phase4_result": {"error": "No file info collected"},
            "metadata_files": [],
            "data_files": [],
            "logs": ["âŒ [Phase 4] No file info collected"]
        }
    
    # 2. LLM í˜¸ì¶œ
    print(f"\n   ğŸ¤– Calling LLM for classification...")
    classifications = _call_llm_for_classification(file_infos)
    
    if not classifications:
        print("   âŒ LLM classification failed")
        return {
            "phase4_result": {"error": "LLM classification failed"},
            "metadata_files": [],
            "data_files": [],
            "logs": ["âŒ [Phase 4] LLM classification failed"]
        }
    
    # 3. ê²°ê³¼ ì²˜ë¦¬ ë° DB ì—…ë°ì´íŠ¸
    print(f"\n   ğŸ“ Processing {len(classifications)} classifications...")
    
    metadata_files = []
    data_files = []
    classifications_dict = {}
    
    for clf in classifications:
        file_name = clf.file_name
        is_metadata = clf.is_metadata
        confidence = clf.confidence
        reasoning = clf.reasoning
        
        # file_path ì°¾ê¸°
        file_path = file_id_to_path.get(file_name, file_name)
        
        # DB ì—…ë°ì´íŠ¸
        updated = _update_file_is_metadata(file_name, is_metadata, confidence)
        
        # ê²°ê³¼ ë¶„ë¥˜
        if is_metadata:
            metadata_files.append(file_path)
            marker = "ğŸ“‹ metadata"
        else:
            data_files.append(file_path)
            marker = "ğŸ“Š data"
        
        print(f"      {marker}: {file_name} (conf={confidence:.2f})")
        
        classifications_dict[file_name] = {
            "file_path": file_path,
            "is_metadata": is_metadata,
            "confidence": confidence,
            "reasoning": reasoning
        }
    
    # 4. ê²°ê³¼ ìš”ì•½
    completed_at = datetime.now()
    duration = (completed_at - started_at).total_seconds()
    
    result = FileClassificationResult(
        total_files=len(file_infos),
        metadata_files=metadata_files,
        data_files=data_files,
        classifications=classifications_dict,
        llm_calls=1,
        started_at=started_at.isoformat(),
        completed_at=completed_at.isoformat()
    )
    
    print(f"\nâœ… Phase 4 Complete!")
    print(f"   ğŸ“‹ Metadata files: {len(metadata_files)}")
    for f in metadata_files:
        print(f"      - {f.split('/')[-1]}")
    print(f"   ğŸ“Š Data files: {len(data_files)}")
    for f in data_files:
        print(f"      - {f.split('/')[-1]}")
    print(f"   â±ï¸  Duration: {duration:.1f}s")
    print("=" * 60 + "\n")
    
    return {
        "phase4_result": result.model_dump(),
        "metadata_files": metadata_files,
        "data_files": data_files,
        "logs": [
            f"ğŸ·ï¸ [Phase 4] Classified {len(file_infos)} files: "
            f"{len(metadata_files)} metadata, {len(data_files)} data"
        ]
    }


# =============================================================================
# í¸ì˜ í•¨ìˆ˜
# =============================================================================

def run_classification_standalone(file_ids: List[str] = None) -> Dict[str, Any]:
    """
    Phase 4 ë…ë¦½ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
    
    Args:
        file_ids: ë¶„ë¥˜í•  íŒŒì¼ ID ëª©ë¡ (Noneì´ë©´ DBì—ì„œ ëª¨ë“  íŒŒì¼ ì¡°íšŒ)
    
    Returns:
        ë¶„ë¥˜ ê²°ê³¼
    """
    if file_ids is None:
        # DBì—ì„œ ëª¨ë“  íŒŒì¼ ID ì¡°íšŒ
        db = get_db_manager()
        conn = db.get_connection()
        cursor = conn.cursor()
        
        cursor.execute("SELECT file_id FROM file_catalog ORDER BY file_name")
        file_ids = [str(row[0]) for row in cursor.fetchall()]
    
    # State ì‹œë®¬ë ˆì´ì…˜
    state = {
        "phase2_file_ids": file_ids
    }
    
    return phase4_classification_node(state)