# src/agents/nodes/parameter_semantic/node.py
"""
Parameter Semantic Analysis Node

parameter í…Œì´ë¸”ì˜ ê° parameterë¥¼ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ 
data_dictionaryì™€ ì—°ê²°í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- LLMì„ ì‚¬ìš©í•´ ê° parameterì˜ semantic_name, unit, description ì¶”ë¡ 
- data_dictionaryì˜ parameter_keyì™€ ë§¤ì¹­ ì‹œë„
- parameter í…Œì´ë¸”ì— ê²°ê³¼ ì €ì¥ (dict_entry_id, dict_match_status)
- parameter ìˆ˜ê°€ ë§ìœ¼ë©´ ë°°ì¹˜ë¡œ ë¶„í• í•˜ì—¬ LLM í˜¸ì¶œ

Workflow:
1. column_classificationì—ì„œ ìƒì„±ëœ parameter ì¡°íšŒ (semantic ë¯¸ë¶„ì„)
2. LLMìœ¼ë¡œ ê° parameter ë¶„ì„
3. parameter í…Œì´ë¸” ì—…ë°ì´íŠ¸
"""

import json
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

from ...state import AgentState
from ...models.llm_responses import (
    ParameterSemanticResult,
    ParameterSemanticResponse,
)
from ...base import BaseNode, LLMMixin, DatabaseMixin
from ...registry import register_node
from src.database import (
    FileRepository,
    DictionaryRepository,
)
from src.database.repositories import ParameterRepository
from src.config import DataSemanticConfig, LLMConfig
from .prompts import ParameterSemanticPrompt


@register_node
class ParameterSemanticNode(BaseNode, LLMMixin, DatabaseMixin):
    """
    Parameter Semantic Analysis Node (LLM-based)
    
    parameter í…Œì´ë¸”ì˜ ê° parameterë¥¼ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ 
    data_dictionaryì™€ ì—°ê²°í•©ë‹ˆë‹¤.
    
    Input State:
        - data_files: ë¶„ì„í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ ëª©ë¡
        - (DB) data_dictionary: ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±ëœ parameter definitions
        - (DB) parameter: column_classificationì—ì„œ ìƒì„±ëœ parameter ëª©ë¡
    
    Output State:
        - parameter_semantic_result: ë¶„ì„ ê²°ê³¼ ìš”ì•½
        - parameter_semantic_entries: ë¶„ì„ëœ parameter ì •ë³´ ë¦¬ìŠ¤íŠ¸
        - (DB) parameter í…Œì´ë¸” ì—…ë°ì´íŠ¸: semantic_name, unit, dict_entry_id ë“±
    """
    
    name = "parameter_semantic"
    description = "Parameter ì˜ë¯¸ ë¶„ì„ ë° dictionary ë§¤ì¹­"
    order = 600
    requires_llm = True
    
    # í”„ë¡¬í”„íŠ¸ í´ë˜ìŠ¤ ì—°ê²°
    prompt_class = ParameterSemanticPrompt
    
    def __init__(self):
        super().__init__()
        self._file_repo: Optional[FileRepository] = None
        self._param_repo: Optional[ParameterRepository] = None
        self._dict_repo: Optional[DictionaryRepository] = None
    
    def _get_repositories(self) -> Tuple[FileRepository, ParameterRepository, DictionaryRepository]:
        """Repository ì¸ìŠ¤í„´ìŠ¤ë“¤ ë°˜í™˜ (lazy initialization)"""
        if self._file_repo is None:
            self._file_repo = FileRepository()
            self._param_repo = ParameterRepository()
            self._dict_repo = DictionaryRepository()
        return self._file_repo, self._param_repo, self._dict_repo
    
    def _load_dictionary_with_context(self) -> Tuple[List[Dict], str, str, Dict[str, str]]:
        """
        data_dictionary ë¡œë“œ + LLM context ìƒì„±
        
        Returns:
            (dictionary_entries, dict_keys_list, dict_context, key_to_id_map)
        """
        _, _, dict_repo = self._get_repositories()
        
        dictionary = dict_repo.get_all_entries()
        dict_keys_list, dict_context, key_to_id_map = dict_repo.build_llm_context()
        
        return dictionary, dict_keys_list, dict_context, key_to_id_map
    
    def _get_parameters_to_analyze(self, data_files: List[str]) -> List[Dict]:
        """
        semantic ë¶„ì„ì´ í•„ìš”í•œ parameter ì¡°íšŒ (íŒŒì¼ ë ˆë²¨ + ê·¸ë£¹ ë ˆë²¨)
        
        Args:
            data_files: ë°ì´í„° íŒŒì¼ ê²½ë¡œ ëª©ë¡
        
        Returns:
            Parameter ì •ë³´ ë¦¬ìŠ¤íŠ¸ (íŒŒì¼ ë ˆë²¨ + ê·¸ë£¹ ë ˆë²¨ í•©ì‚°)
        """
        _, param_repo, _ = self._get_repositories()
        file_repo, _, _ = self._get_repositories()
        
        all_parameters = []
        
        try:
            # 1. íŒŒì¼ ë ˆë²¨ íŒŒë¼ë¯¸í„° ì¡°íšŒ
            files_data = file_repo.get_files_by_paths(data_files)
            file_ids = [f['file_id'] for f in files_data]
            
            if file_ids:
                file_params = param_repo.get_parameters_without_semantic(file_ids)
                all_parameters.extend(file_params)
            
            # 2. ê·¸ë£¹ ë ˆë²¨ íŒŒë¼ë¯¸í„° ì¡°íšŒ (file_id=NULL, group_id!=NULL)
            group_params = param_repo.get_group_parameters_without_semantic()
            if group_params:
                all_parameters.extend(group_params)
                self.log(f"   Including {len(group_params)} group-level parameters", indent=0)
            
            return all_parameters
            
        except Exception as e:
            self.log(f"âš ï¸ Error loading parameters: {e}", indent=1)
            return []
    
    def _build_parameters_info(self, parameters: List[Dict]) -> str:
        """
        Parameter ì •ë³´ë¥¼ LLM context ë¬¸ìì—´ë¡œ ë³€í™˜
        
        Args:
            parameters: parameter ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            í¬ë§·ëœ parameter ì •ë³´ ë¬¸ìì—´
        """
        config = DataSemanticConfig
        lines = []
        
        for param in parameters:
            param_key = param.get('param_key', '')
            source_type = param.get('source_type', '')
            value_stats = param.get('value_stats', {}) or {}
            
            # ê¸°ë³¸ ì •ë³´
            line = f"- {param_key} (source: {source_type})"
            details = []
            
            # í†µê³„ ì •ë³´ (ìˆìœ¼ë©´)
            if value_stats:
                if 'min' in value_stats and 'max' in value_stats:
                    details.append(f"range: [{value_stats['min']}, {value_stats['max']}]")
                if 'mean' in value_stats:
                    details.append(f"mean: {value_stats['mean']:.2f}")
                if 'unique_values' in value_stats:
                    unique_vals = value_stats['unique_values']
                    max_show = config.MAX_UNIQUE_VALUES_DISPLAY
                    if len(unique_vals) <= max_show:
                        details.append(f"values: {unique_vals}")
                    else:
                        details.append(f"values ({len(unique_vals)} unique): {unique_vals[:max_show]}...")
            
            # extracted_unit (ìˆìœ¼ë©´)
            if param.get('extracted_unit'):
                details.append(f"extracted_unit: {param['extracted_unit']}")
            
            # ì¡°í•©
            if details:
                line += "\n    " + "\n    ".join(details)
            
            lines.append(line)
        
        return "\n".join(lines)
    
    def _call_llm_for_semantic(
        self,
        parameters: List[Dict],
        dict_keys_list: str,
        dict_context: str
    ) -> Optional[ParameterSemanticResponse]:
        """
        LLMì„ í˜¸ì¶œí•˜ì—¬ parameter ì‹œë§¨í‹± ë¶„ì„ ìˆ˜í–‰
        
        Args:
            parameters: ë¶„ì„í•  parameter ëª©ë¡
            dict_keys_list: dictionary key ëª©ë¡ ë¬¸ìì—´
            dict_context: dictionary ìƒì„¸ ì •ë³´ ë¬¸ìì—´
        
        Returns:
            ParameterSemanticResponse or None
        """
        # Dictionary section êµ¬ì„±
        dict_section = self.prompt_class.build_dict_section(dict_keys_list, dict_context)
        
        # Parameters info êµ¬ì„±
        parameters_info = self._build_parameters_info(parameters)
        
        # í”„ë¡¬í”„íŠ¸ ë¹Œë“œ
        prompt = self.prompt_class.build(
            dict_section=dict_section,
            parameters_info=parameters_info,
            param_count=len(parameters)
        )
        
        try:
            response = self.call_llm_json(
                prompt=prompt,
                max_tokens=LLMConfig.MAX_TOKENS_COLUMN_ANALYSIS
            )
            
            if not response:
                return None
            
            # ì‘ë‹µ íŒŒì‹±
            param_results = self.prompt_class.parse_response(response)
            
            if param_results is None:
                # fallback: ìˆ˜ë™ íŒŒì‹±
                params_data = response.get('parameters', response.get('columns', []))
                param_results = []
                for p_data in params_data:
                    try:
                        p_result = ParameterSemanticResult(
                            param_key=p_data.get('param_key', p_data.get('original_name', '')),
                            semantic_name=p_data.get('semantic_name', ''),
                            unit=p_data.get('unit'),
                            description=p_data.get('description'),
                            concept_category=p_data.get('concept_category'),
                            dict_entry_key=p_data.get('dict_entry_key'),
                            match_confidence=p_data.get('match_confidence', 0.0),
                            reasoning=p_data.get('reasoning')
                        )
                        param_results.append(p_result)
                    except Exception as e:
                        self.log(f"âš ï¸ Error parsing parameter result: {e}", indent=1)
                        continue
            
            return ParameterSemanticResponse(
                parameters=param_results,
                summary=response.get('summary')
            )
            
        except json.JSONDecodeError as e:
            self.log(f"âŒ JSON parsing error: {e}", indent=1)
            return None
        except Exception as e:
            self.log(f"âŒ LLM call error: {e}", indent=1)
            return None
    
    def _update_parameter_semantic_batch(
        self,
        results: List[ParameterSemanticResult],
        param_key_to_ids: Dict[str, List[int]],
        key_to_dict_id: Dict[str, str]
    ) -> Dict[str, int]:
        """
        parameter í…Œì´ë¸”ì„ ë°°ì¹˜ ì—…ë°ì´íŠ¸
        
        ë™ì¼í•œ param_keyê°€ ì—¬ëŸ¬ íŒŒì¼ì— ì¡´ì¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
        í•´ë‹¹í•˜ëŠ” ëª¨ë“  param_idì— ë™ì¼í•œ semantic ì •ë³´ë¥¼ ì ìš©
        
        Args:
            results: LLM ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            param_key_to_ids: {param_key: [param_id, ...]} ë§¤í•‘
            key_to_dict_id: {dict_key: dict_entry_id} ë§¤í•‘
        
        Returns:
            í†µê³„ dict: {matched: n, not_found: n, null_from_llm: n}
        """
        _, param_repo, dict_repo = self._get_repositories()
        
        stats = {'matched': 0, 'not_found': 0, 'null_from_llm': 0}
        
        for result in results:
            param_key = result.param_key
            param_ids = param_key_to_ids.get(param_key, [])
            
            if not param_ids:
                self.log(f"âš ï¸ param_id not found for: {param_key}", indent=2)
                continue
            
            # dict_entry_id í•´ì„
            dict_id, status = dict_repo.resolve_dict_entry_id(
                result.dict_entry_key,
                key_to_dict_id
            )
            
            # í†µê³„ ì—…ë°ì´íŠ¸ (param_key ë‹¨ìœ„ë¡œ ì¹´ìš´íŠ¸)
            if status == 'matched':
                stats['matched'] += 1
            elif status == 'not_found':
                stats['not_found'] += 1
            else:
                stats['null_from_llm'] += 1
            
            # ëª¨ë“  ê´€ë ¨ param_idì— ëŒ€í•´ ì—…ë°ì´íŠ¸
            for param_id in param_ids:
                try:
                    param_repo.update_semantic_info(
                        param_id=param_id,
                        semantic_name=result.semantic_name,
                        unit=result.unit,
                        concept_category=result.concept_category,
                        description=result.description,
                        dict_entry_id=dict_id,
                        dict_match_status=status,
                        match_confidence=result.match_confidence,
                        llm_confidence=result.match_confidence,  # LLMì´ ì œê³µí•˜ëŠ” ì‹ ë¢°ë„
                        llm_reasoning=result.reasoning
                    )
                except Exception as e:
                    self.log(f"âš ï¸ Error updating parameter {param_key} (id={param_id}): {e}", indent=2)
        
        return stats
    
    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Parameter Semantic Analysis ì‹¤í–‰
        
        parameter í…Œì´ë¸”ì˜ ê° parameterë¥¼ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  data_dictionaryì™€ ì—°ê²°
        """
        started_at = datetime.now().isoformat()
        config = DataSemanticConfig
        
        # ë°ì´í„° íŒŒì¼ ëª©ë¡
        data_files = state.get('data_files', [])
        
        if not data_files:
            self.log("âš ï¸ No data files to analyze")
            return {
                **state,
                'parameter_semantic_result': {
                    'total_parameters': 0,
                    'started_at': started_at,
                    'completed_at': datetime.now().isoformat()
                },
                'parameter_semantic_entries': []
            }
        
        self.log(f"ğŸ“ Data files: {len(data_files)}")
        
        # 1. data_dictionary ë¡œë“œ
        self.log("ğŸ“– Loading data dictionary...")
        dictionary, dict_keys_list, dict_context, key_to_dict_id = self._load_dictionary_with_context()
        self.log(f"Found {len(dictionary)} parameter definitions", indent=1)
        
        # 2. ë¶„ì„í•  parameter ì¡°íšŒ
        self.log("ğŸ” Loading parameters to analyze...")
        parameters = self._get_parameters_to_analyze(data_files)
        self.log(f"Found {len(parameters)} parameters to analyze", indent=1)
        
        if not parameters:
            self.log("âš ï¸ No parameters found to analyze")
            return {
                **state,
                'parameter_semantic_result': {
                    'total_parameters': 0,
                    'started_at': started_at,
                    'completed_at': datetime.now().isoformat()
                },
                'parameter_semantic_entries': []
            }
        
        # param_key â†’ [param_id, ...] ë§¤í•‘ ìƒì„± (ë™ì¼ param_keyê°€ ì—¬ëŸ¬ íŒŒì¼ì— ìˆì„ ìˆ˜ ìˆìŒ)
        from collections import defaultdict
        param_key_to_ids = defaultdict(list)
        for p in parameters:
            param_key_to_ids[p['param_key']].append(p['param_id'])
        
        # ê²°ê³¼ ì¶”ì 
        total_parameters = len(parameters)
        total_matched = 0
        total_not_found = 0
        total_null_from_llm = 0
        llm_calls = 0
        batches_processed = 0
        all_entries = []
        
        # 3. ë°°ì¹˜ ì²˜ë¦¬
        batch_size = config.COLUMN_BATCH_SIZE
        batches = [parameters[i:i+batch_size] for i in range(0, total_parameters, batch_size)]
        
        if len(batches) > 1:
            self.log(f"ğŸ“¦ Splitting into {len(batches)} batches (batch_size={batch_size})")
        
        for batch_idx, batch_params in enumerate(batches):
            if len(batches) > 1:
                self.log(f"ğŸ”„ Batch {batch_idx + 1}/{len(batches)} ({len(batch_params)} parameters)", indent=1)
            
            # LLM í˜¸ì¶œ
            response = self._call_llm_for_semantic(
                batch_params,
                dict_keys_list,
                dict_context
            )
            llm_calls += 1
            batches_processed += 1
            
            if response and response.parameters:
                # DB ì—…ë°ì´íŠ¸
                stats = self._update_parameter_semantic_batch(
                    response.parameters,
                    param_key_to_ids,
                    key_to_dict_id
                )
                
                total_matched += stats.get('matched', 0)
                total_not_found += stats.get('not_found', 0)
                total_null_from_llm += stats.get('null_from_llm', 0)
                
                all_entries.extend([c.dict() for c in response.parameters])
                
                self.log(
                    f"âœ… Analyzed {len(response.parameters)} parameters "
                    f"(matched: {stats.get('matched', 0)}, "
                    f"not_found: {stats.get('not_found', 0)}, "
                    f"null: {stats.get('null_from_llm', 0)})",
                    indent=1
                )
            else:
                self.log("âš ï¸ No results from LLM", indent=1)
        
        # 4. ìµœì¢… ê²°ê³¼ êµ¬ì„±
        completed_at = datetime.now().isoformat()
        
        result = {
            'total_parameters': total_parameters,
            'parameters_analyzed': len(all_entries),
            'parameters_matched': total_matched,
            'parameters_not_found': total_not_found,
            'parameters_null_from_llm': total_null_from_llm,
            'batches_processed': batches_processed,
            'llm_calls': llm_calls,
            'started_at': started_at,
            'completed_at': completed_at
        }
        
        self.log(f"ğŸ“Š Parameters analyzed: {len(all_entries)}/{total_parameters}", indent=1)
        self.log(f"âœ… Dictionary matches: {total_matched}", indent=1)
        self.log(f"âŒ Not found in dict: {total_not_found}", indent=1)
        self.log(f"âš ï¸ Null from LLM: {total_null_from_llm}", indent=1)
        self.log(f"ğŸ”„ Batches: {batches_processed}", indent=1)
        self.log(f"ğŸ¤– LLM calls: {llm_calls}", indent=1)
        
        return {
            **state,
            'parameter_semantic_result': result,
            'parameter_semantic_entries': all_entries
        }
    
    @classmethod
    def run_standalone(cls, data_files: List[str]) -> Dict[str, Any]:
        """
        ë‹¨ë… ì‹¤í–‰ìš© ë©”ì„œë“œ
        
        Args:
            data_files: ë¶„ì„í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì‹¤í–‰ ê²°ê³¼ state
        """
        node = cls()
        initial_state = {
            'data_files': data_files
        }
        return node(initial_state)
