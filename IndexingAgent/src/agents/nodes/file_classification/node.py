# src/agents/nodes/file_classification/node.py
"""
File Classification Node

íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
- metadata: ë°ì´í„° ì‚¬ì „, íŒŒë¼ë¯¸í„° ì •ì˜ íŒŒì¼ (clinical_parameters.csv ë“±)
- data: ì‹¤ì œ ì¸¡ì •/ê¸°ë¡ ë°ì´í„° íŒŒì¼ (clinical_data.csv ë“±)

âœ… LLM ì‚¬ìš©: is_metadata íŒë‹¨
"""

from typing import Dict, Any, List
from datetime import datetime

from shared.database import FileRepository
from shared.config import LLMConfig
from IndexingAgent.src.config import FileClassificationConfig, IndexingConfig
from IndexingAgent.src.models.llm_responses import (
    FileClassificationItem,
    FileClassificationResult,
)
from shared.llm import get_llm_client

from shared.langgraph import BaseNode, LLMMixin, DatabaseMixin
from shared.langgraph import register_node
from .prompts import FileClassificationPrompt


@register_node
class FileClassificationNode(BaseNode, LLMMixin, DatabaseMixin):
    """
    File Classification Node (LLM-based)
    
    íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    - metadata: ë°ì´í„° ì‚¬ì „, íŒŒë¼ë¯¸í„° ì •ì˜ íŒŒì¼
    - data: ì‹¤ì œ ì¸¡ì •/ê¸°ë¡ ë°ì´í„° íŒŒì¼
    """
    
    name = "file_classification"
    description = "íŒŒì¼ ë¶„ë¥˜ (metadata vs data)"
    order = 400
    requires_llm = True
    
    # í”„ë¡¬í”„íŠ¸ í´ë˜ìŠ¤ ì—°ê²°
    prompt_class = FileClassificationPrompt
    
    def __init__(self):
        super().__init__()
        self._file_repo = None
    
    # =========================================================================
    # Main Execution
    # =========================================================================
    
    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        íŒŒì¼ì„ metadata/dataë¡œ ë¶„ë¥˜
        
        Args:
            state: AgentState (catalog_file_ids í•„ìš”)
        
        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ:
            - file_classification_result: ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½
            - metadata_files: metadata íŒŒì¼ ê²½ë¡œ ëª©ë¡
            - data_files: data íŒŒì¼ ê²½ë¡œ ëª©ë¡
        """
        self.log("=" * 60)
        self.log("ğŸ·ï¸  metadata vs data ë¶„ë¥˜")
        self.log("=" * 60)
        
        started_at = datetime.now()
        
        # file_catalogì—ì„œ ì²˜ë¦¬ëœ íŒŒì¼ IDë“¤
        file_ids = state.get("catalog_file_ids", [])
        
        if not file_ids:
            self.log("âš ï¸ No files to classify", indent=1)
            return self._create_empty_result("No files to classify")
        
        self.log(f"ğŸ“‚ Files to classify: {len(file_ids)}", indent=1)
        
        # =====================================================================
        # Skip Already Analyzed (FORCE_REANALYZE=falseì¸ ê²½ìš°)
        # =====================================================================
        skipped_count = 0
        if not IndexingConfig.FORCE_REANALYZE:
            file_repo = self._get_file_repo()
            skipped_count = file_repo.get_already_classified_count(file_ids)
            
            if skipped_count > 0:
                self.log(f"â­ï¸  Skipping {skipped_count} already classified files", indent=1)
                file_ids = file_repo.get_files_without_classification(file_ids)
                
                if not file_ids:
                    self.log("âœ… All files already classified, nothing to do", indent=1)
                    # ê¸°ì¡´ ê²°ê³¼ ì¡°íšŒí•˜ì—¬ ë°˜í™˜
                    return self._get_existing_classification_result(state.get("catalog_file_ids", []))
                
                self.log(f"ğŸ“‚ Files to analyze: {len(file_ids)}", indent=1)
        
        # 1. íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        self.log("ğŸ“Š Collecting file information...", indent=1)
        file_infos = self._get_files_info(file_ids)
        
        # file_name â†’ file_path ë§¤í•‘
        file_id_to_path = {info['file_name']: info['file_path'] for info in file_infos}
        
        for info in file_infos:
            self.log(f"âœ… {info['file_name']} ({info['column_count']} cols, {info['row_count']} rows)", indent=2)
        
        if len(file_infos) < len(file_ids):
            self.log(f"âš ï¸ Failed to get info for {len(file_ids) - len(file_infos)} files", indent=2)
        
        if not file_infos:
            self.log("âŒ No file info collected", indent=1)
            return self._create_empty_result("No file info collected")
        
        # 2. LLM í˜¸ì¶œ (ë°°ì¹˜ ì²˜ë¦¬)
        self.log("ğŸ¤– Calling LLM for classification...", indent=1)
        batch_size = FileClassificationConfig.FILE_BATCH_SIZE
        classifications = self._call_llm_for_classification_batched(file_infos, batch_size)
        
        if not classifications:
            self.log("âŒ LLM classification failed", indent=1)
            return self._create_empty_result("LLM classification failed")
        
        # 3. ê²°ê³¼ ì²˜ë¦¬ ë° DB ì—…ë°ì´íŠ¸
        self.log(f"ğŸ“ Processing {len(classifications)} classifications...", indent=1)
        
        metadata_files = []
        data_files = []
        classifications_dict = {}
        
        for clf in classifications:
            file_name = clf.file_name
            is_metadata = clf.is_metadata
            confidence = clf.confidence
            reasoning = clf.reasoning
            
            file_path = file_id_to_path.get(file_name, file_name)
            
            # DB ì—…ë°ì´íŠ¸
            self._update_file_classification(file_name, is_metadata, confidence)
            
            # ê²°ê³¼ ë¶„ë¥˜
            if is_metadata:
                metadata_files.append(file_path)
                marker = "ğŸ“‹ metadata"
            else:
                data_files.append(file_path)
                marker = "ğŸ“Š data"
            
            self.log(f"{marker}: {file_name} (conf={confidence:.2f})", indent=2)
            
            classifications_dict[file_name] = {
                "file_path": file_path,
                "is_metadata": is_metadata,
                "confidence": confidence,
                "reasoning": reasoning
            }
        
        # 4. ê²°ê³¼ ìš”ì•½
        completed_at = datetime.now()
        duration = (completed_at - started_at).total_seconds()
        
        # LLM í˜¸ì¶œ íšŸìˆ˜ ê³„ì‚°
        batch_size = FileClassificationConfig.FILE_BATCH_SIZE
        llm_calls = (len(file_infos) + batch_size - 1) // batch_size
        
        result = FileClassificationResult(
            total_files=len(file_infos),
            metadata_files=metadata_files,
            data_files=data_files,
            classifications=classifications_dict,
            llm_calls=llm_calls,
            started_at=started_at.isoformat(),
            completed_at=completed_at.isoformat()
        )
        
        self.log("âœ… Complete!")
        self.log(f"ğŸ“‹ Metadata files: {len(metadata_files)}", indent=1)
        for f in metadata_files:
            self.log(f"- {f.split('/')[-1]}", indent=2)
        self.log(f"ğŸ“Š Data files: {len(data_files)}", indent=1)
        for f in data_files:
            self.log(f"- {f.split('/')[-1]}", indent=2)
        self.log(f"â±ï¸  Duration: {duration:.1f}s", indent=1)
        self.log("=" * 60)
        
        return {
            "file_classification_result": result.model_dump(),
            "metadata_files": metadata_files,
            "data_files": data_files,
            "logs": [
                f"ğŸ·ï¸ [File Classification] Classified {len(file_infos)} files: "
                f"{len(metadata_files)} metadata, {len(data_files)} data"
            ]
        }
    
    # =========================================================================
    # File Info Collection
    # =========================================================================
    
    def _get_file_repo(self) -> FileRepository:
        """FileRepository ì‹±ê¸€í†¤ ë°˜í™˜"""
        if self._file_repo is None:
            self._file_repo = FileRepository()
        return self._file_repo
    
    def _get_files_info(self, file_ids: List[str]) -> List[Dict[str, Any]]:
        """DBì—ì„œ íŒŒì¼ ì •ë³´ ì¡°íšŒ"""
        file_repo = self._get_file_repo()
        try:
            return file_repo.get_files_with_classification_info(file_ids)
        except Exception as e:
            self.log(f"âŒ Error getting files info: {e}", indent=1)
            return []
    
    # =========================================================================
    # LLM Methods
    # =========================================================================
    
    def _call_llm_for_classification_batched(
        self,
        file_infos: List[Dict[str, Any]],
        batch_size: int
    ) -> List[FileClassificationItem]:
        """
        LLMì„ ë°°ì¹˜ë¡œ í˜¸ì¶œí•˜ì—¬ íŒŒì¼ ë¶„ë¥˜
        
        íŒŒì¼ ìˆ˜ê°€ ë§ì„ ë•Œ ë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬í•˜ì—¬ í† í° ì œí•œ ë¬¸ì œ ë°©ì§€
        """
        all_classifications = []
        n_files = len(file_infos)
        n_batches = (n_files + batch_size - 1) // batch_size
        
        for batch_idx in range(n_batches):
            start = batch_idx * batch_size
            end = min(start + batch_size, n_files)
            batch_infos = file_infos[start:end]
            
            if n_batches > 1:
                self.log(f"ğŸ“¤ Batch {batch_idx + 1}/{n_batches} ({len(batch_infos)} files)", indent=2)
            
            batch_result = self._call_llm_for_classification(batch_infos)
            
            if batch_result:
                self.log(f"âœ… Got {len(batch_result)} results", indent=3)
                all_classifications.extend(batch_result)
            else:
                self.log(f"âš ï¸ Batch {batch_idx + 1} returned no results", indent=3)
        
        return all_classifications
    
    def _call_llm_for_classification(
        self,
        file_infos: List[Dict[str, Any]]
    ) -> List[FileClassificationItem]:
        """LLMì„ í˜¸ì¶œí•˜ì—¬ íŒŒì¼ ë¶„ë¥˜ (ë‹¨ì¼ ë°°ì¹˜)"""
        llm = get_llm_client()
        
        # í”„ë¡¬í”„íŠ¸ ë¹Œë“œ (PromptTemplate ì‚¬ìš©)
        files_info_text = self._build_files_info_text(file_infos)
        prompt = self.prompt_class.build(files_info=files_info_text)
        
        try:
            data = llm.ask_json(prompt, max_tokens=LLMConfig.MAX_TOKENS)
            
            if data.get("error"):
                self.log(f"âŒ LLM returned error: {data.get('error')}", indent=1)
                return []
            
            # PromptTemplateì˜ parse_response ì‚¬ìš©
            classifications = self.prompt_class.parse_response(data)
            
            if classifications is None:
                self.log("âš ï¸ Failed to parse LLM response", indent=1)
                return []
            
            return classifications
            
        except Exception as e:
            self.log(f"âŒ LLM call error: {e}", indent=1)
            return []
    
    def _build_files_info_text(self, file_infos: List[Dict[str, Any]]) -> str:
        """íŒŒì¼ ì •ë³´ë¥¼ LLM í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        lines = []
        
        for i, info in enumerate(file_infos, 1):
            file_name = info.get('file_name', '?')
            col_count = info.get('column_count', 0)
            row_count = info.get('row_count', 0)
            columns = info.get('columns', [])
            
            lines.append(f'{i}. "{file_name}" [tabular, {col_count} columns, {row_count} rows]')
            
            col_names = [c['name'] for c in columns]
            lines.append(f"   Columns: {', '.join(col_names[:15])}")
            if len(col_names) > 15:
                lines.append(f"            ... and {len(col_names) - 15} more columns")
            
            lines.append("   Sample values per column:")
            for col in columns[:5]:
                col_name = col['name']
                unique_vals = col.get('unique_values', [])
                vals_str = [str(v)[:30] for v in unique_vals[:5]]
                lines.append(f"   - {col_name}: {vals_str}")
            
            if len(columns) > 5:
                lines.append(f"   ... and {len(columns) - 5} more columns")
            
            lines.append("")
        
        return "\n".join(lines)
    
    # =========================================================================
    # DB Update
    # =========================================================================
    
    def _update_file_classification(
        self,
        file_name: str,
        is_metadata: bool,
        confidence: float
    ):
        """file_catalog.is_metadata ì—…ë°ì´íŠ¸"""
        file_repo = self._get_file_repo()
        return file_repo.update_is_metadata(file_name, is_metadata, confidence)
    
    # =========================================================================
    # Helper Methods
    # =========================================================================
    
    def _create_empty_result(self, error_msg: str) -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ ìƒì„±"""
        return {
            "file_classification_result": {
                "total_files": 0,
                "metadata_files": [],
                "data_files": [],
                "error": error_msg
            },
            "metadata_files": [],
            "data_files": [],
            "logs": [f"âš ï¸ [File Classification] {error_msg}"]
        }
    
    def _get_existing_classification_result(self, file_ids: List[str]) -> Dict[str, Any]:
        """
        ì´ë¯¸ ë¶„ë¥˜ëœ íŒŒì¼ë“¤ì˜ ê¸°ì¡´ ê²°ê³¼ ì¡°íšŒí•˜ì—¬ ë°˜í™˜
        
        FORCE_REANALYZE=falseì´ê³  ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ë¶„ë¥˜ëœ ê²½ìš° ì‚¬ìš©
        """
        file_repo = self._get_file_repo()
        files = file_repo.get_files_by_ids(file_ids)
        
        metadata_files = []
        data_files = []
        
        for f in files:
            if f.get('is_metadata'):
                metadata_files.append(f['file_path'])
            else:
                data_files.append(f['file_path'])
        
        result = FileClassificationResult(
            total_files=len(files),
            metadata_files=metadata_files,
            data_files=data_files,
            classifications={},  # ê¸°ì¡´ ë¶„ë¥˜ ê²°ê³¼ëŠ” ìƒì„¸ ì¡°íšŒ ìƒëµ
            llm_calls=0,  # LLM í˜¸ì¶œ ì—†ìŒ (ìŠ¤í‚µ)
            started_at=datetime.now().isoformat(),
            completed_at=datetime.now().isoformat()
        )
        
        self.log(f"ğŸ“‹ Metadata files (cached): {len(metadata_files)}", indent=1)
        self.log(f"ğŸ“Š Data files (cached): {len(data_files)}", indent=1)
        
        return {
            "file_classification_result": result.model_dump(),
            "metadata_files": metadata_files,
            "data_files": data_files,
            "logs": [
                f"ğŸ·ï¸ [File Classification] Skipped (already classified): "
                f"{len(metadata_files)} metadata, {len(data_files)} data"
            ]
        }
    
    # =========================================================================
    # Convenience Methods (Standalone Execution)
    # =========================================================================
    
    @classmethod
    def run_standalone(cls, file_ids: List[str] = None) -> Dict[str, Any]:
        """
        ë…ë¦½ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
        
        Args:
            file_ids: ë¶„ë¥˜í•  íŒŒì¼ ID ëª©ë¡ (Noneì´ë©´ DBì—ì„œ ëª¨ë“  íŒŒì¼ ì¡°íšŒ)
        
        Returns:
            ë¶„ë¥˜ ê²°ê³¼
        """
        node = cls()
        
        if file_ids is None:
            file_repo = node._get_file_repo()
            file_ids = file_repo.get_all_file_ids()
        
        state = {"catalog_file_ids": file_ids}
        return node.execute(state)

