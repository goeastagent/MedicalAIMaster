# src/agents/nodes/file_grouping/node.py
"""
File Grouping Node

[250] file_grouping_prepì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ
LLMì´ íŒŒì¼ ê·¸ë£¹í•‘ ì „ëµì„ ê²°ì •í•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- LLMì„ ì‚¬ìš©í•´ ê·¸ë£¹í•‘ ì „ëµ ê²°ì • (pattern_based, partitioned, paired, single)
- file_group í…Œì´ë¸”ì— ê·¸ë£¹ ìƒì„± (status='confirmed')
- file_catalog.group_id ì—…ë°ì´íŠ¸
"""

import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple

from shared.database.repositories import FileRepository, DirectoryRepository, FileGroupRepository
from shared.config import LLMConfig

from shared.langgraph import BaseNode, LLMMixin, DatabaseMixin
from shared.langgraph import register_node
from .prompts import FileGroupingPrompt


@register_node
class FileGroupingNode(BaseNode, LLMMixin, DatabaseMixin):
    """
    File Grouping Node (LLM-based)
    
    [250] file_grouping_prepì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ
    LLMì´ íŒŒì¼ ê·¸ë£¹í•‘ ì „ëµì„ ê²°ì •í•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.
    
    Input (from state):
        - directories_for_grouping: [250]ì—ì„œ ìˆ˜ì§‘í•œ ë””ë ‰í† ë¦¬ ì •ë³´
        - grouping_prep_result: [250]ì˜ ê²°ê³¼ ìš”ì•½
    
    Output:
        - file_grouping_result: ê·¸ë£¹í•‘ ê²°ê³¼ ìš”ì•½
        - file_groups: ìƒì„±ëœ ê·¸ë£¹ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    
    name = "file_grouping"
    description = "íŒŒì¼ ê·¸ë£¹í•‘ ì „ëµ ê²°ì • ë° ê·¸ë£¹ ìƒì„± (LLM-based)"
    order = 350
    requires_llm = True
    
    # í”„ë¡¬í”„íŠ¸ í´ë˜ìŠ¤ ì—°ê²°
    prompt_class = FileGroupingPrompt
    
    # =========================================================================
    # Configuration
    # =========================================================================
    
    MAX_RETRIES = 3
    RETRY_DELAY_SECONDS = 2
    CONFIDENCE_THRESHOLD = 0.7
    BATCH_SIZE = 10  # í•œ ë²ˆì— ë¶„ì„í•  ìµœëŒ€ ë””ë ‰í† ë¦¬ ìˆ˜
    
    # =========================================================================
    # Repository Access (Lazy Initialization)
    # =========================================================================
    
    @property
    def file_repo(self) -> FileRepository:
        """FileRepository ì¸ìŠ¤í„´ìŠ¤ (lazy)"""
        if not hasattr(self, '_file_repo') or self._file_repo is None:
            self._file_repo = FileRepository()
        return self._file_repo
    
    @property
    def dir_repo(self) -> DirectoryRepository:
        """DirectoryRepository ì¸ìŠ¤í„´ìŠ¤ (lazy)"""
        if not hasattr(self, '_dir_repo') or self._dir_repo is None:
            self._dir_repo = DirectoryRepository()
        return self._dir_repo
    
    @property
    def group_repo(self) -> FileGroupRepository:
        """FileGroupRepository ì¸ìŠ¤í„´ìŠ¤ (lazy)"""
        if not hasattr(self, '_group_repo') or self._group_repo is None:
            self._group_repo = FileGroupRepository()
        return self._group_repo
    
    # =========================================================================
    # Main Execution
    # =========================================================================
    
    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        íŒŒì¼ ê·¸ë£¹í•‘ ì‹¤í–‰
        
        1. [250]ì—ì„œ ìˆ˜ì§‘í•œ ë””ë ‰í† ë¦¬ ì •ë³´ ë¡œë“œ
        2. LLMì—ê²Œ ê·¸ë£¹í•‘ ì „ëµ ê²°ì • ìš”ì²­
        3. ê·¸ë£¹ ìƒì„± ë° íŒŒì¼ í• ë‹¹
        """
        started_at = datetime.now().isoformat()
        
        self.log("=" * 60)
        self.log("ğŸ“¦ íŒŒì¼ ê·¸ë£¹í•‘ (LLM-based)")
        self.log("=" * 60)
        
        # 1. [250]ì—ì„œ ìˆ˜ì§‘í•œ ë””ë ‰í† ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        directories = state.get('directories_for_grouping', [])
        
        if not directories:
            self.log("â„¹ï¸ No directories to analyze for grouping")
            return {
                "file_grouping_result": {
                    "groups_created": 0,
                    "files_grouped": 0,
                    "files_ungrouped": 0,
                    "started_at": started_at,
                    "completed_at": datetime.now().isoformat()
                },
                "file_groups": []
            }
        
        self.log(f"ğŸ“ Directories to analyze: {len(directories)}")
        
        # 2. LLM í˜¸ì¶œ (ë°°ì¹˜ ì²˜ë¦¬)
        all_results = []
        total_llm_calls = 0
        
        for i in range(0, len(directories), self.BATCH_SIZE):
            batch = directories[i:i + self.BATCH_SIZE]
            batch_num = i // self.BATCH_SIZE + 1
            total_batches = (len(directories) + self.BATCH_SIZE - 1) // self.BATCH_SIZE
            
            self.log(f"ğŸ“¤ Batch {batch_num}/{total_batches} ({len(batch)} directories)", indent=1)
            
            results, llm_calls = self._call_llm_for_grouping(batch)
            all_results.extend(results)
            total_llm_calls += llm_calls
            
            self.log(f"âœ… Got {len(results)} results", indent=2)
        
        # 3. ê²°ê³¼ ì²˜ë¦¬ ë° ê·¸ë£¹ ìƒì„±
        # dir_name â†’ dir_id ë§¤í•‘ ìƒì„± (LLMì´ dir_nameë§Œ ë°˜í™˜í•  ê²½ìš° ëŒ€ë¹„)
        dir_id_map = {
            d.get('dir_name'): d.get('dir_id')
            for d in directories
            if d.get('dir_name') and d.get('dir_id')
        }
        
        groups_created = []
        total_files_grouped = 0
        
        for result in all_results:
            if result.get('should_group') and result.get('confidence', 0) >= self.CONFIDENCE_THRESHOLD:
                group_info = self._create_group_from_result(result, dir_id_map)
                if group_info:
                    groups_created.append(group_info)
                    total_files_grouped += group_info.get('file_count', 0)
                    
                    self.log(f"âœ… Created group: {group_info['group_name']}", indent=1)
                    self.log(f"   Strategy: {group_info['grouping_strategy']}", indent=1)
                    self.log(f"   Files: {group_info['file_count']}", indent=1)
            else:
                dir_path = result.get('dir_path') or result.get('dir_name') or '?'
                reason = "low confidence" if result.get('should_group') else "not groupable"
                self.log(f"â„¹ï¸ Skipped: {dir_path} ({reason})", indent=1)
        
        # 4. í†µê³„ ê³„ì‚°
        total_files = sum(d.get('file_count', 0) for d in directories)
        files_ungrouped = total_files - total_files_grouped
        
        # 5. ê²°ê³¼ ì¶œë ¥
        self.log("=" * 60)
        self.log("âœ… Grouping Complete!")
        self.log(f"   Groups created: {len(groups_created)}", indent=1)
        self.log(f"   Files grouped: {total_files_grouped}", indent=1)
        self.log(f"   Files ungrouped: {files_ungrouped}", indent=1)
        self.log(f"   LLM calls: {total_llm_calls}", indent=1)
        self.log("=" * 60)
        
        completed_at = datetime.now().isoformat()
        
        return {
            "file_grouping_result": {
                "groups_created": len(groups_created),
                "files_grouped": total_files_grouped,
                "files_ungrouped": files_ungrouped,
                "llm_calls": total_llm_calls,
                "started_at": started_at,
                "completed_at": completed_at
            },
            "file_groups": groups_created
        }
    
    # =========================================================================
    # LLM Integration
    # =========================================================================
    
    def _build_directories_context(self, directories: List[Dict]) -> str:
        """LLM í”„ë¡¬í”„íŠ¸ìš© ë””ë ‰í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        lines = []
        
        for dir_info in directories:
            dir_path = dir_info.get('dir_path', '?')
            dir_name = dir_info.get('dir_name', '?')
            file_count = dir_info.get('file_count', 0)
            ext_dist = dir_info.get('extension_distribution', {})
            samples = dir_info.get('filename_samples', [])
            patterns = dir_info.get('observed_patterns', [])
            size_stats = dir_info.get('size_stats', {})
            
            lines.append(f"\n## Directory: {dir_name}/")
            lines.append(f"Path: {dir_path}")
            lines.append(f"File count: {file_count}")
            
            # í™•ì¥ì ë¶„í¬
            if ext_dist:
                ext_str = ', '.join(f'"{k}": {v}' for k, v in ext_dist.items())
                lines.append(f"Extensions: {{{ext_str}}}")
            
            # íŒŒì¼ëª… ìƒ˜í”Œ
            if samples:
                sample_str = ', '.join(f'"{s}"' for s in samples[:10])
                lines.append(f"Filename samples: [{sample_str}]")
            
            # í¬ê¸° í†µê³„
            if size_stats:
                lines.append(f"Size range: {size_stats.get('min_mb', 0):.2f} MB - {size_stats.get('max_mb', 0):.2f} MB")
            
            # ê´€ì°°ëœ íŒ¨í„´ (Rule-basedì—ì„œ)
            if patterns:
                lines.append("Observed patterns (from Rule-based analysis):")
                for p in patterns:
                    p_type = p.get('type', '?')
                    p_desc = p.get('description', '')
                    p_ratio = p.get('ratio', 0)
                    lines.append(f"  - {p_type}: {p_desc} (ratio: {p_ratio})")
                    
                    # íŒ¨í„´ë³„ ì¶”ê°€ ì •ë³´
                    if p_type == 'numeric_only' and p.get('value_range'):
                        vr = p['value_range']
                        lines.append(f"    Range: {vr.get('min')} - {vr.get('max')}")
                    elif p_type == 'partitioned' and p.get('base_tables'):
                        for bt in p['base_tables']:
                            lines.append(f"    Base: {bt.get('base_name')}, partitions: {bt.get('partition_count')}")
                    elif p_type == 'paired_extensions':
                        lines.append(f"    Pair: {p.get('most_common_pair')}, count: {p.get('pair_frequency')}")
            else:
                lines.append("Observed patterns: none")
        
        return "\n".join(lines)
    
    def _call_llm_for_grouping(
        self,
        directories: List[Dict]
    ) -> Tuple[List[Dict], int]:
        """
        LLMì„ í˜¸ì¶œí•˜ì—¬ ê·¸ë£¹í•‘ ì „ëµ ê²°ì •
        
        Returns:
            (ê²°ê³¼ ëª©ë¡, LLM í˜¸ì¶œ íšŸìˆ˜)
        """
        if not directories:
            return [], 0
        
        directories_context = self._build_directories_context(directories)
        
        # PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ë¹Œë“œ
        prompt = self.prompt_class.build(directories_context=directories_context)
        
        llm_calls = 0
        results = []
        
        for attempt in range(self.MAX_RETRIES):
            try:
                response = self.call_llm_json(
                    prompt,
                    max_tokens=LLMConfig.MAX_TOKENS
                )
                llm_calls += 1
                
                if response and 'directories' in response:
                    results = response['directories']
                    return results, llm_calls
                else:
                    self.log(f"âš ï¸ Invalid LLM response format, attempt {attempt + 1}", indent=1)
                    
            except Exception as e:
                self.log(f"âŒ LLM call failed (attempt {attempt + 1}): {e}", indent=1)
                if attempt < self.MAX_RETRIES - 1:
                    time.sleep(self.RETRY_DELAY_SECONDS)
        
        return results, llm_calls
    
    # =========================================================================
    # Group Creation
    # =========================================================================
    
    def _create_group_from_result(self, result: Dict, dir_id_map: Dict[str, str] = None) -> Optional[Dict]:
        """
        LLM ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¸ë£¹ ìƒì„±
        
        1. file_group í…Œì´ë¸”ì— ê·¸ë£¹ ë ˆì½”ë“œ ìƒì„±
        2. file_catalog.group_id ì—…ë°ì´íŠ¸
        
        Args:
            result: LLM ì‘ë‹µ ê²°ê³¼
            dir_id_map: dir_name â†’ dir_id ë§¤í•‘ (LLMì´ dir_nameë§Œ ë°˜í™˜í•  ê²½ìš° ì‚¬ìš©)
        """
        dir_path = result.get('dir_path')
        dir_name = result.get('dir_name')
        group_name = result.get('group_name')
        strategy = result.get('grouping_strategy')
        pattern = result.get('filename_pattern')
        entity_source = result.get('entity_identifier_source')
        entity_key = result.get('entity_identifier_key')
        confidence = result.get('confidence', 0)
        reasoning = result.get('reasoning', '')
        
        if not group_name:
            return None
        
        # dir_pathì—ì„œ dir_name ì¶”ì¶œ (LLMì´ dir_nameì„ ë°˜í™˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°)
        if not dir_name and dir_path:
            dir_name = dir_path.rstrip('/').split('/')[-1]
        
        # ë””ë ‰í† ë¦¬ ì •ë³´ ì¡°íšŒ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
        dir_info = None
        dir_id = None
        
        # 1. dir_id_mapì—ì„œ ì§ì ‘ ì¡°íšŒ (ê°€ì¥ ë¹ ë¦„)
        if dir_id_map and dir_name and dir_name in dir_id_map:
            dir_id = dir_id_map[dir_name]
            dir_info = self.dir_repo.get_directory_by_id(dir_id)
        
        # 2. dir_pathë¡œ ì¡°íšŒ
        if not dir_info and dir_path:
            dir_info = self.dir_repo.get_directory_by_path(dir_path)
        
        # 3. dir_nameìœ¼ë¡œ ì¡°íšŒ
        if not dir_info and dir_name:
            dir_info = self.dir_repo.get_directory_by_name(dir_name)
        
        if not dir_info:
            self.log(f"âš ï¸ Directory not found: {dir_path or dir_name}", indent=2)
            return None
        
        dir_id = dir_info['dir_id']
        
        # grouping_criteria êµ¬ì„±
        grouping_criteria = {
            "strategy": strategy,
            "dir_path": dir_path,
            "pattern": pattern
        }
        
        # í™•ì¥ì ì •ë³´ ì¶”ê°€
        ext_dist = dir_info.get('file_extensions', {})
        if ext_dist:
            grouping_criteria["extensions"] = list(ext_dist.keys())
        
        try:
            # 1. ê·¸ë£¹ ìƒì„±
            group_id = self.group_repo.create_group(
                group_name=group_name,
                grouping_criteria=grouping_criteria
            )
            
            if not group_id:
                self.log(f"âš ï¸ Failed to create group: {group_name}", indent=2)
                return None
            
            # 2. ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ì„ ê·¸ë£¹ì— í• ë‹¹
            files = self.file_repo.get_files_by_dir_id(dir_id)
            file_ids = [f['file_id'] for f in files]
            
            if file_ids:
                updated_count = self.group_repo.add_files_to_group(group_id, file_ids)
            else:
                updated_count = 0
            
            # 3. ê·¸ë£¹ ë¶„ì„ ì •ë³´ ì—…ë°ì´íŠ¸ (LLM ê²°ê³¼)
            self.group_repo.update_group_analysis(
                group_id=group_id,
                row_represents=None,  # entity_identificationì—ì„œ ë‚˜ì¤‘ì— ì±„ì›€
                entity_identifier_source=entity_source,
                entity_identifier_key=entity_key,
                confidence=confidence,
                reasoning=reasoning
            )
            
            # 4. ê·¸ë£¹ ìƒíƒœë¥¼ confirmedë¡œ ë³€ê²½
            self.group_repo.confirm_group(
                group_id=group_id,
                reasoning=f"LLM confirmed with {confidence:.2f} confidence: {reasoning}"
            )
            
            return {
                "group_id": group_id,
                "group_name": group_name,
                "grouping_strategy": strategy,
                "filename_pattern": pattern,
                "entity_identifier_source": entity_source,
                "entity_identifier_key": entity_key,
                "file_count": updated_count,
                "confidence": confidence,
                "reasoning": reasoning
            }
            
        except Exception as e:
            self.log(f"âŒ Error creating group: {e}", indent=2)
            import traceback
            traceback.print_exc()
            return None
    
    # =========================================================================
    # Standalone Execution
    # =========================================================================
    
    @classmethod
    def run_standalone(cls, directories_for_grouping: List[Dict]) -> Dict[str, Any]:
        """
        ë‹¨ë… ì‹¤í–‰ìš© ë©”ì„œë“œ
        
        Args:
            directories_for_grouping: [250] ë…¸ë“œì˜ ì¶œë ¥
        
        Returns:
            ì‹¤í–‰ ê²°ê³¼ state
        """
        node = cls()
        initial_state = {
            'directories_for_grouping': directories_for_grouping
        }
        return node(initial_state)

