# src/agents/nodes/analyzer.py
"""
Analyzer Node - ì‹œë§¨í‹± ë¶„ì„ ë° ì˜¨í†¨ë¡œì§€ ë¹Œë“œ
"""

import os
from datetime import datetime
from typing import Dict, Any

from src.agents.state import AgentState
from src.agents.nodes.common import (
    llm_client, llm_cache, ontology_manager,
    create_empty_conversation_history, format_history_for_prompt
)
from src.agents.helpers.llm_helpers import (
    analyze_columns_with_llm,
    analyze_intra_table_hierarchy,
    compare_with_global_context,
    should_request_human_review,
    ask_llm_is_metadata,
)
from src.agents.helpers.feedback_parser import (
    parse_human_feedback_to_column,
    generate_natural_human_question,
)
from src.agents.helpers.metadata_helpers import (
    build_metadata_detection_context,
    parse_metadata_content,
    infer_relationships_with_llm,
)
from src.config import HumanReviewConfig


def analyze_semantics_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node 2] Semantic Analysis (Semantic Reasoning)
    Core brain that finalizes schema based on Processor results
    """
    print("\n" + "="*80)
    print("ğŸ§  [ANALYZER NODE] Starting - Semantic Analysis")
    print("="*80)
    
    metadata = state["raw_metadata"]
    local_anchor_info = metadata.get("anchor_info", {})
    human_feedback = state.get("human_feedback")
    
    # Get Global Context
    project_context = state.get("project_context", {
        "master_anchor_name": None, 
        "known_aliases": [], 
        "example_id_values": []
    })
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬
    dataset_id = state.get("current_dataset_id", "unknown")
    conversation_history = state.get("conversation_history")
    if not conversation_history:
        conversation_history = create_empty_conversation_history(dataset_id)
    
    history_context = format_history_for_prompt(conversation_history, max_turns=5)
    if history_context:
        print(f"   ğŸ“š ëŒ€í™” íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œë¨ ({len(conversation_history.get('turns', []))}ê°œ í„´)")
    
    finalized_anchor = state.get("finalized_anchor")
    retry_count = state.get("retry_count", 0)
    
    # Prevent infinite loop
    if retry_count >= HumanReviewConfig.MAX_RETRY_COUNT:
        log_msg = f"âš ï¸ [Analyzer] Retry count exceeded ({retry_count}). Forcing local Anchor."
        
        finalized_anchor = {
            "status": "CONFIRMED",
            "column_name": local_anchor_info.get("target_column", "unknown"),
            "is_time_series": local_anchor_info.get("is_time_series", False),
            "reasoning": f"Forced confirmation after {retry_count} retries",
            "mapped_to_master": project_context.get("master_anchor_name")
        }
        
        return {
            "finalized_anchor": finalized_anchor,
            "finalized_schema": [],
            "project_context": project_context,
            "needs_human_review": False,
            "human_feedback": None,
            "retry_count": retry_count,
            "logs": [log_msg, "âš ï¸ [Analyzer] Schema analysis skipped (retry exceeded)"]
        }

    # --- Process user feedback ---
    if human_feedback:
        log_msg = f"ğŸ—£ï¸ [Feedback] User feedback received: '{human_feedback}'"
        
        file_path = state.get("file_path", "")
        if file_path:
            filename = os.path.basename(file_path)
            llm_cache.invalidate_for_file(filename)
        
        parsed_column = parse_human_feedback_to_column(
            feedback=human_feedback,
            available_columns=metadata.get("columns", []),
            master_anchor=project_context.get("master_anchor_name"),
            file_path=state.get("file_path", "")
        )
        
        if parsed_column.get("action") == "skip":
            return {
                "finalized_anchor": None,
                "finalized_schema": [],
                "project_context": project_context,
                "needs_human_review": False,
                "human_feedback": None,
                "skip_indexing": True,
                "logs": [log_msg, "â­ï¸ [Analyzer] File skipped by user request"]
            }
        
        if parsed_column.get("action") == "use_filename_as_id":
            caseid_value = parsed_column.get("caseid_value")
            reasoning = parsed_column.get("reasoning", "Using filename as identifier")
            
            print(f"   â†’ Using filename as ID: caseid={caseid_value}")
            
            if "anchor_info" not in metadata:
                metadata["anchor_info"] = {}
            
            metadata["anchor_info"]["status"] = "FOUND"
            metadata["anchor_info"]["target_column"] = "caseid"
            metadata["anchor_info"]["caseid_value"] = caseid_value
            metadata["anchor_info"]["is_time_series"] = True
            metadata["anchor_info"]["needs_human_confirmation"] = False
            
            finalized_anchor = {
                "status": "CONFIRMED",
                "column_name": "caseid",
                "caseid_value": caseid_value,
                "is_time_series": metadata.get("is_time_series", True),
                "reasoning": reasoning,
                "mapped_to_master": project_context.get("master_anchor_name")
            }
        
        determined_column = parsed_column.get("column_name", human_feedback.strip())
        reasoning = parsed_column.get("reasoning", "User manually confirmed.")
        
        print(f"   â†’ Parsing result: '{determined_column}'")
        
        finalized_anchor = {
            "status": "CONFIRMED",
            "column_name": determined_column,
            "is_time_series": local_anchor_info.get("is_time_series", False),
            "reasoning": reasoning,
            "mapped_to_master": project_context.get("master_anchor_name") 
        }
        
        if "anchor_info" in metadata:
            metadata["anchor_info"]["needs_human_confirmation"] = False
            metadata["anchor_info"]["status"] = "CONFIRMED"
    
    # --- When Anchor is not yet finalized -> Check Global Context ---
    if not finalized_anchor:
        file_type = state.get("file_type", "tabular")
        
        # Signal íŒŒì¼ íŠ¹ë³„ ì²˜ë¦¬
        if file_type == "signal" and local_anchor_info.get("id_value"):
            id_column = local_anchor_info.get("target_column", "file_id")
            id_value = local_anchor_info.get("id_value")
            confidence = local_anchor_info.get("confidence", 0.5)
            needs_confirmation = local_anchor_info.get("needs_human_confirmation", False)
            
            print(f"\nğŸ“¡ [Signal File] LLM-inferred ID: {id_column}={id_value} (confidence: {confidence:.0%})")
            
            if needs_confirmation and confidence < HumanReviewConfig.SIGNAL_FILE_CONFIDENCE_THRESHOLD:
                question = generate_natural_human_question(
                    file_path=state.get("file_path", ""),
                    context={
                        "reasoning": local_anchor_info.get("reasoning", ""),
                        "candidates": f"{id_column}={id_value}",
                        "columns": [],
                        "message": f"LLM inferred ID with {confidence:.0%} confidence."
                    },
                    issue_type="anchor_uncertain",
                    conversation_history=conversation_history
                )
                
                return {
                    "needs_human_review": True,
                    "review_type": "anchor",
                    "human_question": question,
                    "conversation_history": conversation_history,
                    "logs": [f"âš ï¸ [Analyzer] Signal file ID uncertain ({confidence:.0%})."]
                }
            
            finalized_anchor = {
                "status": "CONFIRMED",
                "column_name": id_column,
                "id_value": id_value,
                "is_time_series": True,
                "reasoning": local_anchor_info.get("reasoning", "LLM inferred ID"),
                "confidence": confidence,
                "mapped_to_master": project_context.get("master_anchor_name")
            }
        
        # Case 1: Project already has agreed Anchor (Leader)
        elif project_context.get("master_anchor_name"):
            master_name = project_context["master_anchor_name"]
            
            # ontology_context ì „ë‹¬í•˜ì—¬ FK ì¶”ë¡  í™œì„±í™”
            ontology_context = state.get("ontology_context")
            
            comparison = compare_with_global_context(
                local_metadata=metadata,
                local_anchor_info=local_anchor_info,
                project_context=project_context,
                ontology_context=ontology_context
            )
            
            comparison_status = comparison.get("status", "UNKNOWN")
            print(f"\n[DEBUG] Global Anchor comparison result: {comparison_status}")
            
            if comparison["status"] == "MATCH":
                target_col = comparison["target_column"]
                finalized_anchor = {
                    "status": "CONFIRMED",
                    "column_name": target_col,
                    "is_time_series": local_anchor_info.get("is_time_series", False),
                    "reasoning": f"Matched with global master anchor '{master_name}'",
                    "mapped_to_master": master_name
                }
            
            elif comparison["status"] == "INDIRECT_LINK":
                via_col = comparison["target_column"]
                via_table = comparison.get("via_table", "unknown")
                
                finalized_anchor = {
                    "status": "INDIRECT_LINK",
                    "column_name": via_col,
                    "is_time_series": local_anchor_info.get("is_time_series", False),
                    "reasoning": comparison.get("message"),
                    "mapped_to_master": master_name,
                    "via_table": via_table,
                    "link_type": "indirect"
                }
                
                print(f"\nâœ… [INDIRECT_LINK] Auto-confirmed indirect link!")
            
            elif comparison["status"] == "FK_LINK":
                # NEW: FK ê´€ê³„ë¥¼ í†µí•œ ìë™ ì—°ê²°
                fk_col = comparison["target_column"]
                via_table = comparison.get("via_table", "unknown")
                via_column = comparison.get("via_column", fk_col)
                fk_path = comparison.get("fk_path", [])
                confidence = comparison.get("confidence", 0.7)
                
                finalized_anchor = {
                    "status": "FK_LINK",
                    "column_name": fk_col,
                    "is_time_series": local_anchor_info.get("is_time_series", False),
                    "reasoning": comparison.get("message"),
                    "mapped_to_master": master_name,
                    "via_table": via_table,
                    "via_column": via_column,
                    "fk_path": fk_path,
                    "link_type": "fk",
                    "confidence": confidence
                }
                
                print(f"\nâœ… [FK_LINK] Auto-confirmed FK relationship!")
                print(f"   - FK Path: {' â†’ '.join(fk_path)}")
                print(f"   - Confidence: {confidence:.0%}")
                
                # FK ê´€ê³„ë¥¼ ì˜¨í†¨ë¡œì§€ì— ì €ì¥
                if ontology_context is not None:
                    current_table = os.path.basename(state.get("file_path", "")).replace(".csv", "").replace(".CSV", "")
                    new_relationship = {
                        "source_table": current_table,
                        "target_table": via_table,
                        "source_column": fk_col,
                        "target_column": via_column,
                        "relation_type": comparison.get("relation_type", "N:1"),
                        "confidence": confidence,
                        "llm_inferred": True,
                        "description": f"FK inferred: {current_table}.{fk_col} â†’ {via_table}.{via_column}"
                    }
                    
                    if "relationships" not in ontology_context:
                        ontology_context["relationships"] = []
                    
                    # ì¤‘ë³µ ì²´í¬
                    existing_keys = {
                        (r.get("source_table"), r.get("target_table"), 
                         r.get("source_column"), r.get("target_column"))
                        for r in ontology_context.get("relationships", [])
                    }
                    new_key = (current_table, via_table, fk_col, via_column)
                    
                    if new_key not in existing_keys:
                        ontology_context["relationships"].append(new_relationship)
                        print(f"   - FK relationship saved to ontology")
            
            else:
                msg = comparison.get("message", "Anchor mismatch occurred")
                
                natural_question = generate_natural_human_question(
                    file_path=state.get("file_path", ""),
                    context={
                        "master_anchor": master_name,
                        "candidates": local_anchor_info.get("target_column"),
                        "reasoning": msg,
                        "columns": metadata.get("columns", [])
                    },
                    issue_type="anchor_conflict",
                    conversation_history=conversation_history
                )
                
                return {
                    "needs_human_review": True,
                    "review_type": "anchor",
                    "human_question": natural_question,
                    "conversation_history": conversation_history,
                    "retry_count": retry_count,
                    "logs": [f"âš ï¸ [Analyzer] Global Anchor mismatch ({comparison_status})."]
                }

        # Case 2: This is the first file (no Global Context)
        else:
            processor_confidence = local_anchor_info.get(
                "confidence", 
                0.5 if local_anchor_info.get("needs_human_confirmation") else 0.9
            )
            
            review_decision = should_request_human_review(
                file_path=state.get("file_path", ""),
                issue_type="anchor_detection",
                context={
                    "processor_msg": local_anchor_info.get("msg"),
                    "candidates": local_anchor_info.get("target_column"),
                    "columns": metadata.get("columns", []),
                    "processor_needs_confirmation": local_anchor_info.get("needs_human_confirmation", False)
                },
                rule_based_confidence=processor_confidence
            )
            
            if review_decision["needs_review"]:
                question = generate_natural_human_question(
                    file_path=state.get("file_path", ""),
                    context={
                        "reasoning": local_anchor_info.get("msg"),
                        "candidates": local_anchor_info.get("target_column", "None"),
                        "columns": metadata.get("columns", [])
                    },
                    issue_type="anchor_uncertain",
                    conversation_history=conversation_history
                )
                
                return {
                    "needs_human_review": True,
                    "review_type": "anchor",
                    "human_question": question,
                    "conversation_history": conversation_history,
                    "logs": [f"âš ï¸ [Analyzer] Anchor uncertain (first file). {review_decision['reason']}"]
                }
            
            finalized_anchor = {
                "status": "CONFIRMED",
                "column_name": local_anchor_info.get("target_column"),
                "is_time_series": local_anchor_info.get("is_time_series"),
                "reasoning": local_anchor_info.get("reasoning"),
                "mapped_to_master": None
            }

    # --- Update Global Context ---
    if finalized_anchor and not project_context.get("master_anchor_name"):
        project_context["master_anchor_name"] = finalized_anchor["column_name"]
        project_context["known_aliases"].append(finalized_anchor["column_name"])
        print(f"ğŸ‘‘ [Project Context] New Master Anchor set: '{finalized_anchor['column_name']}'")

    # --- [NEW] user_feedbackì„ LLMì— ì „ë‹¬í•˜ì—¬ ë¶„ì„ í’ˆì§ˆ í–¥ìƒ ---
    human_feedback = state.get("human_feedback")
    dataset_id = state.get("current_dataset_id", "unknown")
    
    if human_feedback:
        print(f"   ğŸ“ [User Feedback] Passing to LLM: '{human_feedback[:50]}...'")
    
    # --- Detailed schema analysis (with user_feedback) ---
    schema_analysis = analyze_columns_with_llm(
        columns=metadata.get("columns", []),
        sample_data=metadata.get("column_details", {}),
        anchor_context=finalized_anchor,
        user_feedback=human_feedback  # NEW: LLMì— user_feedback ì „ë‹¬
    )
    
    # --- [NEW] Build analysis_context for traceability ---
    enrichments = []
    
    for schema_item in schema_analysis:
        col_name = schema_item.get("original_name")
        if col_name:
            # analysis_context ìƒì„±: ë¶„ì„ ê·¼ê±° (user_feedback í¬í•¨)
            # NOTE: user_feedback ì›ë³¸ì€ ë³„ë„ ì €ì¥í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
            context_parts = []
            if human_feedback:
                context_parts.append(f"user_feedback: '{human_feedback}'")
            if schema_item.get("full_name"):
                context_parts.append(f"full_name: '{schema_item.get('full_name')}'")
            if schema_item.get("semantic_type"):
                context_parts.append(f"semantic_type: '{schema_item.get('semantic_type')}'")
            
            analysis_context = "; ".join(context_parts) if context_parts else None
            
            # PostgreSQLì— analysis_contextë§Œ ì €ì¥ (user_feedback ì¤‘ë³µ ì œê±°)
            schema_item["analysis_context"] = analysis_context
            
            # enriched_definition: LLMì´ ë¶„ì„í•œ í’ë¶€í•œ ì„¤ëª…
            enriched_def = schema_item.get("description_kr") or schema_item.get("description", "")
            
            # Neo4j enrichment ì¤€ë¹„
            enrichments.append({
                "name": col_name,
                "enriched_definition": enriched_def,
                "analysis_context": analysis_context
            })
    
    if human_feedback:
        print(f"   âœ… [User Feedback] Applied to LLM analysis & stored in analysis_context")
    
    # ë°°ì¹˜ë¡œ Neo4j Concept ì—…ë°ì´íŠ¸
    if enrichments:
        from src.utils.ontology_manager import get_ontology_manager
        ontology_mgr = get_ontology_manager()
        ontology_mgr.enrich_concepts_batch(enrichments, dataset_id=dataset_id)

    # --- Intra-table Hierarchy Analysis ---
    file_path = state.get("file_path", "")
    table_name = os.path.basename(file_path).replace(".csv", "").replace(".CSV", "")
    
    # human_feedbackëŠ” ìœ„ì—ì„œ ì´ë¯¸ ê°€ì ¸ì˜´ (line 383)
    
    print(f"\nğŸ”— [Hierarchy] Analyzing intra-table hierarchy for {table_name}...")
    hierarchy_info = analyze_intra_table_hierarchy(
        columns=metadata.get("columns", []),
        sample_data=metadata.get("column_details", {}),
        table_name=table_name,
        user_feedback=human_feedback  # NEW: ì‚¬ìš©ì í”¼ë“œë°± ì „ë‹¬
    )
    
    # hierarchyê°€ ë°œê²¬ë˜ë©´ ì €ì¥
    intra_table_hierarchy = None
    if hierarchy_info:
        intra_table_hierarchy = hierarchy_info
        
        # 1. PostgreSQL column_metadataì— parent_column/cardinality ì¶”ê°€
        # (schema_analysisì˜ child_columnì— ì •ë³´ ì¶”ê°€)
        child_col = hierarchy_info.get("child_column")
        parent_col = hierarchy_info.get("parent_column")
        cardinality = hierarchy_info.get("cardinality", "N:1")
        
        for schema_item in schema_analysis:
            if schema_item.get("original_name") == child_col:
                schema_item["parent_column"] = parent_col
                schema_item["cardinality"] = cardinality
                schema_item["hierarchy_type"] = hierarchy_info.get("hierarchy_type", "unknown")
                print(f"   âœ… [PostgreSQL] {child_col} metadata updated with parent_column={parent_col}")
                break
        
        # 2. Neo4jì— CHILD_OF ê´€ê³„ ì €ì¥ (ontology_contextì— ì¶”ê°€)
        ontology_context = state.get("ontology_context")
        if ontology_context is not None:
            if "column_hierarchy" not in ontology_context:
                ontology_context["column_hierarchy"] = []
            
            new_hierarchy = {
                "table_name": table_name,
                "child_column": child_col,
                "parent_column": parent_col,
                "cardinality": cardinality,
                "hierarchy_type": hierarchy_info.get("hierarchy_type", "unknown"),
                "reasoning": hierarchy_info.get("reasoning", ""),
                "dataset_id": state.get("current_dataset_id", "unknown")
            }
            
            # ì¤‘ë³µ ì²´í¬
            existing_keys = {
                (h.get("table_name"), h.get("child_column"), h.get("parent_column"))
                for h in ontology_context.get("column_hierarchy", [])
            }
            new_key = (table_name, child_col, parent_col)
            
            if new_key not in existing_keys:
                ontology_context["column_hierarchy"].append(new_hierarchy)
                print(f"   âœ… [Neo4j] CHILD_OF relationship added: {child_col} â†’ {parent_col}")

    print(f"\nâœ… [ANALYZER NODE] Complete")
    print(f"   - Anchor: {finalized_anchor.get('column_name', 'N/A')}")
    print(f"   - Anchor Status: {finalized_anchor.get('status', 'N/A')}")
    if finalized_anchor.get('status') == 'FK_LINK':
        print(f"   - FK Path: {finalized_anchor.get('fk_path', [])}")
    print(f"   - Schema Columns: {len(schema_analysis)}")
    if intra_table_hierarchy:
        print(f"   - Hierarchy: {intra_table_hierarchy['child_column']} â†’ {intra_table_hierarchy['parent_column']} ({intra_table_hierarchy['cardinality']})")
    print("="*80)

    # ontology_contextê°€ ìˆ˜ì •ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•¨ê»˜ ë°˜í™˜
    result = {
        "finalized_anchor": finalized_anchor,
        "finalized_schema": schema_analysis,
        "project_context": project_context,
        "raw_metadata": metadata,
        "needs_human_review": False,
        "human_feedback": None, 
        "logs": ["ğŸ§  [Analyzer] Complete schema and ontology analysis."]
    }
    
    # FK_LINKì˜ ê²½ìš° ontology_context ì—…ë°ì´íŠ¸ ë°˜í™˜
    if finalized_anchor.get('status') == 'FK_LINK':
        ontology_context = state.get("ontology_context")
        if ontology_context:
            result["ontology_context"] = ontology_context
    
    return result


def ontology_builder_node(state: AgentState) -> Dict[str, Any]:
    """
    [Node] ì˜¨í†¨ë¡œì§€ êµ¬ì¶• - Rule Prepares, LLM Decides
    
    íŒŒì¼ì´ ë©”íƒ€ë°ì´í„°ì¸ì§€ íŒë‹¨í•˜ê³ , ë©”íƒ€ë°ì´í„°ë©´ íŒŒì‹±í•˜ì—¬ ì˜¨í†¨ë¡œì§€ì— ì¶”ê°€
    """
    print("\n" + "="*80)
    print("ğŸ“š [ONTOLOGY BUILDER NODE] ì‹œì‘")
    print("="*80)
    
    file_path = state["file_path"]
    metadata = state["raw_metadata"]
    
    dataset_id = state.get("current_dataset_id", "unknown")
    conversation_history = state.get("conversation_history")
    if not conversation_history:
        conversation_history = create_empty_conversation_history(dataset_id)
    
    ontology = state.get("ontology_context")
    
    if not ontology or not ontology.get("definitions"):
        print(f"   - ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì‹œë„...")
        ontology = ontology_manager.load()
    
    if not ontology:
        ontology = {
            "definitions": {},
            "relationships": [],
            "hierarchy": [],
            "file_tags": {}
        }
    
    # === Step 1: Rule Prepares ===
    print("\nğŸ”§ [Rule] ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    context = build_metadata_detection_context(file_path, metadata)
    
    print(f"   - íŒŒì¼ëª… íŒŒì‹±: {context.get('name_parts')}")
    print(f"   - ì»¬ëŸ¼ ìˆ˜: {context.get('num_columns')}ê°œ")
    
    # === Step 2: LLM Decides ===
    print("\nğŸ§  [LLM] ë©”íƒ€ë°ì´í„° ì—¬ë¶€ íŒë‹¨ ì¤‘...")
    
    meta_result = ask_llm_is_metadata(context)
    
    confidence = meta_result.get("confidence", 0.0)
    is_metadata = meta_result.get("is_metadata", False)
    
    print(f"   - íŒë‹¨: {'ë©”íƒ€ë°ì´í„°' if is_metadata else 'ì¼ë°˜ ë°ì´í„°'}")
    print(f"   - í™•ì‹ ë„: {confidence:.2%}")
    
    # === Step 3: Confidence Check ===
    review_decision = should_request_human_review(
        file_path=file_path,
        issue_type="metadata_classification",
        context={
            "is_metadata": is_metadata,
            "reasoning": meta_result.get("reasoning"),
            "columns": context.get("columns", []),
            "indicators": meta_result.get("indicators", {})
        },
        rule_based_confidence=confidence
    )
    
    if review_decision["needs_review"]:
        print(f"\nâš ï¸  [Low Confidence] Human Review ìš”ì²­")
        
        specific_question = generate_natural_human_question(
            file_path=file_path,
            context={
                "reasoning": meta_result.get("reasoning"),
                "message": f"Confidence {confidence:.1%}",
                "columns": context.get("columns", [])
            },
            issue_type="metadata_uncertain",
            conversation_history=conversation_history
        )
        
        return {
            "needs_human_review": True,
            "review_type": "classification",
            "human_question": specific_question,
            "ontology_context": ontology,
            "conversation_history": conversation_history,
            "logs": [f"âš ï¸ [Ontology] ë©”íƒ€ë°ì´í„° íŒë‹¨ ë¶ˆí™•ì‹¤ ({confidence:.2%})."]
        }
    
    # === Step 4: Branching ===
    
    # [Branch A] ë©”íƒ€ë°ì´í„° íŒŒì¼
    if is_metadata:
        print(f"\nğŸ“– [Metadata] ë©”íƒ€ë°ì´í„° íŒŒì¼ë¡œ í™•ì •")
        
        ontology["file_tags"][file_path] = {
            "type": "metadata",
            "role": "dictionary",
            "confidence": confidence,
            "detected_at": datetime.now().isoformat()
        }
        
        print(f"   - ë©”íƒ€ë°ì´í„° íŒŒì‹± ì¤‘...")
        new_definitions = parse_metadata_content(file_path)
        ontology["definitions"].update(new_definitions)
        
        print(f"   - ìš©ì–´ {len(new_definitions)}ê°œ ì¶”ê°€")
        
        ontology_manager.save(ontology)
        
        return {
            "ontology_context": ontology,
            "skip_indexing": True,
            "logs": [f"ğŸ“š [Ontology] ë©”íƒ€ë°ì´í„° ë“±ë¡: {len(new_definitions)}ê°œ ìš©ì–´ ì¶”ê°€"]
        }
    
    # [Branch B] ì¼ë°˜ ë°ì´í„° íŒŒì¼
    else:
        print(f"\nğŸ“Š [Data] ì¼ë°˜ ë°ì´í„° íŒŒì¼ë¡œ í™•ì •")
        
        columns = metadata.get("columns", [])
        
        ontology["file_tags"][file_path] = {
            "type": "transactional_data",
            "confidence": confidence,
            "detected_at": datetime.now().isoformat(),
            "columns": columns
        }
        
        # ê´€ê³„ ì¶”ë¡ 
        existing_data_files = [
            fp for fp, tag in ontology.get("file_tags", {}).items()
            if tag.get("type") == "transactional_data" and fp != file_path
        ]
        
        if existing_data_files:
            print(f"\nğŸ”— [Relationship] ê´€ê³„ ì¶”ë¡  ì‹œì‘...")
            print(f"   - ê¸°ì¡´ ë°ì´í„° íŒŒì¼: {len(existing_data_files)}ê°œ")
            
            table_name = os.path.basename(file_path).replace(".csv", "_table").replace(".", "_")
            
            relationship_result = infer_relationships_with_llm(
                current_table_name=table_name,
                current_cols=columns,
                ontology_context=ontology,
                current_metadata=metadata
            )
            
            new_relationships = relationship_result.get("relationships", [])
            if new_relationships:
                print(f"   - ê´€ê³„ {len(new_relationships)}ê°œ ë°œê²¬")
                
                existing_rels = ontology.get("relationships", [])
                existing_keys = {
                    (r["source_table"], r["target_table"], r["source_column"], r["target_column"])
                    for r in existing_rels
                }
                
                for new_rel in new_relationships:
                    key = (new_rel["source_table"], new_rel["target_table"], 
                           new_rel["source_column"], new_rel["target_column"])
                    if key not in existing_keys:
                        ontology["relationships"].append(new_rel)
        
        ontology_manager.save(ontology)
        
        return {
            "ontology_context": ontology,
            "skip_indexing": False,
            "logs": ["ğŸ” [Ontology] ì¼ë°˜ ë°ì´í„° í™•ì¸. ê´€ê³„ ì¶”ë¡  ì™„ë£Œ."]
        }

