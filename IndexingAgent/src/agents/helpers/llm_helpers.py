# src/agents/helpers/llm_helpers.py
"""
LLM ê´€ë ¨ í—¬í¼ í•¨ìˆ˜ë“¤ - ì‹œë§¨í‹± ë¶„ì„, ë¦¬ë·° íŒë‹¨ ë“±
"""

import os
import json
from typing import Dict, Any, List, Optional, Union

from src.agents.state import ColumnSchema
from src.agents.models import (
    ColumnSchemaResult,
    ColumnAnalysisResponse,
    EntityAnalysisResult,
    LinkableColumnInfo,
    EntityRelationType,
    safe_parse_entity,
)
from src.utils.llm_client import get_llm_client
from src.utils.ontology_manager import get_ontology_manager
from src.utils.llm_cache import get_llm_cache
from src.config import HumanReviewConfig, LLMConfig

# Lazy initialization to avoid circular imports
_llm_client = None
_ontology_manager = None
_llm_cache = None

def _get_llm_client():
    global _llm_client
    if _llm_client is None:
        _llm_client = get_llm_client()
    return _llm_client

def _get_ontology_manager():
    global _ontology_manager
    if _ontology_manager is None:
        _ontology_manager = get_ontology_manager()
    return _ontology_manager

def _get_llm_cache():
    global _llm_cache
    if _llm_cache is None:
        _llm_cache = get_llm_cache()
    return _llm_cache




# =============================================================================
# Entity Understanding
# =============================================================================

def analyze_entity_with_llm(
    metadata: Dict[str, Any],
    project_context: Dict[str, Any] = None,
    user_feedback: str = None,
    ontology_context: Dict[str, Any] = None,
    conversation_history: List[Dict] = None
) -> EntityAnalysisResult:
    """
    [LLM Decides] í…Œì´ë¸”/Signal íŒŒì¼ì˜ Entity êµ¬ì¡°ë¥¼ ì´í•´í•©ë‹ˆë‹¤.
    
    Tabularì™€ Signal íŒŒì¼ ëª¨ë‘ ì²˜ë¦¬ (ê³µí†µ ì»¨í…ìŠ¤íŠ¸ + íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸)
    
    Args:
        metadata: Processorì—ì„œ ì¶”ì¶œí•œ ë©”íƒ€ë°ì´í„° (tabular ë˜ëŠ” signal)
        project_context: í”„ë¡œì íŠ¸ ì „ì—­ ì»¨í…ìŠ¤íŠ¸
        user_feedback: ì‚¬ìš©ì í”¼ë“œë°± (ì¬ì‹¤í–‰ ì‹œ)
        ontology_context: ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ (ìš©ì–´ ì •ì˜ ë“±)
        conversation_history: ì´ì „ ëŒ€í™” ê¸°ë¡
    
    Returns:
        EntityAnalysisResult: Entity ì´í•´ ê²°ê³¼
    """
    import re
    
    # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    columns = metadata.get("columns", [])
    column_details = metadata.get("column_details", [])
    file_path = metadata.get("file_path", "")
    filename = os.path.basename(file_path)
    processor_type = metadata.get("processor_type", "tabular")
    
    if project_context is None:
        project_context = {}
    if ontology_context is None:
        ontology_context = {}
    if conversation_history is None:
        conversation_history = []
    
    # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸
    known_entities = project_context.get("known_entities", {})
    master_identifier = project_context.get("master_entity_identifier")  # TODO: master_entity_identifierë¡œ ë³€ê²½ í•„ìš”
    definitions = ontology_context.get("definitions", {})
    processed_files = project_context.get("processed_signal_files", [])
    
    print(f"   ğŸ” [LLM] Entity ë¶„ì„ ì¤‘... (file: {filename}, type: {processor_type})")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ê³µí†µ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (Tabular/Signal ë™ì¼)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    shared_context_parts = []
    
    # 1) Known entities (ë‹¤ë¥¸ í…Œì´ë¸”ì—ì„œ ë°œê²¬ëœ)
    if known_entities:
        entity_lines = [f"- {col}: {info.get('entity', 'unknown')}" 
                       for col, info in known_entities.items()]
        shared_context_parts.append(
            f"[KNOWN ENTITIES FROM OTHER TABLES]\n" + "\n".join(entity_lines)
        )
    
    # 2) ì´ì „ ëŒ€í™” ê¸°ë¡
    if conversation_history:
        turns = conversation_history.get("turns", []) if isinstance(conversation_history, dict) else conversation_history
        recent_turns = turns[-5:] if turns else []
        conv_lines = []
        for turn in recent_turns:
            role = turn.get("role", "unknown")
            content = turn.get("content", "")[:150]
            file_ref = turn.get("file", "")
            conv_lines.append(f"[{role}] {file_ref}: {content}")
        shared_context_parts.append(
            f"[PREVIOUS CONVERSATION]\n" + "\n".join(conv_lines)
        )
    
    # 3) ì´ì „ì— ì²˜ë¦¬ëœ íŒŒì¼ë“¤ (Signalìš©ì´ì§€ë§Œ Tabularì—ë„ ìœ ìš©)
    if processed_files:
        proc_lines = [f"- {p['filename']}: {p['id_column']}={p.get('id_value', '?')}" 
                      for p in processed_files[-5:]]
        shared_context_parts.append(
            f"[PREVIOUSLY PROCESSED FILES]\n" + "\n".join(proc_lines)
        )
    
    # 4) ì‚¬ìš©ì í”¼ë“œë°± (ìµœìš°ì„ )
    if user_feedback:
        shared_context_parts.append(
            f"[USER FEEDBACK - HIGHEST PRIORITY]\n"
            f"ì‚¬ìš©ì í”¼ë“œë°±: \"{user_feedback}\"\n"
            f"ì´ í”¼ë“œë°±ì„ ë¶„ì„ì˜ ìµœìš°ì„ ìœ¼ë¡œ ë°˜ì˜í•˜ì„¸ìš”."
        )
    
    shared_context = "\n\n".join(shared_context_parts)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if processor_type == "signal":
        prompt = _build_signal_entity_prompt(metadata, shared_context, master_identifier)
    else:
        prompt = _build_tabular_entity_prompt(metadata, shared_context, master_identifier, definitions)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # LLM í˜¸ì¶œ ë° ê²°ê³¼ íŒŒì‹± (ê³µí†µ)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    try:
        response = _get_llm_client().ask_json(prompt)
        
        if isinstance(response, str):
            response = safe_parse_entity(response.strip()) or {}
        
        if "error" in response:
            print(f"   âš ï¸ LLM error: {response.get('error')}")
            return _create_default_entity_result(columns, filename, processor_type)
        
        # LinkableColumnInfo ê°ì²´ë¡œ ë³€í™˜
        linkable_cols = []
        for col_info in response.get("linkable_columns", []):
            try:
                relation_type = col_info.get("relation_type", "reference")
                if isinstance(relation_type, str) and relation_type in ["self", "parent", "child", "sibling", "reference"]:
                    rel_enum = EntityRelationType(relation_type)
                else:
                    rel_enum = EntityRelationType.REFERENCE
                    
                linkable_cols.append(LinkableColumnInfo(
                    column_name=col_info.get("column_name", ""),
                    represents_entity=col_info.get("represents_entity", "unknown"),
                    represents_entity_kr=col_info.get("represents_entity_kr", ""),
                    relation_type=rel_enum,
                    cardinality=col_info.get("cardinality", "N:1"),
                    is_primary_identifier=col_info.get("is_primary_identifier", False)
                ))
            except Exception as e:
                print(f"   âš ï¸ LinkableColumn parse error: {e}")
        
        # entity_identifier ê²°ì •
        entity_identifier = response.get("entity_identifier") or response.get("id_column")
        if not entity_identifier:
            entity_identifier = columns[0] if columns else "id"
        
        # confidence ê³„ì‚°
        confidence = float(response.get("confidence", 0.7))
        
        # ì´ì „ ì²˜ë¦¬ ê¸°ë¡ì´ ìˆìœ¼ë©´ confidence ìƒí–¥ (íŒ¨í„´ í•™ìŠµë¨)
        if processed_files and processor_type == "signal":
            confidence = max(confidence, 0.9)
        
        needs_review = confidence < HumanReviewConfig.DEFAULT_CONFIDENCE_THRESHOLD
        
        # Signal íŒŒì¼ì¸ ê²½ìš° id_value ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ LLMì´ ì¶”ë¡ í•œ ê°’)
        id_value = response.get("id_value") if processor_type == "signal" else None
        
        result = EntityAnalysisResult(
            row_represents=response.get("row_represents", "unknown"),
            row_represents_kr=response.get("row_represents_kr", "ì•Œ ìˆ˜ ì—†ìŒ"),
            entity_identifier=entity_identifier,
            linkable_columns=linkable_cols,
            hierarchy_explanation=response.get("hierarchy_explanation", ""),
            confidence=confidence,
            reasoning=response.get("reasoning", ""),
            status="CONFIRMED" if not needs_review else "NEEDS_REVIEW",
            needs_human_confirmation=needs_review,
            user_feedback_applied=user_feedback,
            id_value=id_value
        )
        
        print(f"   âœ… [LLM] Entity ë¶„ì„ ì™„ë£Œ: {result.row_represents} (identifier: {result.entity_identifier}, {confidence:.0%})")
        return result
        
    except Exception as e:
        print(f"   âŒ [LLM] Entity ë¶„ì„ ì‹¤íŒ¨: {e}")
        return _create_default_entity_result(columns, filename, processor_type)


def _build_tabular_entity_prompt(
    metadata: Dict[str, Any],
    shared_context: str,
    master_identifier: str,
    definitions: Dict[str, Any]
) -> str:
    """Tabular íŒŒì¼ìš© Entity ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    columns = metadata.get("columns", [])
    column_details = metadata.get("column_details", [])
    filename = os.path.basename(metadata.get("file_path", ""))
    
    # ì»¬ëŸ¼ ì •ë³´ ìš”ì•½
    column_summary = _build_column_summary_for_entity(columns, column_details)
    
    # ì˜¨í†¨ë¡œì§€ íŒíŠ¸
    ontology_hints = ""
    if definitions:
        relevant_defs = {k: v for k, v in list(definitions.items())[:10]}
        if relevant_defs:
            def_lines = []
            for k, v in relevant_defs.items():
                if isinstance(v, dict):
                    def_text = v.get('enriched_definition', v.get('definition', ''))
                else:
                    def_text = str(v) if v else ''
                def_lines.append(f"- {k}: {def_text[:100]}")
            ontology_hints = f"\n[ONTOLOGY HINTS]\n" + "\n".join(def_lines)
    
    return f"""You are analyzing a **TABULAR DATA FILE** (CSV/Excel with rows and columns).

[TASK]
Analyze this table and answer:
1. **row_represents**: What does each row represent? (e.g., "surgery", "patient", "lab_result")
2. **entity_identifier**: Which column uniquely identifies that entity?
3. **linkable_columns**: Which columns can be used to JOIN with other tables?
4. **hierarchy**: Entity relationships (e.g., patient â†’ surgery is 1:N)

[FILE INFORMATION]
- Data Type: TABULAR (structured rows and columns)
- Filename: {filename}
- Total columns: {len(columns)}
- Master Identifier: {master_identifier or 'Not yet determined'}

[COLUMNS DETAIL]
{column_summary}
{ontology_hints}

{shared_context}

[OUTPUT FORMAT - JSON ONLY]
{{
    "row_represents": "surgery|patient|lab_result|measurement|other",
    "row_represents_kr": "ìˆ˜ìˆ  ê¸°ë¡|í™˜ì ì •ë³´|ê²€ì‚¬ ê²°ê³¼|ì¸¡ì •ê°’|ê¸°íƒ€",
    "entity_identifier": "the column name that uniquely identifies each row",
    "linkable_columns": [
        {{
            "column_name": "caseid",
            "represents_entity": "surgery",
            "represents_entity_kr": "ìˆ˜ìˆ ",
            "relation_type": "self|parent|child|reference",
            "cardinality": "1:1|1:N|N:1",
            "is_primary_identifier": true|false
        }}
    ],
    "hierarchy_explanation": "Natural language explanation of entity relationships",
    "confidence": 0.0-1.0,
    "reasoning": "Detailed reasoning"
}}

RULES:
1. User feedback has HIGHEST priority
2. relation_type: "self"=identifies this row, "parent"=links to higher entity, "reference"=lookup
3. entity_identifier should have relation_type="self"
"""


def _build_signal_entity_prompt(
    metadata: Dict[str, Any],
    shared_context: str,
    master_identifier: str
) -> str:
    """Signal íŒŒì¼ìš© Entity ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    import re
    
    filename_info = metadata.get("filename_info", {})
    file_path = metadata.get("file_path", "")
    filename = os.path.basename(file_path)
    name_without_ext = filename_info.get("name_without_ext", os.path.splitext(filename)[0])
    
    # íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ
    numbers = re.findall(r'\d+', name_without_ext)
    potential_id = int(numbers[-1]) if numbers else None
    
    # íŠ¸ë™ ì •ë³´
    columns = metadata.get("columns", [])  # íŠ¸ë™ëª… ë¦¬ìŠ¤íŠ¸
    column_details = metadata.get("column_details", {})  # íŠ¸ë™ë³„ ìƒì„¸ ì •ë³´
    duration = metadata.get("duration", 0)
    
    # íŠ¸ë™ ìƒì„¸ ì •ë³´ í¬ë§·íŒ…
    track_summary = _format_signal_tracks(columns, column_details)
    
    return f"""You are analyzing a **SIGNAL DATA FILE** (time-series physiological measurements).

[TASK]
For this signal file:
1. What ID links this file to other data? (usually extracted from filename)
2. What entity does this file represent measurements for?

[FILE INFORMATION]
- Data Type: SIGNAL (time-series waveforms/measurements)
- Filename: {filename}
- Filename without extension: {name_without_ext}
- Numbers found in filename: {numbers}
- Potential ID from filename: {potential_id}
- Master Identifier: {master_identifier or 'Not yet determined'}

[SIGNAL TRACKS]
- Total tracks: {len(columns)}
- Duration: {duration:.1f} seconds
{track_summary}

{shared_context}

[OUTPUT FORMAT - JSON ONLY]
{{
    "row_represents": "time_series_measurement",
    "row_represents_kr": "ì‹œê³„ì—´ ì¸¡ì •ê°’",
    "entity_identifier": "the column/ID that links this file (e.g., caseid)",
    "id_value": {potential_id},
    "linkable_columns": [
        {{
            "column_name": "caseid",
            "represents_entity": "case/surgery",
            "represents_entity_kr": "ì¼€ì´ìŠ¤/ìˆ˜ìˆ ",
            "relation_type": "parent",
            "cardinality": "N:1",
            "is_primary_identifier": false
        }}
    ],
    "hierarchy_explanation": "This signal file contains measurements for case/surgery ID {potential_id}",
    "confidence": 0.0-1.0,
    "reasoning": "How you determined the ID from filename"
}}

IMPORTANT RULES:
1. User feedback has HIGHEST priority
2. If previous signal file decisions exist in conversation, follow the SAME PATTERN
   (e.g., if "0001.vital â†’ caseid=1" was confirmed, then "0002.vital â†’ caseid=2")
3. Extract ID value from filename (e.g., "0001.vital" â†’ caseid: 1, "0002.vital" â†’ caseid: 2)
4. confidence should be HIGH (0.9+) if pattern is clear from previous decisions
"""


def _format_signal_tracks(columns: List[str], column_details: Dict[str, Any]) -> str:
    """Signal íŠ¸ë™ ì •ë³´ë¥¼ í¬ë§·íŒ…"""
    if not columns:
        return "- No tracks available"
    
    lines = []
    for track_name in columns[:20]:  # ìµœëŒ€ 20ê°œë§Œ
        detail = column_details.get(track_name, {})
        if isinstance(detail, dict):
            unit = detail.get("unit", "")
            sr = detail.get("sample_rate", 0)
            col_type = detail.get("column_type", "unknown")
            lines.append(f"  - {track_name}: {col_type}, {sr}Hz, unit={unit}")
        else:
            lines.append(f"  - {track_name}")
    
    if len(columns) > 20:
        lines.append(f"  ... and {len(columns) - 20} more tracks")
    
    return "\n".join(lines)


def _build_column_summary_for_entity(
    columns: List[str],
    column_details: List[Dict]
) -> str:
    """Entity ë¶„ì„ìš© ì»¬ëŸ¼ ìš”ì•½ ìƒì„±"""
    lines = []
    
    if isinstance(column_details, list) and column_details:
        for col_info in column_details[:25]:
            col_name = col_info.get('column_name', '')
            col_type = col_info.get('column_type', 'unknown')
            dtype = col_info.get('dtype', 'unknown')
            n_unique = col_info.get('n_unique', '?')
            n_total = col_info.get('n_total', '?')
            
            # Cardinality hint
            cardinality_hint = ""
            if n_unique != '?' and n_total != '?':
                try:
                    ratio = int(n_unique) / int(n_total)
                    if ratio > 0.95:
                        cardinality_hint = " [LIKELY IDENTIFIER - high uniqueness]"
                    elif ratio < 0.01:
                        cardinality_hint = " [LIKELY CATEGORICAL - low uniqueness]"
                except:
                    pass
            
            if col_type == 'categorical':
                unique_vals = col_info.get('unique_values', [])[:5]
                lines.append(
                    f"- '{col_name}' | {dtype} | {n_unique} unique / {n_total} rows | "
                    f"samples: {unique_vals}{cardinality_hint}"
                )
            else:
                samples = col_info.get('samples', [])[:3]
                lines.append(
                    f"- '{col_name}' | {dtype} | {n_unique} unique | samples: {samples}{cardinality_hint}"
                )
    else:
        for col in columns[:25]:
            lines.append(f"- '{col}'")
    
    if len(columns) > 25:
        lines.append(f"... and {len(columns) - 25} more columns")
    
    return "\n".join(lines)


def _create_default_entity_result(columns: List[str], filename: str, processor_type: str = "tabular") -> EntityAnalysisResult:
    """ê¸°ë³¸ Entity ê²°ê³¼ ìƒì„± (LLM ì‹¤íŒ¨ ì‹œ)"""
    import re
    
    # Signal íŒŒì¼ì˜ ê²½ìš°: íŒŒì¼ëª…ì—ì„œ ID ì¶”ì¶œ ì‹œë„
    if processor_type == "signal":
        name_without_ext = os.path.splitext(filename)[0]
        numbers = re.findall(r'\d+', name_without_ext)
        identifier = "caseid"  # Signalì€ ë³´í†µ caseidë¡œ ì—°ê²°
        id_value = int(numbers[-1]) if numbers else None  # íŒŒì¼ëª…ì—ì„œ ID ê°’ ì¶”ì¶œ
        
        return EntityAnalysisResult(
            row_represents="time_series_measurement",
            row_represents_kr="ì‹œê³„ì—´ ì¸¡ì •ê°’",
            entity_identifier=identifier,
            linkable_columns=[
                LinkableColumnInfo(
                    column_name=identifier,
                    represents_entity="case",
                    represents_entity_kr="ì¼€ì´ìŠ¤",
                    relation_type=EntityRelationType.PARENT,
                    cardinality="N:1",
                    is_primary_identifier=False
                )
            ],
            hierarchy_explanation=f"Signal file - default fallback for {filename}",
            confidence=0.3,
            reasoning=f"Default fallback for signal file {filename}",
            status="NEEDS_REVIEW",
            needs_human_confirmation=True,
            id_value=id_value
        )
    
    # Tabular íŒŒì¼ì˜ ê²½ìš°: ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ identifierë¡œ ê°€ì •
    identifier = columns[0] if columns else "id"
    
    # IDë¡œ ë³´ì´ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
    id_candidates = [c for c in columns if 'id' in c.lower()]
    if id_candidates:
        identifier = id_candidates[0]
    
    return EntityAnalysisResult(
        row_represents="unknown",
        row_represents_kr="ì•Œ ìˆ˜ ì—†ìŒ",
        entity_identifier=identifier,
        linkable_columns=[
            LinkableColumnInfo(
                column_name=identifier,
                represents_entity="unknown",
                represents_entity_kr="ì•Œ ìˆ˜ ì—†ìŒ",
                relation_type=EntityRelationType.SELF,
                cardinality="1:1",
                is_primary_identifier=True
            )
        ],
        hierarchy_explanation="Unable to determine entity structure",
        confidence=0.3,
        reasoning=f"Default fallback for {filename}",
        status="NEEDS_REVIEW",
        needs_human_confirmation=True
    )


def analyze_columns_with_llm(
    columns: List[str], 
    sample_data: Any, 
    entity_context: Dict,
    user_feedback: str = None,
    ontology_context: Dict[str, Any] = None
) -> List[ColumnSchemaResult]:
    """
    [Helper] Analyze column meaning, data type, PII status, units, etc. using LLM
    
    Args:
        columns: ë¶„ì„í•  ì»¬ëŸ¼ëª… ëª©ë¡
        sample_data: ìƒ˜í”Œ ë°ì´í„° (list ë˜ëŠ” dict)
        entity_context: Entity Identification ì •ë³´
        user_feedback: ì‚¬ìš©ìê°€ ì œê³µí•œ ì»¬ëŸ¼/ë°ì´í„° ì„¤ëª…
        ontology_context: ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ (ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œí•œ ìš©ì–´ ì •ì˜)
    
    Returns:
        List[ColumnSchemaResult]: Pydantic ëª¨ë¸ë¡œ êµ¬ì¡°í™”ëœ ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼
    """
    if ontology_context is None:
        ontology_context = {}
    
    definitions = ontology_context.get("definitions", {})
    
    # User feedback context
    user_context = ""
    if user_feedback:
        user_context = f"""
    [USER FEEDBACK - PRIORITIZE THIS INFORMATION]
    The user has provided the following context about this data:
    "{user_feedback}"
    
    Use this information to improve your analysis accuracy.
    """
    
    # Ontology definitions context (ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œí•œ ìš©ì–´ ì •ì˜)
    definitions_context = ""
    if definitions:
        relevant_defs = []
        for col in columns[:30]:  # ìƒìœ„ 30ê°œ ì»¬ëŸ¼
            col_lower = col.lower()
            for def_key, def_value in definitions.items():
                if col_lower == def_key.lower() or col_lower in def_key.lower():
                    relevant_defs.append(f"    - {def_key}: {str(def_value)[:150]}")
                    break
        
        if relevant_defs:
            definitions_context = f"""
    [ONTOLOGY DEFINITIONS - IMPORTANT: Use these as ground truth]
    The following definitions were extracted from the dataset's official metadata files.
    Prioritize these over guessing:
{chr(10).join(relevant_defs)}
    """
    
    # Context summary for LLM
    prompt = f"""
    You are a Medical Data Ontologist specializing in clinical database design.
    Analyze the columns of a medical dataset and provide DETAILED metadata.
    {user_context}
    {definitions_context}
    [Context]
    - Entity Identifier Column: {entity_context.get('column_name')}
    - Is Time Series: {entity_context.get('is_time_series')}
    
    [Columns to Analyze]
    """
    
    # If sample_data is a list (from TabularProcessor)
    if isinstance(sample_data, list):
        for col_detail in sample_data:
            col_name = col_detail.get('column_name', 'unknown')
            col_type = col_detail.get('column_type', 'unknown')
            samples = col_detail.get('samples', [])
            
            if col_type == 'categorical':
                unique_vals = col_detail.get('unique_values', [])
                prompt += f"- Column: '{col_name}' | Type: CATEGORICAL | Unique Values: {unique_vals}\n"
            else:
                min_val = col_detail.get('min', 'N/A')
                max_val = col_detail.get('max', 'N/A')
                prompt += f"- Column: '{col_name}' | Type: CONTINUOUS | Range: [{min_val}, {max_val}] | Samples: {samples}\n"
    elif isinstance(sample_data, dict):
        for col in columns:
            details = sample_data.get(col, {})
            samples = details.get("sample_values", [])
            prompt += f"- Column: '{col}', Samples: {samples}\n"
    else:
        for col in columns:
            prompt += f"- Column: '{col}'\n"

    prompt += """
    [Task]
    For EACH column, provide a JSON object with DETAILED metadata:
    
    1. original_name: The exact column name as provided (REQUIRED)
    2. inferred_name: Human-readable name (e.g., 'sbp' â†’ 'Systolic Blood Pressure')
    3. full_name: Full medical term without abbreviation
    4. description: Brief medical description
    5. description_kr: Korean description for Korean users (í•œê¸€ ì„¤ëª…)
    6. data_type: SQL compatible type (VARCHAR, INT, FLOAT, TIMESTAMP, BOOLEAN)
    7. semantic_type: High-level semantic category (e.g., "identifier", "timestamp", "measurement", "demographic", "clinical_score", "outcome")
    8. column_type: "categorical" or "continuous" based on the data nature
    9. unit: Measurement unit if applicable (e.g., "mmHg", "kg", null if N/A)
    10. typical_range: Normal/typical value range in medical context (null if N/A)
    11. is_pii: Boolean (true if it contains name, phone, address, social security number)
    12. confidence: 0.0 to 1.0
    13. value_mappings: (ONLY for CATEGORICAL columns) Dictionary mapping each unique value to its meaning
        - Example: sex column with values [0, 1] â†’ {"0": "Male", "1": "Female"}
        - Example: asa column with values [1,2,3,4,5] â†’ {"1": "Normal healthy patient", "2": "Mild systemic disease", ...}
        - For CONTINUOUS/NUMERIC columns: null
        - If meaning cannot be inferred: null

    Respond with a JSON object: {"columns": [list of column objects]}
    """
    from src.config import LLMConfig
    
    # ì»¬ëŸ¼ ë¶„ì„ì€ value_mappings ë“±ìœ¼ë¡œ í† í°ì´ ë§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
    response = _get_llm_client().ask_json(prompt, max_tokens=LLMConfig.MAX_TOKENS_COLUMN_ANALYSIS)
    
    if isinstance(response, dict) and "columns" in response:
        result_list = response["columns"]
    elif isinstance(response, list):
        result_list = response
    else:
        result_list = []

    final_schema: List[ColumnSchemaResult] = []
    for idx, item in enumerate(result_list):
        original = item.get("original_name") or (columns[idx] if idx < len(columns) else "unknown")
        
        # value_mappings ì²˜ë¦¬: dictì—¬ì•¼ í•˜ê³ , ë¹„ì–´ìˆìœ¼ë©´ nullë¡œ ì²˜ë¦¬
        value_mappings = item.get("value_mappings")
        if value_mappings is not None and not isinstance(value_mappings, dict):
            value_mappings = None
        if isinstance(value_mappings, dict) and len(value_mappings) == 0:
            value_mappings = None
        
        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ (ìë™ ê²€ì¦)
        final_schema.append(ColumnSchemaResult(
            original_name=original,
            inferred_name=item.get("inferred_name", original),
            full_name=item.get("full_name", item.get("inferred_name", original)),
            description=item.get("description", ""),
            description_kr=item.get("description_kr", ""),
            data_type=item.get("data_type", "VARCHAR"),
            semantic_type=item.get("semantic_type"),
            column_type=item.get("column_type"),
            unit=item.get("unit"),
            typical_range=item.get("typical_range"),
            is_pii=item.get("is_pii", False),
            confidence=item.get("confidence", 0.5),
            value_mappings=value_mappings
        ))
        
    return final_schema


def analyze_intra_table_hierarchy(
    columns: List[str],
    sample_data: Any,
    table_name: str,
    user_feedback: str = None  # NEW: ì‚¬ìš©ì í”¼ë“œë°± ì „ë‹¬
) -> Optional[Dict]:
    """
    [LLM] í…Œì´ë¸” ë‚´ ID ì»¬ëŸ¼ ê°„ì˜ ê³„ì¸µ ê´€ê³„ ê°ì§€
    
    ì˜ˆ: subjectid (í™˜ì) â†’ caseid (ìˆ˜ìˆ ) = 1:N ê´€ê³„
    í•œ í™˜ìê°€ ì—¬ëŸ¬ ë²ˆì˜ ìˆ˜ìˆ ì„ ë°›ì„ ìˆ˜ ìˆìŒ
    
    Args:
        user_feedback: ì‚¬ìš©ìê°€ ì œê³µí•œ ì»¬ëŸ¼ ê´€ê³„ ì„¤ëª… (ì˜ˆ: "subjectidëŠ” í™˜ìID, caseidëŠ” ìˆ˜ìˆ ID")
    
    Returns:
        {
            "child_column": "caseid",
            "parent_column": "subjectid",
            "cardinality": "N:1",
            "reasoning": "..."
        }
        ë˜ëŠ” None (ê³„ì¸µ ê´€ê³„ ì—†ìŒ)
    """
    # ID ì»¬ëŸ¼ í›„ë³´ í•„í„°ë§ (id, _idë¡œ ëë‚˜ëŠ” ì»¬ëŸ¼ë“¤)
    id_columns = [col for col in columns if 
                  col.lower().endswith('id') or 
                  col.lower().endswith('_id') or
                  col.lower() in ['id', 'key', 'code']]
    
    if len(id_columns) < 2:
        print(f"   â„¹ï¸ [Hierarchy] ID ì»¬ëŸ¼ì´ 2ê°œ ë¯¸ë§Œ ({id_columns}) - ìŠ¤í‚µ")
        return None
    
    # ìƒ˜í”Œ ë°ì´í„°ì—ì„œ ID ì»¬ëŸ¼ë“¤ì˜ ê°’ ë¶„í¬ ì¶”ì¶œ
    id_samples = {}
    if isinstance(sample_data, list):
        for col_detail in sample_data:
            col_name = col_detail.get('column_name', '')
            if col_name in id_columns:
                # TabularProcessorëŠ” 'n_unique' í•„ë“œë¥¼ ì œê³µí•¨
                n_unique = col_detail.get('n_unique', 0)
                # unique_values ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´ë¡œë„ ê³„ì‚° ê°€ëŠ¥
                if n_unique == 0:
                    unique_vals = col_detail.get('unique_values', [])
                    n_unique = len(unique_vals) if isinstance(unique_vals, list) else 0
                
                id_samples[col_name] = {
                    "unique_count": n_unique,
                    "sample_values": col_detail.get('samples', [])[:10],
                    "column_type": col_detail.get('column_type', 'unknown')
                }
    
    # ì‚¬ìš©ì í”¼ë“œë°±ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    user_context = ""
    if user_feedback:
        user_context = f"""
[USER FEEDBACK - IMPORTANT, PRIORITIZE THIS]
The user has provided the following explanation about the column relationships:
"{user_feedback}"

"""

    prompt = f"""You are a Medical Data Expert analyzing table structure.

[TASK]
Analyze the ID columns in this table to find parent-child relationships.
A parent-child relationship exists when:
1. One ID column has FEWER unique values than another
2. The column with MORE unique values is likely grouped under the other
{user_context}
[TABLE]
Table Name: {table_name}

[ID COLUMNS - unique_count shows number of distinct values]
{json.dumps(id_samples, indent=2)}

[EXAMPLE]
If subjectid has unique_count=1000 and caseid has unique_count=6000,
then: caseid is CHILD of subjectid (N:1 relationship)
- Meaning: One patient (subjectid) can have multiple surgery cases (caseid)
- Ratio ~6:1 suggests each patient has ~6 cases on average

[RESPONSE FORMAT - JSON ONLY]
If hierarchy found:
{{
    "hierarchy_found": true,
    "child_column": "caseid",
    "parent_column": "subjectid",
    "cardinality": "N:1",
    "hierarchy_type": "patient_to_case",
    "reasoning": "subjectid has 1000 unique values, caseid has 6000, ratio ~6:1 suggests multiple cases per patient"
}}

If NO hierarchy:
{{
    "hierarchy_found": false,
    "reasoning": "All ID columns appear to be independent identifiers or have 1:1 relationship"
}}

IMPORTANT:
- Common medical hierarchies: patient â†’ case/visit â†’ measurement
"""
    
    try:
        result = _get_llm_client().ask_json(prompt)
        
        if not result.get("hierarchy_found", False):
            print(f"   â„¹ï¸ [Hierarchy] ê³„ì¸µ ê´€ê³„ ì—†ìŒ: {result.get('reasoning', '')}")
            return None
        
        hierarchy = {
            "child_column": result.get("child_column"),
            "parent_column": result.get("parent_column"),
            "cardinality": result.get("cardinality", "N:1"),
            "hierarchy_type": result.get("hierarchy_type", "unknown"),
            "reasoning": result.get("reasoning", "")
        }
        
        print(f"   âœ… [Hierarchy] ë°œê²¬: {hierarchy['child_column']} â†’ {hierarchy['parent_column']} ({hierarchy['cardinality']})")
        print(f"      ê·¼ê±°: {hierarchy['reasoning'][:100]}...")
        
        return hierarchy
        
    except Exception as e:
        print(f"   âš ï¸ [Hierarchy] ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None


def analyze_tracks_with_llm(tracks: List[str], column_details: Dict) -> Dict[str, Dict]:
    """
    [LLM Decides] Signal íŠ¸ë™ì˜ ì˜ë¯¸ë¥¼ LLMì´ ë¶„ì„
    """
    if not tracks:
        return {}
    
    tracks_summary = ""
    for track_name in tracks[:20]:
        details = column_details.get(track_name, {})
        unit = details.get("unit", "N/A")
        sr = details.get("sample_rate", 0)
        col_type = details.get("column_type", "unknown")
        
        tracks_summary += f"- Track: '{track_name}' | Unit: {unit} | Sample Rate: {sr}Hz | Type: {col_type}\n"
    
    if len(tracks) > 20:
        tracks_summary += f"  ... and {len(tracks) - 20} more tracks\n"
    
    prompt = f"""You are a Medical Signal Processing Expert.
Analyze the following signal tracks and provide detailed metadata for each.

[SIGNAL TRACKS - Pre-processed by Rules]
{tracks_summary}

[TASK]
For each track, determine:
1. **inferred_name**: Human-readable name (e.g., 'SNUADC/ECG_II' â†’ 'Lead II ECG')
2. **description**: Brief medical description
3. **clinical_category**: One of: cardiac_waveform, cardiac_vital, respiratory, neurological, temperature, anesthesia, other

[RESPONSE FORMAT - JSON]
{{
    "tracks": {{
        "track_name": {{
            "inferred_name": "Human readable name",
            "description": "Brief description",
            "clinical_category": "category"
        }}
    }}
}}
"""
    
    try:
        result = _get_llm_client().ask_json(prompt)
        tracks_analysis = result.get("tracks", {})
        
        for track_name in tracks:
            if track_name not in tracks_analysis:
                tracks_analysis[track_name] = {
                    "inferred_name": track_name,
                    "description": "",
                    "clinical_category": "other"
                }
        
        print(f"   ğŸ§  [LLM] Analyzed {len(tracks_analysis)} tracks")
        return tracks_analysis
        
    except Exception as e:
        print(f"   âš ï¸ [LLM] Track analysis failed: {e}")
        return {track_name: {
            "inferred_name": track_name,
            "description": "",
            "clinical_category": "other"
        } for track_name in tracks}


def compare_with_global_context(
    local_metadata: Dict, 
    local_identification_info: Dict, 
    project_context: Dict,
    ontology_context: Optional[Dict] = None
) -> Dict[str, Any]:
    """
    [Helper] Compare current file data with project Global Entity Identifier info (using LLM)
    
    Returns:
    - MATCH: ì™„ì „ ì¼ì¹˜
    - CONFLICT/MISSING: ì—°ê²° ë¶ˆê°€
    """
    master_name = project_context["master_entity_identifier"]
    local_cols = local_metadata.get("columns", [])
    local_candidate = local_identification_info.get("target_column")
    
    # 1. ì´ë¦„ì´ ì™„ì „íˆ ê°™ì€ ê²½ìš° (Fast Path)
    if master_name in local_cols:
        return {"status": "MATCH", "target_column": master_name, "message": "Exact name match"}

    # 2. ë¡œì»¬ í›„ë³´ê°€ ì—†ëŠ” ê²½ìš°
    if not local_candidate:
        return {
            "status": "MISSING",
            "target_column": None,
            "message": f"No identifier candidate found. Master identifier '{master_name}' not found in columns: {local_cols}"
        }

    # 3. LLMì„ í†µí•œ ì˜ë¯¸ë¡ ì  ë¹„êµ
    prompt = f"""
    You are a Medical Data Integration Agent.
    Check if the new file contains the Project's Master Entity Identifier (Patient ID).

    [Project Context / Global Master]
    - Master Entity Identifier: '{master_name}'
    - Known Aliases: {project_context.get('known_aliases')}
    
    [New File Info]
    - Candidate Column found by AI: '{local_candidate}'
    - All Columns in file: {local_cols}
    
    [Task]
    Determine if any column represents the same 'Patient ID' entity as the Global Master.

    Respond with JSON:
    {{
        "status": "MATCH" or "MISSING" or "CONFLICT",
        "target_column": "name_of_column" or null,
        "message": "Reasoning"
    }}
    """
    
    try:
        result = _get_llm_client().ask_json(prompt)
        
        if not isinstance(result, dict):
            return {"status": "CONFLICT", "target_column": None, "message": "LLM returned invalid format"}
        
        status = result.get("status", "CONFLICT").upper()
        if status not in ["MATCH", "MISSING", "CONFLICT"]:
            status = "CONFLICT"
        
        return {
            "status": status,
            "target_column": result.get("target_column"),
            "message": result.get("message", "No explanation provided")
        }
        
    except Exception as e:
        return {"status": "CONFLICT", "target_column": None, "message": f"Error: {str(e)}"}


def should_request_human_review(
    file_path: str,
    issue_type: str,
    context: Dict[str, Any],
    rule_based_confidence: float = 1.0
) -> Dict[str, Any]:
    """
    [Helper] Human Reviewê°€ í•„ìš”í•œì§€ íŒë‹¨ (Rule + LLM Hybrid)
    """
    filename = os.path.basename(file_path)
    
    # === 1ë‹¨ê³„: Rule-based íŒë‹¨ ===
    threshold = _get_threshold_for_issue(issue_type)
    
    rule_decision = {
        "needs_review": rule_based_confidence < threshold,
        "reason": f"Confidence {rule_based_confidence:.1%} < Threshold {threshold:.1%}",
        "confidence": rule_based_confidence
    }
    
    if not HumanReviewConfig.USE_LLM_FOR_REVIEW_DECISION:
        print(f"   [Rule-only] {issue_type}: needs_review={rule_decision['needs_review']}")
        return rule_decision
    
    # === 2ë‹¨ê³„: LLM ê¸°ë°˜ íŒë‹¨ ===
    if rule_based_confidence < HumanReviewConfig.LLM_SKIP_CONFIDENCE_THRESHOLD:
        print(f"   [Rule] Low confidence ({rule_based_confidence:.1%}), skipping LLM check")
        return rule_decision
    
    llm_decision = ask_llm_for_review_decision(
        filename=filename,
        issue_type=issue_type,
        context=context,
        rule_confidence=rule_based_confidence
    )
    
    # === 3ë‹¨ê³„: Ruleê³¼ LLM ê²°ê³¼ ì¢…í•© ===
    final_needs_review = rule_decision["needs_review"] or llm_decision.get("needs_review", False)
    
    combined_reason = []
    if rule_decision["needs_review"]:
        combined_reason.append(f"Rule: {rule_decision['reason']}")
    if llm_decision.get("needs_review"):
        combined_reason.append(f"LLM: {llm_decision.get('reason', 'LLM recommended review')}")
    
    result = {
        "needs_review": final_needs_review,
        "reason": " | ".join(combined_reason) if combined_reason else "No issues detected",
        "confidence": rule_based_confidence,
        "llm_opinion": llm_decision.get("reason", "N/A")
    }
    
    print(f"   [Hybrid] {issue_type}: needs_review={final_needs_review}")
    
    return result


def _get_threshold_for_issue(issue_type: str) -> float:
    """ì´ìŠˆ ìœ í˜•ë³„ Threshold ë°˜í™˜"""
    thresholds = {
        "metadata_classification": HumanReviewConfig.METADATA_CONFIDENCE_THRESHOLD,
        "entity_detection": HumanReviewConfig.ANCHOR_CONFIDENCE_THRESHOLD,
        "entity_conflict": HumanReviewConfig.ANCHOR_CONFIDENCE_THRESHOLD,
        "general": HumanReviewConfig.FILENAME_ANALYSIS_CONFIDENCE_THRESHOLD
    }
    return thresholds.get(issue_type, HumanReviewConfig.DEFAULT_CONFIDENCE_THRESHOLD)


def ask_llm_for_review_decision(
    filename: str,
    issue_type: str,
    context: Dict[str, Any],
    rule_confidence: float
) -> Dict[str, Any]:
    """LLMì—ê²Œ Human Review í•„ìš” ì—¬ë¶€ íŒë‹¨ ìš”ì²­"""
    
    prompt = f"""
    You are an AI assistant helping with medical data processing.
    Based on the following situation, decide if human intervention is needed.

    [Situation]
    - File: {filename}
    - Issue Type: {issue_type}
    - Rule-based Confidence: {rule_confidence:.1%}
    - Context: {json.dumps(context, ensure_ascii=False, default=str)[:500]}...

    [Decision Criteria]
    Return "needs_review": true if:
    1. The context shows ambiguous or conflicting information
    2. Critical decisions might affect data integrity
    3. Domain expertise is clearly needed
    4. Multiple valid interpretations exist

    Respond with JSON only:
    {{
        "needs_review": true or false,
        "reason": "Brief explanation"
    }}
    """
    
    try:
        result = _get_llm_client().ask_json(prompt)
        return {
            "needs_review": result.get("needs_review", False),
            "reason": result.get("reason", "LLM did not provide reason")
        }
    except Exception as e:
        print(f"   âš ï¸ [LLM Review Decision] Error: {e}")
        return {"needs_review": False, "reason": f"LLM error: {str(e)}"}


def ask_llm_is_metadata(context: dict) -> dict:
    """
    [LLM] Determine if file is metadata
    """
    cached = _get_llm_cache().get("metadata_detection", context)
    if cached:
        return cached
    
    prompt = f"""
You are a Data Classification Expert.

I have pre-processed file information using rules. Based on these facts, determine if this is METADATA or TRANSACTIONAL DATA.

[PRE-PROCESSED FILE INFORMATION]
Filename: {context['filename']}
Parsed Name Parts: {context['name_parts']}
Base Name: {context['base_name']}
Extension: {context['extension']}
Number of Columns: {context['num_columns']}
Columns: {context['columns']}

[PRE-PROCESSED SAMPLE DATA]
{json.dumps(context['sample_data'], indent=2)}

[DEFINITION]
- METADATA file: Describes OTHER data (column definitions, parameter lists, codebooks)
- TRANSACTIONAL DATA: Actual records/measurements

[OUTPUT FORMAT - JSON ONLY]
{{
    "is_metadata": true or false,
    "confidence": 0.0 to 1.0,
    "reasoning": "Brief explanation",
    "indicators": {{
        "filename_hint": "strong/weak/none",
        "structure_hint": "dictionary-like/tabular/unclear",
        "content_type": "descriptive/transactional/mixed"
    }}
}}
"""
    
    try:
        result = _get_llm_client().ask_json(prompt)
        
        # Check for error response from ask_json
        if "error" in result:
            error_msg = result.get("error", "Unknown error")
            print(f"âŒ [Metadata Detection] LLM returned error: {error_msg}")
            return {
                "is_metadata": False,
                "confidence": 0.0,
                "reasoning": f"LLM error: {error_msg}",
                "indicators": {},
                "needs_human_review": True
            }
        
        _get_llm_cache().set("metadata_detection", context, result)
        
        confidence = result.get("confidence", 0.0)
        if confidence < HumanReviewConfig.METADATA_DETECTION_CONFIDENCE_THRESHOLD:
            print(f"âš ï¸  [Metadata Detection] Low confidence ({confidence:.2%})")
        
        return result
        
    except Exception as e:
        print(f"âŒ [Metadata Detection] LLM Error: {e}")
        return {
            "is_metadata": False,
            "confidence": 0.0,
            "reasoning": f"LLM error: {str(e)}",
            "indicators": {},
            "needs_human_review": True
        }

