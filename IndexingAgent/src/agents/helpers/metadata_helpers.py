# src/agents/helpers/metadata_helpers.py
"""
ë©”íƒ€ë°ì´í„° ì²˜ë¦¬ ê´€ë ¨ í—¬í¼ í•¨ìˆ˜ë“¤
"""

import os
import json
import pandas as pd
from typing import Dict, Any, List, Optional

from src.utils.llm_client import get_llm_client
from src.utils.llm_cache import get_llm_cache
from src.config import HumanReviewConfig, MetadataEnrichmentConfig


# Lazy initialization
_llm_client = None
_llm_cache = None


def _get_llm_client():
    global _llm_client
    if _llm_client is None:
        _llm_client = get_llm_client()
    return _llm_client


def _get_llm_cache():
    global _llm_cache
    if _llm_cache is None:
        _llm_cache = get_llm_cache()
    return _llm_cache


def parse_metadata_content(file_path: str) -> dict:
    """
    [Rule] Parse metadata file using Processor
    
    Processorë¥¼ í™œìš©í•˜ì—¬ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    - Processorê°€ extract_metadata()ë¡œ ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ
    - ì¶”ì¶œëœ column_detailsë¥¼ definitions í˜•íƒœë¡œ ë³€í™˜
    - Processorê°€ ì—†ê±°ë‚˜ ì—ëŸ¬ ë°œìƒ ì‹œ í´ë°±ìœ¼ë¡œ ì§ì ‘ íŒŒì‹±
    """
    from src.agents.nodes.common import processors
    
    definitions = {}
    filename = os.path.basename(file_path)
    
    try:
        # 1. ì í•©í•œ Processor ì°¾ê¸°
        processor = next((p for p in processors if p.can_handle(file_path)), None)
        
        if not processor:
            print(f"      âš ï¸ Processor ì—†ìŒ: {filename} - ì§ì ‘ íŒŒì‹± ì‹œë„")
            return _parse_metadata_fallback(file_path)
        
        # 2. Processorë¡œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        raw_metadata = processor.extract_metadata(file_path)
        
        if not raw_metadata:
            print(f"      âš ï¸ Processor ë©”íƒ€ë°ì´í„° ì—†ìŒ - ì§ì ‘ íŒŒì‹± ì‹œë„")
            return _parse_metadata_fallback(file_path)
        
        # 3. ì¶”ì¶œëœ column_detailsë¥¼ definitions í˜•íƒœë¡œ ë³€í™˜
        column_details = raw_metadata.get('column_details', [])
        
        if column_details:
            for col_info in column_details:
                col_name = col_info.get('column_name', '')
                if not col_name:
                    continue
                    
                # ì»¬ëŸ¼ ì •ë³´ë¡œë¶€í„° definition ë¬¸ìì—´ ìƒì„±
                desc = _build_definition_from_column_info(col_info)
                definitions[col_name] = desc
        
        # 4. ë©”íƒ€ë°ì´í„° íŒŒì¼ íŠ¹ì„±: ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ key, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ descriptionì¸ ê²½ìš° ì¶”ê°€ ì²˜ë¦¬
        # (ì˜ˆ: definitions.csv, dictionary.csv ë“±)
        if len(column_details) >= 2:
            extra_definitions = _extract_key_value_definitions(file_path)
            if extra_definitions:
                definitions.update(extra_definitions)
        
        return definitions
        
    except Exception as e:
        print(f"      âŒ [Processor Parse Error] {filename}: {e}")
        # í´ë°±: ì§ì ‘ íŒŒì‹± ì‹œë„
        return _parse_metadata_fallback(file_path)


def _build_definition_from_column_info(col_info: dict) -> str:
    """
    Processorì˜ column_infoë¥¼ definition ë¬¸ìì—´ë¡œ ë³€í™˜
    """
    parts = []
    
    col_type = col_info.get('column_type', 'unknown')
    dtype = col_info.get('dtype', 'unknown')
    
    parts.append(f"Type: {col_type}")
    parts.append(f"dtype: {dtype}")
    
    if col_type == 'categorical':
        unique_values = col_info.get('unique_values', [])
        n_unique = col_info.get('n_unique', len(unique_values))
        parts.append(f"unique: {n_unique}")
        if unique_values:
            # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            sample_vals = unique_values[:5] if isinstance(unique_values, list) else [str(unique_values)]
            parts.append(f"values: {sample_vals}")
    else:  # continuous
        min_val = col_info.get('min')
        max_val = col_info.get('max')
        if min_val is not None and max_val is not None:
            parts.append(f"range: [{min_val}, {max_val}]")
        samples = col_info.get('samples', [])
        if samples:
            parts.append(f"samples: {samples[:3]}")
    
    return " | ".join(parts)


def _extract_key_value_definitions(file_path: str) -> dict:
    """
    ë©”íƒ€ë°ì´í„° íŒŒì¼ì—ì„œ key-value í˜•íƒœì˜ definitions ì¶”ì¶œ
    (ì²« ë²ˆì§¸ ì»¬ëŸ¼ = key, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ = description)
    """
    definitions = {}
    
    try:
        df = pd.read_csv(file_path)
        
        if len(df.columns) >= 2:
            key_col = df.columns[0]
            desc_col = df.columns[1]
            
            for _, row in df.iterrows():
                key = str(row[key_col]).strip()
                desc = str(row[desc_col]).strip()
                
                # NaN ì²´í¬
                if key == 'nan' or desc == 'nan':
                    continue
                
                # ì¶”ê°€ ì»¬ëŸ¼ ì •ë³´ í¬í•¨
                extra_info = []
                for col in df.columns[2:]:
                    val = row[col]
                    if pd.notna(val) and str(val).strip() and str(val).strip() != 'nan':
                        extra_info.append(f"{col}={val}")
                
                if extra_info:
                    desc += " | " + " | ".join(extra_info)
                
                definitions[key] = desc
        
        return definitions
        
    except Exception:
        return {}


def _parse_metadata_fallback(file_path: str) -> dict:
    """
    Processor ì‹¤íŒ¨ ì‹œ ì§ì ‘ íŒŒì‹± í´ë°±
    """
    definitions = {}
    
    try:
        df = pd.read_csv(file_path)
        
        if len(df.columns) >= 2:
            key_col = df.columns[0]
            desc_col = df.columns[1]
            
            for _, row in df.iterrows():
                key = str(row[key_col]).strip()
                desc = str(row[desc_col]).strip()
                
                if key == 'nan' or desc == 'nan':
                    continue
                
                extra_info = []
                for col in df.columns[2:]:
                    val = row[col]
                    if pd.notna(val) and str(val).strip() and str(val).strip() != 'nan':
                        extra_info.append(f"{col}={val}")
                
                if extra_info:
                    desc += " | " + " | ".join(extra_info)
                
                definitions[key] = desc
        
        return definitions
        
    except Exception as e:
        print(f"      âŒ [Fallback Parse Error] {file_path}: {e}")
        return {}


def build_lightweight_classification_context(file_path: str, max_rows: int = 10) -> dict:
    """
    [Rule] íŒŒì¼ì—ì„œ ì§ì ‘ ê°„ë‹¨í•œ ìƒ˜í”Œë§Œ ì½ì–´ ë¶„ë¥˜ìš© context ìƒì„± (extract_metadata ì—†ì´)
    
    batch_classifierì—ì„œ metadata vs data ë¶„ë¥˜ë§Œ í•  ë•Œ ì‚¬ìš©.
    ì „ì²´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œì€ loader ë…¸ë“œì—ì„œ ë³„ë„ë¡œ ìˆ˜í–‰.
    """
    basename = os.path.basename(file_path)
    name_without_ext = os.path.splitext(basename)[0]
    extension = os.path.splitext(basename)[1].lower()
    
    parts = name_without_ext.split('_')
    base_name = parts[0] if parts else name_without_ext
    
    columns = []
    sample_data = []
    
    try:
        # CSV/TSV íŒŒì¼ë§Œ ì²˜ë¦¬ (ë‹¤ë¥¸ í˜•ì‹ì€ rule-basedë¡œ ì²˜ë¦¬)
        if extension in ['.csv', '.tsv']:
            sep = '\t' if extension == '.tsv' else ','
            df = pd.read_csv(file_path, nrows=max_rows, sep=sep)
            columns = df.columns.tolist()
            
            # ê°„ë‹¨í•œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            for col in columns[:10]:  # ìµœëŒ€ 10ê°œ ì»¬ëŸ¼ë§Œ
                col_data = df[col].dropna()
                unique_vals = col_data.unique()[:5].tolist()  # ìµœëŒ€ 5ê°œ unique values
                
                # numpy íƒ€ì…ì„ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                unique_vals = [
                    int(v) if hasattr(v, 'item') and isinstance(v.item(), int) else
                    float(v) if hasattr(v, 'item') and isinstance(v.item(), float) else
                    str(v) for v in unique_vals
                ]
                
                sample_data.append({
                    "column": col,
                    "samples": unique_vals,
                    "is_text": df[col].dtype == object
                })
        else:
            # ë¹„-CSV íŒŒì¼ì€ íŒŒì¼ëª…ë§Œìœ¼ë¡œ íŒë‹¨
            pass
            
    except Exception as e:
        print(f"âš ï¸ [Lightweight Context] Error reading {basename}: {e}")
    
    return {
        "filename": basename,
        "name_parts": parts,
        "base_name": base_name,
        "extension": extension,
        "columns": columns,
        "num_columns": len(columns),
        "sample_data": sample_data,
        "avg_text_length_overall": 0,  # ê°„ì†Œí™” - ì‚¬ìš© ì•ˆí•¨
        "context_size_bytes": 0
    }


def extract_filename_hints(filename: str) -> dict:
    """
    [Rule + LLM] Extract semantic hints from filename
    """
    basename = os.path.basename(filename)
    name_without_ext = os.path.splitext(basename)[0]
    extension = os.path.splitext(basename)[1]
    
    parts = name_without_ext.split('_')
    base_name = parts[0] if parts else name_without_ext
    
    prefix = parts[0] if len(parts) >= 2 else None
    suffix = parts[-1] if len(parts) >= 2 else None
    
    parsed_structure = {
        "original_filename": basename,
        "name_without_ext": name_without_ext,
        "extension": extension,
        "parts": parts,
        "base_name": base_name,
        "prefix": prefix,
        "suffix": suffix,
        "has_underscore": '_' in name_without_ext,
        "num_parts": len(parts)
    }
    
    cached = _get_llm_cache().get("filename_hints", parsed_structure)
    if cached:
        return cached
    
    prompt = f"""
You are a Data Architecture Analyst.
Infer semantic meaning from this parsed filename structure.

[PARSED FILENAME STRUCTURE]
{json.dumps(parsed_structure, indent=2)}

[TASK]
Infer:
1. **Entity Type**: What domain entity does base_name represent?
2. **Scope**: individual, event, measurement, treatment
3. **Suggested Hierarchy Level**: 1(highest) to 5(lowest)
4. **Data Type Indicator**: transactional, metadata, or reference

[OUTPUT FORMAT - JSON]
{{
    "entity_type": "Laboratory" or null,
    "scope": "measurement" or null,
    "suggested_level": 4 or null,
    "data_type_indicator": "transactional" or "metadata",
    "related_file_patterns": [],
    "confidence": 0.0 to 1.0,
    "reasoning": "Brief explanation"
}}
"""
    
    try:
        hints = _get_llm_client().ask_json(prompt)
        
        hints["filename"] = basename
        hints["base_name"] = base_name
        hints["parts"] = parts
        
        _get_llm_cache().set("filename_hints", parsed_structure, hints)
        
        if hints.get("confidence", 1.0) < HumanReviewConfig.FILENAME_ANALYSIS_CONFIDENCE_THRESHOLD:
            print(f"âš ï¸  [Filename Analysis] Low confidence ({hints.get('confidence'):.2%}) for {basename}")
        
        return hints
        
    except Exception as e:
        print(f"âŒ [Filename Analysis] LLM Error: {e}")
        return {
            "filename": basename,
            "base_name": base_name,
            "parts": parts,
            "entity_type": None,
            "scope": None,
            "suggested_level": None,
            "data_type_indicator": None,
            "related_file_patterns": [],
            "confidence": 0.0,
            "error": str(e)
        }


def summarize_existing_tables(ontology_context: dict, processed_files_data: dict = None) -> dict:
    """
    [Rule] Summarize existing table info (for LLM)
    """
    tables = {}
    
    for file_path, tag_info in ontology_context.get("file_tags", {}).items():
        if tag_info.get("type") == "transactional_data":
            table_name = os.path.basename(file_path).replace(".csv", "_table").replace(".", "_")
            
            columns = tag_info.get("columns", [])
            
            if not columns and processed_files_data:
                columns = processed_files_data.get(file_path, {}).get("columns", [])
            
            tables[table_name] = {
                "file_path": file_path,
                "type": tag_info.get("type"),
                "columns": columns
            }
    
    return tables


def find_common_columns(current_cols: List[str], existing_tables: dict) -> List[dict]:
    """
    [Rule] Find common columns between current table and existing tables (FK candidate search)
    """
    candidates = []
    
    for table_name, table_info in existing_tables.items():
        existing_cols = table_info.get("columns", [])
        
        common_cols = set(current_cols) & set(existing_cols)
        
        for common_col in common_cols:
            candidates.append({
                "column_name": common_col,
                "current_table": "new_table",
                "existing_table": table_name,
                "match_type": "exact_name",
                "confidence_hint": 0.9
            })
    
    # Find similar names (underscore normalization)
    for table_name, table_info in existing_tables.items():
        existing_cols = table_info.get("columns", [])
        
        for curr_col in current_cols:
            for exist_col in existing_cols:
                curr_normalized = curr_col.replace('_', '').lower()
                exist_normalized = exist_col.replace('_', '').lower()
                
                if curr_normalized == exist_normalized and curr_col != exist_col:
                    candidates.append({
                        "current_col": curr_col,
                        "existing_col": exist_col,
                        "existing_table": table_name,
                        "match_type": "similar_name",
                        "confidence_hint": 0.7
                    })
    
    return candidates


def infer_relationships_with_llm(
    current_table_name: str,
    current_cols: List[str],
    ontology_context: dict,
    current_metadata: dict
) -> dict:
    """
    [Rule ì „ì²˜ë¦¬ + LLM íŒë‹¨] í…Œì´ë¸” ê°„ ê´€ê³„ ì¶”ë¡ 
    """
    # íŒŒì¼ëª… íŒíŠ¸
    filename_hints = extract_filename_hints(current_table_name)
    
    # ê¸°ì¡´ í…Œì´ë¸” ìš”ì•½
    existing_tables = summarize_existing_tables(ontology_context)
    
    # FK í›„ë³´
    fk_candidates = find_common_columns(current_cols, existing_tables)
    
    # ì¹´ë””ë„ë¦¬í‹° ë¶„ì„
    cardinality_hints = {}
    column_details = current_metadata.get("column_details", [])
    
    for col_info in column_details:
        if not isinstance(col_info, dict):
            continue
        col_name = col_info.get('column_name')
        samples = col_info.get('samples', [])
        
        if samples:
            unique_count = len(set(samples))
            total_count = len(samples)
            ratio = unique_count / total_count if total_count > 0 else 0
            
            cardinality_hints[col_name] = {
                "uniqueness_ratio": round(ratio, 2),
                "pattern": "UNIQUE" if ratio > 0.95 else "REPEATED"
            }
    
    llm_context = {
        "current_table": current_table_name,
        "current_cols": current_cols,
        "filename_hints": filename_hints,
        "fk_candidates": fk_candidates,
        "cardinality": cardinality_hints,
        "existing_tables": existing_tables,
        "definitions": ontology_context.get("definitions", {})
    }
    
    cached = _get_llm_cache().get("relationship_inference", llm_context)
    if cached:
        print(f"âœ… [Cache Hit] ê´€ê³„ ì¶”ë¡  ìºì‹œ ì‚¬ìš©")
        return cached
    
    prompt = f"""
You are a Database Schema Architect for Medical Data Integration.
Infer table relationships from pre-processed data.

[NEW TABLE]
Name: {current_table_name}
Columns: {current_cols}

[FILENAME HINTS]
{json.dumps(filename_hints, indent=2)}

[FK CANDIDATES (Common Columns)]
{json.dumps(fk_candidates, indent=2)}

[CARDINALITY]
{json.dumps(cardinality_hints, indent=2)}

[EXISTING TABLES]
{json.dumps(existing_tables, indent=2)}

[TASK]
1. Validate FK Candidates using cardinality and filename hints
2. Determine Relationship Type (1:1, 1:N, N:1, M:N)
3. Infer Hierarchy

[OUTPUT FORMAT - JSON]
{{
  "relationships": [
    {{
      "source_table": "{current_table_name}",
      "target_table": "existing_table_name",
      "source_column": "column_name",
      "target_column": "column_name",
      "relation_type": "N:1",
      "confidence": 0.95,
      "description": "Brief explanation",
      "llm_inferred": true
    }}
  ],
  "hierarchy": [],
  "reasoning": "Overall explanation"
}}
"""
    
    try:
        result = _get_llm_client().ask_json(prompt)
        _get_llm_cache().set("relationship_inference", llm_context, result)
        
        rels = result.get("relationships", [])
        low_conf_rels = [r for r in rels if r.get("confidence", 0) < HumanReviewConfig.RELATIONSHIP_CONFIDENCE_THRESHOLD]
        
        if low_conf_rels:
            print(f"âš ï¸  [Relationship] Low confidence for {len(low_conf_rels)} relationships")
        
        return result
        
    except Exception as e:
        print(f"âŒ [Relationship Inference] LLM Error: {e}")
        return {
            "relationships": [],
            "hierarchy": [],
            "reasoning": f"Error: {str(e)}",
            "error": True
        }


# =============================================================================
# Hybrid Approach: LLM Enrichment Functions
# =============================================================================

def extract_relevant_context(conversation_history: Dict[str, Any]) -> str:
    """
    [Helper] ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ LLM í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    
    ì „ì²´ íˆìŠ¤í† ë¦¬ê°€ ì•„ë‹Œ í•µì‹¬ ê²°ì •ì‚¬í•­ê³¼ ì‚¬ìš©ì ì„ í˜¸ë„ë§Œ ì¶”ì¶œí•˜ì—¬
    í† í° ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    
    Args:
        conversation_history: ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ (stateì˜ conversation_history)
    
    Returns:
        LLM í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•  ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    if not conversation_history:
        return ""
    
    context_parts = []
    
    # 1. ì‚¬ìš©ì ì„ í˜¸ë„ (í•™ìŠµëœ íŒ¨í„´)
    user_preferences = conversation_history.get("user_preferences", {})
    if user_preferences:
        prefs_text = "\n".join([f"  - {k}: {v}" for k, v in user_preferences.items()])
        context_parts.append(f"[USER PREFERENCES]\n{prefs_text}")
    
    # 2. ì´ì „ ë¶„ë¥˜ ê²°ì • (ìµœê·¼ 3ê°œë§Œ)
    classification_decisions = conversation_history.get("classification_decisions", [])[-3:]
    if classification_decisions:
        decisions_text = "\n".join([
            f"  - {d.get('file', 'unknown')}: {d.get('response', '')}" 
            for d in classification_decisions
        ])
        context_parts.append(f"[PREVIOUS CLASSIFICATION DECISIONS]\n{decisions_text}")
    
    # 3. ì´ì „ ì•µì»¤ ê²°ì • (ìµœê·¼ 3ê°œë§Œ)
    anchor_decisions = conversation_history.get("anchor_decisions", [])[-3:]
    if anchor_decisions:
        decisions_text = "\n".join([
            f"  - {d.get('file', 'unknown')}: {d.get('response', '')}"
            for d in anchor_decisions
        ])
        context_parts.append(f"[PREVIOUS ANCHOR DECISIONS]\n{decisions_text}")
    
    # 4. ìµœê·¼ ëŒ€í™”ì—ì„œ ë„ë©”ì¸ íŒíŠ¸ ì¶”ì¶œ (ì‚¬ìš©ìê°€ ì¤€ ì„¤ëª…)
    turns = conversation_history.get("turns", [])[-MetadataEnrichmentConfig.MAX_CONVERSATION_TURNS:]
    domain_hints = []
    for turn in turns:
        response = turn.get("human_response", "")
        # ì˜ë¯¸ìˆëŠ” ì„¤ëª…ì´ í¬í•¨ëœ ì‘ë‹µë§Œ ì¶”ì¶œ (ë‹¨ìˆœ í™•ì¸ ì œì™¸)
        if response and len(response) > 10 and response.lower() not in ["ok", "í™•ì¸", "yes", "y", "approve"]:
            domain_hints.append(f"  - Q: {turn.get('agent_question', '')[:80]}...")
            domain_hints.append(f"    A: {response}")
    
    if domain_hints:
        context_parts.append(f"[DOMAIN HINTS FROM USER]\n" + "\n".join(domain_hints[-6:]))  # ìµœëŒ€ 3ìŒ
    
    if not context_parts:
        return ""
    
    return "\n\n".join(context_parts)


def enrich_definitions_with_llm(
    definitions: Dict[str, str],
    conversation_context: str = "",
    chunk_size: int = MetadataEnrichmentConfig.ENRICHMENT_CHUNK_SIZE,
    dataset_domain: str = "medical",
    max_chunks: Optional[int] = None  # NEW: ì²˜ë¦¬í•  ìµœëŒ€ ì²­í¬ ìˆ˜ (Noneì´ë©´ ì „ì²´)
) -> List[Dict[str, str]]:
    """
    [LLM] ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹±ëœ definitionsë¥¼ LLMìœ¼ë¡œ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ í’ë¶€í•˜ê²Œ ë§Œë“¦
    
    ê¸°ì¡´ parse_metadata_content()ë¡œ ì¶”ì¶œí•œ ë‹¨ìˆœ {key: desc} í˜•íƒœë¥¼
    ì˜ë£Œ ë„ë©”ì¸ ê´€ì ì—ì„œ enriched_definitionìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        definitions: ê·œì¹™ ê¸°ë°˜ íŒŒì‹± ê²°ê³¼ {term: description}
        conversation_context: extract_relevant_context()ë¡œ ì¶”ì¶œí•œ ì»¨í…ìŠ¤íŠ¸
        chunk_size: LLMì— í•œ ë²ˆì— ë³´ë‚¼ definition ìˆ˜
        dataset_domain: ë°ì´í„°ì…‹ ë„ë©”ì¸ (medical, clinical, etc.)
        max_chunks: ì²˜ë¦¬í•  ìµœëŒ€ ì²­í¬ ìˆ˜ (Noneì´ë©´ ì „ì²´, 1ì´ë©´ ì²« ë²ˆì§¸ë§Œ)
    
    Returns:
        List[Dict]: [{
            "name": "caseid",
            "enriched_definition": "ìˆ˜ìˆ  ì¼€ì´ìŠ¤ ê³ ìœ  ì‹ë³„ì. í•œ í™˜ìê°€ ì—¬ëŸ¬ ìˆ˜ìˆ ì„...",
            "analysis_context": "user_hint: ìˆ˜ìˆ ID"
        }, ...]
    """
    if not definitions:
        return []
    
    enriched_results = []
    definition_items = list(definitions.items())
    total_chunks = (len(definition_items) + chunk_size - 1) // chunk_size
    
    # max_chunks ì ìš©
    chunks_to_process = total_chunks
    if max_chunks is not None:
        chunks_to_process = min(max_chunks, total_chunks)
    
    if max_chunks and max_chunks < total_chunks:
        print(f"\n   ğŸ§  [LLM Enrichment] {len(definitions)}ê°œ ìš©ì–´ ì¤‘ {chunks_to_process}/{total_chunks}ê°œ ì²­í¬ë§Œ ë¶„ì„ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ)")
    else:
        print(f"\n   ğŸ§  [LLM Enrichment] {len(definitions)}ê°œ ìš©ì–´ë¥¼ {total_chunks}ê°œ ì²­í¬ë¡œ ë¶„ì„")
    
    processed_chunks = 0
    for chunk_idx in range(0, len(definition_items), chunk_size):
        # max_chunks ì²´í¬
        if max_chunks is not None and processed_chunks >= max_chunks:
            remaining = total_chunks - processed_chunks
            print(f"      â­ï¸ ë‚˜ë¨¸ì§€ {remaining}ê°œ ì²­í¬ ìŠ¤í‚µ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ)")
            break
        
        chunk = definition_items[chunk_idx:chunk_idx + chunk_size]
        chunk_num = chunk_idx // chunk_size + 1
        
        # ìºì‹œ í‚¤ ìƒì„± (ì²­í¬ ë‚´ìš© ê¸°ë°˜)
        cache_key = {
            "chunk": [(k, v[:100]) for k, v in chunk],  # ì„¤ëª… 100ìë¡œ ì œí•œ
            "context_hash": hash(conversation_context[:200]) if conversation_context else 0
        }
        
        cached = _get_llm_cache().get("definition_enrichment", cache_key)
        if cached:
            print(f"      âœ… [Cache Hit] ì²­í¬ {chunk_num}/{total_chunks}")
            enriched_results.extend(cached)
            processed_chunks += 1
            continue
        
        # ì²­í¬ ë°ì´í„° í¬ë§·íŒ…
        definitions_text = "\n".join([
            f"- {term}: {desc[:200]}{'...' if len(desc) > 200 else ''}"
            for term, desc in chunk
        ])
        
        # ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€
        context_section = ""
        if conversation_context:
            context_section = f"""
[CONVERSATION CONTEXT - Use this to improve analysis accuracy]
{conversation_context}
"""
        
        prompt = f"""You are a Medical Data Ontologist specializing in healthcare terminology.
Enrich the following term definitions with detailed medical domain knowledge.

{context_section}
[TERMS TO ENRICH]
{definitions_text}

[TASK]
For each term, provide:
1. **enriched_definition**: A comprehensive medical definition including:
   - Full medical term (if abbreviated)
   - What it represents in clinical context
   - Typical usage/importance in medical data
   - Relationship to patient care
   
2. **semantic_category**: One of:
   - identifier (patient ID, case ID, etc.)
   - demographic (age, sex, etc.)
   - vital_sign (HR, BP, etc.)
   - laboratory (lab test results)
   - medication (drug info)
   - procedure (surgery, intervention)
   - diagnosis (ICD codes, conditions)
   - temporal (dates, timestamps)
   - administrative (hospital info)
   - measurement (clinical measurements)
   - other

3. **korean_summary**: í•œê¸€ ìš”ì•½ (1-2ë¬¸ì¥)

[OUTPUT FORMAT - JSON]
{{
    "enrichments": [
        {{
            "name": "term_name",
            "enriched_definition": "Detailed medical definition...",
            "semantic_category": "identifier",
            "korean_summary": "í•œê¸€ ìš”ì•½"
        }}
    ]
}}

IMPORTANT:
- If conversation context provides user hints about terms, PRIORITIZE that information
- Keep enriched_definition concise but informative (max 200 chars)
- Use standard medical terminology where applicable
"""
        from src.config import LLMConfig
        
        try:
            result = _get_llm_client().ask_json(prompt, max_tokens=LLMConfig.MAX_TOKENS_ENRICHMENT)
            chunk_enrichments = result.get("enrichments", [])
            
            # ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            for item in chunk_enrichments:
                item["analysis_context"] = f"chunk_{chunk_num}, context_provided={bool(conversation_context)}"
            
            _get_llm_cache().set("definition_enrichment", cache_key, chunk_enrichments)
            enriched_results.extend(chunk_enrichments)
            processed_chunks += 1
            
            print(f"      âœ… ì²­í¬ {chunk_num}/{total_chunks} ì™„ë£Œ ({len(chunk_enrichments)}ê°œ)")
            
        except Exception as e:
            print(f"      âš ï¸ ì²­í¬ {chunk_num} ì‹¤íŒ¨: {e}")
            processed_chunks += 1
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€
            for term, desc in chunk:
                enriched_results.append({
                    "name": term,
                    "enriched_definition": desc,
                    "semantic_category": "other",
                    "korean_summary": "",
                    "analysis_context": f"error: {str(e)[:50]}"
                })
    
    skipped_count = len(definitions) - len(enriched_results)
    if skipped_count > 0:
        print(f"   âœ… [LLM Enrichment] ì™„ë£Œ: {len(enriched_results)}ê°œ ë¶„ì„, {skipped_count}ê°œ ìŠ¤í‚µ")
    else:
        print(f"   âœ… [LLM Enrichment] ì™„ë£Œ: {len(enriched_results)}ê°œ ìš©ì–´ ë¶„ì„ë¨")
    return enriched_results


def infer_concept_relationships(
    definitions: Dict[str, str],
    enrichments: List[Dict[str, str]],
    conversation_context: str = ""
) -> Dict[str, Any]:
    """
    [LLM] ê°œë…(Concept) ê°„ì˜ ê´€ê³„ ì¶”ë¡ 
    
    ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œí•œ ìš©ì–´ë“¤ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤.
    ì˜ˆ: caseidì™€ subjectidê°€ ê³„ì¸µ ê´€ê³„ì„ì„ íŒŒì•…
    
    Args:
        definitions: ì›ë³¸ definitions
        enrichments: enrich_definitions_with_llm()ì˜ ê²°ê³¼
        conversation_context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
    
    Returns:
        Dict with:
        - concept_relationships: [{source, target, relation_type, reasoning}, ...]
        - hierarchy_hints: [{concept, level, reasoning}, ...]
    """
    if not definitions or len(definitions) < 2:
        return {"concept_relationships": [], "hierarchy_hints": []}
    
    # ID ê´€ë ¨ ìš©ì–´ í•„í„°ë§ (ê´€ê³„ ì¶”ë¡ ì— ì§‘ì¤‘)
    id_terms = [e for e in enrichments if e.get("semantic_category") == "identifier"]
    
    if len(id_terms) < 2:
        # ID ìš©ì–´ê°€ ë¶€ì¡±í•˜ë©´ ì „ì²´ì—ì„œ ìƒ˜í”Œë§
        sample_terms = enrichments[:20] if len(enrichments) > 20 else enrichments
    else:
        sample_terms = id_terms[:10]  # ID ìš©ì–´ ìµœëŒ€ 10ê°œ
    
    # ìºì‹œ í™•ì¸
    cache_key = {
        "terms": [t["name"] for t in sample_terms],
        "context_hash": hash(conversation_context[:100]) if conversation_context else 0
    }
    
    cached = _get_llm_cache().get("concept_relationships", cache_key)
    if cached:
        print(f"   âœ… [Cache Hit] ê°œë… ê´€ê³„ ì¶”ë¡  ìºì‹œ ì‚¬ìš©")
        return cached
    
    # ìš©ì–´ ìš”ì•½ ìƒì„±
    terms_summary = "\n".join([
        f"- {t['name']}: {t.get('enriched_definition', '')[:100]}... (category: {t.get('semantic_category', 'unknown')})"
        for t in sample_terms
    ])
    
    context_section = f"\n[USER CONTEXT]\n{conversation_context}" if conversation_context else ""
    
    prompt = f"""You are a Medical Data Ontologist analyzing term relationships.

[TERMS FROM METADATA]
{terms_summary}
{context_section}
[TASK]
1. Identify HIERARCHICAL relationships between identifier terms
   - Example: subjectid (patient) â†’ caseid (surgery case) is a 1:N hierarchy
   - Patient level > Case/Visit level > Measurement level

2. Identify SEMANTIC relationships between concepts
   - Example: "age" and "sex" are both "demographic" attributes
   - Example: "HR" and "BP" are both "vital_sign" measurements

[OUTPUT FORMAT - JSON]
{{
    "concept_relationships": [
        {{
            "source": "subjectid",
            "target": "caseid",
            "relation_type": "PARENT_OF",
            "cardinality": "1:N",
            "reasoning": "One patient can have multiple surgery cases"
        }}
    ],
    "hierarchy_hints": [
        {{
            "concept": "subjectid",
            "level": 1,
            "entity_type": "patient",
            "reasoning": "Top-level patient identifier"
        }},
        {{
            "concept": "caseid",
            "level": 2,
            "entity_type": "case",
            "reasoning": "Surgery case, child of patient"
        }}
    ],
    "semantic_groups": [
        {{
            "group_name": "patient_identifiers",
            "members": ["subjectid", "patientid"],
            "reasoning": "Both refer to patient identification"
        }}
    ]
}}

IMPORTANT:
- Only include relationships you are confident about
- Common medical hierarchies: Patient > Case/Visit > Measurement > Signal
- If no clear relationships found, return empty arrays
"""
    
    try:
        result = _get_llm_client().ask_json(prompt)
        
        # ê²°ê³¼ ì •ë¦¬
        output = {
            "concept_relationships": result.get("concept_relationships", []),
            "hierarchy_hints": result.get("hierarchy_hints", []),
            "semantic_groups": result.get("semantic_groups", [])
        }
        
        _get_llm_cache().set("concept_relationships", cache_key, output)
        
        print(f"   âœ… [Concept Relations] ë°œê²¬: {len(output['concept_relationships'])}ê°œ ê´€ê³„, {len(output['hierarchy_hints'])}ê°œ ê³„ì¸µ íŒíŠ¸")
        
        return output
        
    except Exception as e:
        print(f"   âš ï¸ [Concept Relations] ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return {"concept_relationships": [], "hierarchy_hints": [], "semantic_groups": []}
