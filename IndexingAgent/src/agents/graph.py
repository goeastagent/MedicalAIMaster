"""
2-Phase Workflow Architecture
=============================

Phase 1: Classification (ì „ì²´ íŒŒì¼ ë¶„ë¥˜)
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   START     â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  batch_classifier  â”‚  â† ëª¨ë“  íŒŒì¼ ë¶„ë¥˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
uncertain?   all ok?
    â”‚         â”‚
    â–¼         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚classification_reviewâ”‚ â† Human-in-Loop
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼

Phase 2: Processing (ë©”íƒ€ë°ì´í„° â†’ ë°ì´í„° ìˆœì„œ)
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ process_metadata     â”‚ â† ë©”íƒ€ë°ì´í„° ë¨¼ì €!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ process_data_batch   â”‚ â† ë°ì´í„° íŒŒì¼ ì²˜ë¦¬ ì‹œì‘
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   loader    â”‚  â† í˜„ì¬ íŒŒì¼ ë¡œë“œ
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  analyzer   â”‚  â† ì˜ë¯¸ ë¶„ì„
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
      â”‚         â”‚
low conf?    high conf?
      â”‚         â”‚
      â–¼         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚human_reviewâ”‚  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
      â”‚         â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   indexer   â”‚  â† DB ì €ì¥
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   advance   â”‚  â† ë‹¤ìŒ íŒŒì¼?
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
      â”‚         â”‚
 has more?   all done?
      â”‚         â”‚
      â†º loop    â–¼
              â”Œâ”€â”€â”€â”€â”€â”
              â”‚ END â”‚
              â””â”€â”€â”€â”€â”€â”˜
"""

from langgraph.graph import StateGraph, END
from src.agents.state import AgentState

# ìƒˆë¡œìš´ nodes íŒ¨í‚¤ì§€ì—ì„œ import
from src.agents.nodes import (
    # ê¸°ì¡´ ë…¸ë“œ
    load_data_node,
    ontology_builder_node,
    analyze_semantics_node,
    human_review_node,
    index_data_node,
    # 2-Phase ìƒˆ ë…¸ë“œ
    batch_classifier_node,
    classification_review_node,
    process_metadata_batch_node,
    process_data_batch_node,
    advance_to_next_file_node,
    # Routing functions
    check_classification_needs_review,
    check_has_more_files,
    check_data_needs_review,
)


def build_agent(checkpointer=None, mode="batch"):
    """
    LangGraph ì›Œí¬í”Œë¡œìš° ë¹Œë“œ
    
    Args:
        checkpointer: (ì„ íƒ) ìƒíƒœ ì €ì¥ìš© checkpointer (ì˜ˆ: MemorySaver())
                     Human-in-the-Loopì—ì„œ interrupt/resumeì„ ìœ„í•´ í•„ìš”
        mode: ì›Œí¬í”Œë¡œìš° ëª¨ë“œ
            - "batch": 2-Phase Workflow (ê¶Œì¥, ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬)
            - "single": ê¸°ì¡´ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°
    """
    if mode == "batch":
        return _build_batch_workflow(checkpointer)
    else:
        return _build_single_file_workflow(checkpointer)


def _build_batch_workflow(checkpointer=None):
    """
    [NEW] 2-Phase Batch Workflow
    
    ë©”íƒ€ë°ì´í„°ë¥¼ ë¨¼ì € ì²˜ë¦¬í•˜ì—¬ ì˜¨í†¨ë¡œì§€ë¥¼ êµ¬ì¶•í•œ í›„,
    ë°ì´í„° íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    workflow = StateGraph(AgentState)
    
    # ==========================================================================
    # Phase 1: Classification (íŒŒì¼ ë¶„ë¥˜)
    # ==========================================================================
    workflow.add_node("batch_classifier", batch_classifier_node)
    workflow.add_node("classification_review", classification_review_node)
    
    # ==========================================================================
    # Phase 2: Processing (ë©”íƒ€ë°ì´í„° â†’ ë°ì´í„°)
    # ==========================================================================
    workflow.add_node("process_metadata", process_metadata_batch_node)
    workflow.add_node("process_data_batch", process_data_batch_node)
    
    # ê°œë³„ ë°ì´í„° íŒŒì¼ ì²˜ë¦¬ ë…¸ë“œ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
    workflow.add_node("loader", load_data_node)
    workflow.add_node("analyzer", analyze_semantics_node)
    workflow.add_node("human_review", human_review_node)
    workflow.add_node("indexer", index_data_node)
    workflow.add_node("advance", advance_to_next_file_node)
    
    # ==========================================================================
    # Edges: Phase 1
    # ==========================================================================
    
    # Entry Point
    workflow.set_entry_point("batch_classifier")
    
    # batch_classifier â†’ classification_review (ë¶ˆí™•ì‹¤í•œ íŒŒì¼ ìˆìœ¼ë©´)
    # batch_classifier â†’ process_metadata (ëª¨ë‘ í™•ì‹¤í•˜ë©´)
    workflow.add_conditional_edges(
        "batch_classifier",
        check_classification_needs_review,
        {
            "needs_review": "classification_review",
            "all_confident": "process_metadata"
        }
    )
    
    # classification_review â†’ process_metadata (í™•ì • í›„)
    # classification_review â†’ classification_review (ê³„ì† ì§ˆë¬¸ - ìì²´ ë£¨í”„ëŠ” stateë¡œ ì²˜ë¦¬)
    workflow.add_conditional_edges(
        "classification_review",
        lambda state: "continue" if not state.get("needs_human_review") else "wait",
        {
            "continue": "process_metadata",
            "wait": "classification_review"  # Human Review ëŒ€ê¸° (interruptë¡œ ì²˜ë¦¬)
        }
    )
    
    # ==========================================================================
    # Edges: Phase 2
    # ==========================================================================
    
    # process_metadata â†’ process_data_batch
    workflow.add_edge("process_metadata", "process_data_batch")
    
    # process_data_batch â†’ loader (ì²« ë°ì´í„° íŒŒì¼ ë¡œë“œ)
    # process_data_batch â†’ END (ë°ì´í„° íŒŒì¼ ì—†ìœ¼ë©´)
    workflow.add_conditional_edges(
        "process_data_batch",
        lambda state: "has_data" if state.get("classification_result", {}).get("data_files") else "no_data",
        {
            "has_data": "loader",
            "no_data": END
        }
    )
    
    # loader â†’ analyzer
    workflow.add_edge("loader", "analyzer")
    
    # analyzer â†’ human_review / indexer (confidence ì²´í¬)
    workflow.add_conditional_edges(
        "analyzer",
        check_data_needs_review,
        {
            "review_required": "human_review",
            "approved": "indexer"
        }
    )
    
    # human_review â†’ analyzer (í”¼ë“œë°± ë°˜ì˜)
    workflow.add_edge("human_review", "analyzer")
    
    # indexer â†’ advance (ë‹¤ìŒ íŒŒì¼ë¡œ)
    workflow.add_edge("indexer", "advance")
    
    # advance â†’ loader (ë” ìˆìœ¼ë©´) / END (ì™„ë£Œ)
    workflow.add_conditional_edges(
        "advance",
        check_has_more_files,
        {
            "has_more": "loader",
            "all_done": END
        }
    )
    
    # ==========================================================================
    # Compile with Interrupt Points
    # ==========================================================================
    compile_config = {}
    if checkpointer:
        compile_config["checkpointer"] = checkpointer
        # Human-in-Loop ì§€ì ë“¤
        compile_config["interrupt_before"] = [
            "classification_review",  # ë¶„ë¥˜ í™•ì¸
            "human_review"           # ë°ì´í„° ë¶„ì„ í™•ì¸
        ]
    
    return workflow.compile(**compile_config)


def _build_single_file_workflow(checkpointer=None):
    """
    [LEGACY] ê¸°ì¡´ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°
    
    í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    workflow = StateGraph(AgentState)

    # ë…¸ë“œ ë“±ë¡
    workflow.add_node("loader", load_data_node)
    workflow.add_node("ontology_builder", ontology_builder_node)
    workflow.add_node("analyzer", analyze_semantics_node)
    workflow.add_node("human_review", human_review_node)
    workflow.add_node("indexer", index_data_node)

    # ì—£ì§€ ì—°ê²°
    workflow.set_entry_point("loader")
    workflow.add_edge("loader", "ontology_builder")
    
    workflow.add_conditional_edges(
        "ontology_builder",
        lambda state: "skip" if state.get("skip_indexing") else "continue",
        {
            "skip": END,
            "continue": "analyzer"
        }
    )

    workflow.add_conditional_edges(
        "analyzer",
        check_confidence,
        {
            "review_required": "human_review",
            "approved": "indexer"
        }
    )

    workflow.add_edge("human_review", "analyzer")
    workflow.add_edge("indexer", END)

    # ì»´íŒŒì¼
    compile_config = {}
    if checkpointer:
        compile_config["checkpointer"] = checkpointer
        compile_config["interrupt_before"] = ["human_review"]
    
    return workflow.compile(**compile_config)


# =============================================================================
# Routing Functions (Legacy - for single file mode)
# =============================================================================

def check_confidence(state: AgentState):
    """ìƒíƒœë¥¼ ë³´ê³  ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (ë‹¨ì¼ íŒŒì¼ ëª¨ë“œìš©)"""
    
    print("\n" + "ğŸ”"*40)
    print("[DEBUG] check_confidence í˜¸ì¶œ")
    print("ğŸ”"*40)
    
    needs_human = state.get("needs_human_review", False)
    finalized_anchor = state.get("finalized_anchor", {})
    anchor_status = finalized_anchor.get("status") if finalized_anchor else None
    
    print(f"[DEBUG] needs_human_review: {needs_human}")
    print(f"[DEBUG] finalized_anchor status: {anchor_status}")
    
    # Anchorê°€ í™•ì •ëœ ê²½ìš° (FK_LINK í¬í•¨!)
    if anchor_status in ["CONFIRMED", "INDIRECT_LINK", "FK_LINK"]:
        print(f"[DEBUG] â†’ approved (Anchor í™•ì •ë¨: {anchor_status})")
        print("ğŸ”"*40)
        return "approved"
    
    # Processorê°€ í™•ì¸ ìš”ì²­
    if state.get("raw_metadata", {}).get("anchor_info", {}).get("needs_human_confirmation"):
        print(f"[DEBUG] â†’ review_required (Processor ìš”ì²­)")
        return "review_required"
    
    # needs_human_review í”Œë˜ê·¸
    if state.get("needs_human_review"):
        print(f"[DEBUG] â†’ review_required (needs_human_review=True)")
        return "review_required"

    print(f"[DEBUG] â†’ approved (ì •ìƒ ì§„í–‰)")
    print("ğŸ”"*40)
    
    return "approved"


# =============================================================================
# Convenience Functions
# =============================================================================

def build_batch_agent(checkpointer=None):
    """2-Phase Batch Workflow ë¹Œë“œ (í¸ì˜ í•¨ìˆ˜)"""
    return build_agent(checkpointer=checkpointer, mode="batch")


def build_single_agent(checkpointer=None):
    """ë‹¨ì¼ íŒŒì¼ ì›Œí¬í”Œë¡œìš° ë¹Œë“œ (í¸ì˜ í•¨ìˆ˜)"""
    return build_agent(checkpointer=checkpointer, mode="single")
