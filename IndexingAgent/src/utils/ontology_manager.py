"""
ì˜¨í†¨ë¡œì§€ ì €ìž¥/ë¡œë“œ/ë³‘í•© ê´€ë¦¬ìž (Neo4j + PostgreSQL í•˜ì´ë¸Œë¦¬ë“œ)

Dataset-First Architecture:
- ëª¨ë“  ë…¸ë“œì— dataset_id ì†ì„± ì¶”ê°€
- ë°ì´í„°ì…‹ë³„ë¡œ ë…ë¦½ì ì¸ ì˜¨í†¨ë¡œì§€ ê´€ë¦¬
- ê°™ì€ ì´ë¦„ì˜ Conceptë„ ë°ì´í„°ì…‹ë³„ë¡œ êµ¬ë¶„

ì—­í•  ë¶„ë¦¬:
- Neo4j: ê·¸ëž˜í”„ êµ¬ì¡° (Concept, Table, Relationships, Hierarchy)
- PostgreSQL: ë³µìž¡í•œ ë¬¸ì„œí˜• ë°ì´í„° (column_metadata - JSONB)
"""

import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from src.database.neo4j_connection import Neo4jConnection
from src.database.connection import get_db_manager
from src.utils.naming import sanitize_for_neo4j_label

logger = logging.getLogger(__name__)


class OntologyManager:
    """
    ì˜¨í†¨ë¡œì§€ ì§€ì‹ ë² ì´ìŠ¤ ê´€ë¦¬ìž (Neo4j ê¸°ë°˜)
    
    Dataset-First Architecture:
    - ëª¨ë“  ì—”í‹°í‹°ëŠ” dataset_idë¡œ êµ¬ë¶„ë¨
    - load()/save()ëŠ” íŠ¹ì • ë°ì´í„°ì…‹ì˜ ì˜¨í†¨ë¡œì§€ë§Œ ì²˜ë¦¬
    - load_all()ë¡œ ì „ì²´ ì˜¨í†¨ë¡œì§€ ì¡°íšŒ ê°€ëŠ¥
    """
    
    def __init__(self, db_path: str = "data/processed/ontology_db.json"):
        # db_pathëŠ” í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        self.neo4j = Neo4jConnection()
        self.pg = get_db_manager()  # PostgreSQL for column_metadata
        self.ontology = self._create_empty_ontology()
        self.current_dataset_id: Optional[str] = None  # í˜„ìž¬ ìž‘ì—… ì¤‘ì¸ ë°ì´í„°ì…‹
        
        # PostgreSQL column_metadata í…Œì´ë¸” ì´ˆê¸°í™”
        self._ensure_column_metadata_table()
    
    def _ensure_column_metadata_table(self):
        """PostgreSQLì— column_metadata í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)"""
        try:
            conn = self.pg.get_connection()
            cursor = conn.cursor()
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS column_metadata (
                    dataset_id TEXT NOT NULL,
                    table_name TEXT NOT NULL,
                    column_name TEXT NOT NULL,
                    metadata JSONB NOT NULL DEFAULT '{}',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    PRIMARY KEY (dataset_id, table_name, column_name)
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„± (ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_column_metadata_dataset 
                ON column_metadata(dataset_id)
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_column_metadata_table 
                ON column_metadata(dataset_id, table_name)
            """)
            
            conn.commit()
        except Exception as e:
            logger.warning(f"column_metadata í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _load_column_metadata_from_pg(self, dataset_id: Optional[str] = None) -> Dict[str, Dict[str, Any]]:
        """PostgreSQLì—ì„œ column_metadata ë¡œë“œ"""
        column_metadata = {}
        
        try:
            conn = self.pg.get_connection()
            cursor = conn.cursor()
            
            if dataset_id:
                cursor.execute("""
                    SELECT table_name, column_name, metadata
                    FROM column_metadata
                    WHERE dataset_id = %s
                """, (dataset_id,))
            else:
                cursor.execute("""
                    SELECT table_name, column_name, metadata
                    FROM column_metadata
                """)
            
            for row in cursor.fetchall():
                table_name, col_name, metadata = row
                
                if table_name not in column_metadata:
                    column_metadata[table_name] = {}
                
                # JSONBëŠ” ìžë™ìœ¼ë¡œ dictë¡œ ë³€í™˜ë¨
                if isinstance(metadata, str):
                    metadata = json.loads(metadata)
                
                column_metadata[table_name][col_name] = metadata
                
        except Exception as e:
            logger.warning(f"column_metadata ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return column_metadata
    
    def _save_column_metadata_to_pg(self, column_metadata: Dict, dataset_id: str):
        """PostgreSQLì— column_metadata ì €ìž¥ (UPSERT)"""
        if not column_metadata:
            return
        
        try:
            conn = self.pg.get_connection()
            cursor = conn.cursor()
            
            for table_name, columns in column_metadata.items():
                for col_name, col_info in columns.items():
                    # JSONBë¡œ ì €ìž¥
                    metadata_json = json.dumps(col_info, ensure_ascii=False, default=str)
                    
                    cursor.execute("""
                        INSERT INTO column_metadata (dataset_id, table_name, column_name, metadata, updated_at)
                        VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
                        ON CONFLICT (dataset_id, table_name, column_name)
                        DO UPDATE SET 
                            metadata = EXCLUDED.metadata,
                            updated_at = CURRENT_TIMESTAMP
                    """, (dataset_id, table_name, col_name, metadata_json))
            
            conn.commit()
            
        except Exception as e:
            logger.error(f"column_metadata ì €ìž¥ ì‹¤íŒ¨: {e}")
            raise
    
    def load(self, dataset_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Neo4jì—ì„œ ì˜¨í†¨ë¡œì§€ë¥¼ ë¡œë“œí•˜ì—¬ ë©”ëª¨ë¦¬ ìƒì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ìž¬êµ¬ì„±
        
        Dataset-First Architecture:
        - dataset_idê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ ë°ì´í„°ì…‹ì˜ ì˜¨í†¨ë¡œì§€ë§Œ ë¡œë“œ
        - dataset_idê°€ Noneì´ë©´ ì „ì²´ ë¡œë“œ (í•˜ìœ„ í˜¸í™˜ì„±)
        
        Args:
            dataset_id: ë¡œë“œí•  ë°ì´í„°ì…‹ ID (Noneì´ë©´ ì „ì²´)
        
        Returns:
            ì˜¨í†¨ë¡œì§€ ë”•ì…”ë„ˆë¦¬
        """
        self.current_dataset_id = dataset_id
        
        # ë°ì´í„°ì…‹ í•„í„° ì¡°ê±´
        dataset_filter = ""
        if dataset_id:
            dataset_filter = f"AND c.dataset_id = '{dataset_id}'"
            self.ontology["dataset_id"] = dataset_id
        
        try:
            # 1. Definitions (Concepts) ë¡œë“œ - original_definition + enriched_definition
            query_concepts = f"""
                MATCH (c:Concept) 
                WHERE c.name IS NOT NULL {dataset_filter.replace('c.', 'c.')}
                RETURN c.name as name, 
                       c.original_definition as original_definition,
                       c.enriched_definition as enriched_definition,
                       c.analysis_context as analysis_context,
                       c.dataset_id as dataset_id
            """
            results = self.neo4j.execute_query(query_concepts)
            
            # definitions: ê¸°ë³¸ì ìœ¼ë¡œ enriched_definition ìš°ì„ , ì—†ìœ¼ë©´ original_definition
            # definitions_detail: ìƒì„¸ ì •ë³´ (ì›ë³¸, enriched, context ëª¨ë‘ í¬í•¨)
            self.ontology["definitions_detail"] = {}
            
            for record in results:
                name = record["name"]
                original = record["original_definition"]
                enriched = record["enriched_definition"]
                context = record["analysis_context"]
                
                # ê¸°ë³¸ definitions: enrichedê°€ ìžˆìœ¼ë©´ enriched, ì—†ìœ¼ë©´ original
                self.ontology["definitions"][name] = enriched or original
                
                # ìƒì„¸ ì •ë³´ ì €ìž¥
                self.ontology["definitions_detail"][name] = {
                    "original_definition": original,
                    "enriched_definition": enriched,
                    "analysis_context": context
                }

            # 2. Hierarchy ë¡œë“œ
            query_hier = f"""
                MATCH (c:Concept) 
                WHERE c.level IS NOT NULL {dataset_filter}
                RETURN c
            """
            results = self.neo4j.execute_query(query_hier)
            
            # ì´ˆê¸°í™”
            self.ontology["hierarchy"] = []
            
            for record in results:
                node = record["c"]
                self.ontology["hierarchy"].append({
                    "entity_name": node.get("name"),
                    "level": node.get("level"),
                    "anchor_column": node.get("anchor_column"),
                    "confidence": node.get("confidence", 0),
                    "dataset_id": node.get("dataset_id")
                })
            # ë ˆë²¨ ì •ë ¬
            self.ontology["hierarchy"].sort(key=lambda x: x.get("level", 99))

            # 3. Relationships ë¡œë“œ (Table ë…¸ë“œ ê°„ ê´€ê³„)
            rel_filter = ""
            if dataset_id:
                rel_filter = f"WHERE s.dataset_id = '{dataset_id}'"
            
            query_rels = f"""
                MATCH (s:Table)-[r]->(t:Table)
                {rel_filter}
                RETURN s.name as source, t.name as target, type(r) as type, 
                       properties(r) as props, s.dataset_id as dataset_id
            """
            results = self.neo4j.execute_query(query_rels)
            
            # ì´ˆê¸°í™”
            self.ontology["relationships"] = []
            
            for record in results:
                props = record["props"]
                rel_data = {
                    "source_table": record["source"], 
                    "target_table": record["target"],
                    "relation_type": record["type"],
                    "source_column": props.get("source_column", ""),
                    "target_column": props.get("target_column", ""),
                    "confidence": props.get("confidence", 0),
                    "dataset_id": record.get("dataset_id")
                }
                self.ontology["relationships"].append(rel_data)

            # 4. Column Hierarchy ë¡œë“œ (CHILD_OF ê´€ê³„)
            hierarchy_filter = ""
            if dataset_id:
                hierarchy_filter = f"WHERE child.dataset_id = '{dataset_id}'"
            
            query_col_hierarchy = f"""
                MATCH (child:Column)-[r:CHILD_OF]->(parent:Column)
                {hierarchy_filter}
                RETURN child.name as child_col, child.table as table_name,
                       parent.name as parent_col,
                       r.cardinality as cardinality, r.hierarchy_type as hierarchy_type,
                       r.reasoning as reasoning, child.dataset_id as dataset_id
            """
            results = self.neo4j.execute_query(query_col_hierarchy)
            
            self.ontology["column_hierarchy"] = []
            for record in results:
                self.ontology["column_hierarchy"].append({
                    "table_name": record.get("table_name", "unknown"),
                    "child_column": record.get("child_col"),
                    "parent_column": record.get("parent_col"),
                    "cardinality": record.get("cardinality", "N:1"),
                    "hierarchy_type": record.get("hierarchy_type", "unknown"),
                    "reasoning": record.get("reasoning", ""),
                    "dataset_id": record.get("dataset_id")
                })

            # 5. Column Metadata ë¡œë“œ (PostgreSQL JSONBì—ì„œ)
            self.ontology["column_metadata"] = self._load_column_metadata_from_pg(dataset_id)

            dataset_label = f" (dataset: {dataset_id})" if dataset_id else " (all datasets)"
            print(f"âœ… [Ontology] Neo4j ë°ì´í„° ë¡œë“œ ì™„ë£Œ{dataset_label}")
            print(f"   - ìš©ì–´: {len(self.ontology.get('definitions', {}))}ê°œ")
            print(f"   - ê´€ê³„: {len(self.ontology.get('relationships', []))}ê°œ")
            print(f"   - ì»¬ëŸ¼ ê³„ì¸µ: {len(self.ontology.get('column_hierarchy', []))}ê°œ")
            print(f"   - ì»¬ëŸ¼ ë©”íƒ€: {len(self.ontology.get('column_metadata', {}))}ê°œ í…Œì´ë¸”")
            
            return self.ontology

        except Exception as e:
            print(f"âš ï¸ [Ontology] Neo4j ë¡œë“œ ì‹¤íŒ¨ (ë˜ëŠ” ë°ì´í„° ì—†ìŒ): {e}")
            return self.ontology

    def save(self, ontology: Dict[str, Any], dataset_id: Optional[str] = None):
        """
        ë©”ëª¨ë¦¬ì˜ ì˜¨í†¨ë¡œì§€ë¥¼ Neo4jì— ë™ê¸°í™” (MERGE ì‚¬ìš©)
        
        Dataset-First Architecture:
        - ëª¨ë“  ë…¸ë“œì— dataset_id ì†ì„± ì¶”ê°€
        - dataset_idë¡œ ë…¸ë“œë¥¼ êµ¬ë¶„í•˜ì—¬ ë°ì´í„°ì…‹ë³„ ë…ë¦½ì„± ë³´ìž¥
        
        Args:
            ontology: ì €ìž¥í•  ì˜¨í†¨ë¡œì§€ ë”•ì…”ë„ˆë¦¬
            dataset_id: ë°ì´í„°ì…‹ ID (Noneì´ë©´ ontologyì—ì„œ ì¶”ì¶œ ë˜ëŠ” current_dataset_id ì‚¬ìš©)
        """
        self.ontology = ontology  # ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        
        # dataset_id ê²°ì •
        if dataset_id is None:
            dataset_id = ontology.get("dataset_id") or self.current_dataset_id or "default"
        
        self.current_dataset_id = dataset_id
        
        print(f"ðŸ’¾ [Ontology] Neo4j ì €ìž¥ ì‹œìž‘... (dataset: {dataset_id})")
        
        try:
            with self.neo4j.get_session() as session:
                # 1. Definitions -> Concept ë…¸ë“œ ìƒì„± (dataset_id í¬í•¨)
                # original_definition: ë©”íƒ€ë°ì´í„° íŒŒì¼ ì›ë³¸
                # enriched_definition: LLM ë¶„ì„ ê²°ê³¼ (ë³„ë„ ë©”ì„œë“œë¡œ ì—…ë°ì´íŠ¸)
                for name, definition in ontology.get("definitions", {}).items():
                    session.run("""
                        MERGE (c:Concept {name: $name, dataset_id: $dataset_id})
                        SET c.original_definition = $definition,
                            c.last_updated = datetime()
                    """, name=name, definition=definition, dataset_id=dataset_id)
                
                # 2. Hierarchy -> ë…¸ë“œ ì†ì„± ì—…ë°ì´íŠ¸
                for h in ontology.get("hierarchy", []):
                    session.run("""
                        MERGE (c:Concept {name: $name, dataset_id: $dataset_id})
                        SET c.level = $level,
                            c.anchor_column = $anchor,
                            c.confidence = coalesce($conf, c.confidence)
                    """, name=h["entity_name"], level=h["level"], 
                         anchor=h.get("anchor_column"), conf=h.get("confidence"),
                         dataset_id=dataset_id)

                # 3. Relationships -> Table ë…¸ë“œ ìƒì„± í›„ ì—£ì§€ ìƒì„±
                for rel in ontology.get("relationships", []):
                    # ê´€ê³„ íƒ€ìž… ì •ì œ (ê³µë°± ì œê±°, ëŒ€ë¬¸ìží™”)
                    rel_type = rel["relation_type"].upper().replace(" ", "_")
                    
                    # Dataset-First: Table ë…¸ë“œì—ë„ dataset_id ì¶”ê°€
                    query = f"""
                        MERGE (s:Table {{name: $source, dataset_id: $dataset_id}})
                        MERGE (t:Table {{name: $target, dataset_id: $dataset_id}})
                        MERGE (s)-[r:`{rel_type}`]->(t)
                        SET r.source_column = $src_col,
                            r.target_column = $tgt_col,
                            r.confidence = $conf,
                            r.updated_at = datetime()
                    """
                    session.run(query, 
                        source=rel["source_table"],
                        target=rel["target_table"],
                        src_col=rel.get("source_column"),
                        tgt_col=rel.get("target_column"),
                        conf=rel.get("confidence", 0),
                        dataset_id=dataset_id
                    )

                # 4. Column Hierarchy -> CHILD_OF ê´€ê³„ ì €ìž¥ (Intra-table hierarchy)
                for hierarchy in ontology.get("column_hierarchy", []):
                    table_name = hierarchy.get("table_name", "unknown")
                    child_col = hierarchy.get("child_column")
                    parent_col = hierarchy.get("parent_column")
                    cardinality = hierarchy.get("cardinality", "N:1")
                    hierarchy_type = hierarchy.get("hierarchy_type", "unknown")
                    reasoning = hierarchy.get("reasoning", "")
                    
                    # Column ë…¸ë“œ ìƒì„± ë° CHILD_OF ê´€ê³„ ìƒì„±
                    session.run("""
                        MERGE (child:Column {name: $child_col, table: $table_name, dataset_id: $dataset_id})
                        MERGE (parent:Column {name: $parent_col, table: $table_name, dataset_id: $dataset_id})
                        MERGE (child)-[r:CHILD_OF]->(parent)
                        SET r.cardinality = $cardinality,
                            r.hierarchy_type = $hierarchy_type,
                            r.reasoning = $reasoning,
                            r.updated_at = datetime()
                    """, 
                        child_col=child_col,
                        parent_col=parent_col,
                        table_name=table_name,
                        cardinality=cardinality,
                        hierarchy_type=hierarchy_type,
                        reasoning=reasoning[:500] if reasoning else "",  # Neo4j ë¬¸ìžì—´ ê¸¸ì´ ì œí•œ
                        dataset_id=dataset_id
                    )
                
                if ontology.get("column_hierarchy"):
                    print(f"   - Column Hierarchy: {len(ontology['column_hierarchy'])}ê°œ CHILD_OF ê´€ê³„ ì €ìž¥")

                print(f"âœ… [Ontology] Neo4j ì €ìž¥(ë™ê¸°í™”) ì™„ë£Œ (dataset: {dataset_id})")
            
            # 4. Column Metadata -> PostgreSQL JSONBë¡œ ì €ìž¥ (Neo4j ëŒ€ì‹ )
            if ontology.get("column_metadata"):
                self._save_column_metadata_to_pg(ontology["column_metadata"], dataset_id)
                print(f"âœ… [Ontology] PostgreSQL column_metadata ì €ìž¥ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ [Ontology] Neo4j ì €ìž¥ ì‹¤íŒ¨: {e}")
            # raise e # í•„ìš” ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ ì—ëŸ¬ ì „íŒŒ

    def enrich_concept(
        self, 
        concept_name: str, 
        enriched_definition: str,
        analysis_context: Optional[str] = None,
        dataset_id: Optional[str] = None
    ):
        """
        Neo4j Concept ë…¸ë“œì— LLM ë¶„ì„ ê²°ê³¼(enriched_definition) ì¶”ê°€
        
        Args:
            concept_name: ì»¨ì…‰ ì´ë¦„ (ì˜ˆ: 'caseid')
            enriched_definition: LLMì´ ë¶„ì„í•œ í’ë¶€í•œ ì„¤ëª…
            analysis_context: ë¶„ì„ ê·¼ê±° (ì˜ˆ: "user_feedback: 'ìˆ˜ìˆ ID'")
            dataset_id: ë°ì´í„°ì…‹ ID
        """
        dataset_id = dataset_id or self.current_dataset_id or "default"
        
        try:
            with self.neo4j.get_session() as session:
                session.run("""
                    MERGE (c:Concept {name: $name, dataset_id: $dataset_id})
                    SET c.enriched_definition = $enriched_def,
                        c.analysis_context = $context,
                        c.enriched_at = datetime()
                """, 
                    name=concept_name,
                    enriched_def=enriched_definition,
                    context=analysis_context or "",
                    dataset_id=dataset_id
                )
            print(f"   âœ… [Neo4j] Concept '{concept_name}' enriched with LLM analysis")
        except Exception as e:
            print(f"   âš ï¸ [Neo4j] Failed to enrich concept '{concept_name}': {e}")

    def enrich_concepts_batch(
        self,
        enrichments: List[Dict[str, str]],
        dataset_id: Optional[str] = None
    ):
        """
        ì—¬ëŸ¬ Conceptì„ í•œë²ˆì— enrich (ë°°ì¹˜ ì²˜ë¦¬)
        
        Args:
            enrichments: [{"name": "caseid", "enriched_definition": "...", "analysis_context": "..."}]
            dataset_id: ë°ì´í„°ì…‹ ID
        """
        dataset_id = dataset_id or self.current_dataset_id or "default"
        
        try:
            with self.neo4j.get_session() as session:
                for item in enrichments:
                    session.run("""
                        MERGE (c:Concept {name: $name, dataset_id: $dataset_id})
                        SET c.enriched_definition = $enriched_def,
                            c.analysis_context = $context,
                            c.enriched_at = datetime()
                    """, 
                        name=item["name"],
                        enriched_def=item.get("enriched_definition", ""),
                        context=item.get("analysis_context", ""),
                        dataset_id=dataset_id
                    )
            print(f"   âœ… [Neo4j] {len(enrichments)} Concepts enriched with LLM analysis")
        except Exception as e:
            print(f"   âš ï¸ [Neo4j] Failed to enrich concepts: {e}")

    def merge(self, new_knowledge: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê¸°ì¡´ ì˜¨í†¨ë¡œì§€ + ìƒˆ ì§€ì‹ ë³‘í•© (ì¦ë¶„ ì—…ë°ì´íŠ¸)
        
        Args:
            new_knowledge: ìƒˆë¡œ ì¶”ê°€í•  ì§€ì‹
        
        Returns:
            ë³‘í•©ëœ ì˜¨í†¨ë¡œì§€
        """
        if not self.ontology:
            self.ontology = self._create_empty_ontology()
        
        # 1. Definitions ë³‘í•©
        if "definitions" in new_knowledge:
            self.ontology["definitions"].update(new_knowledge["definitions"])
        
        # 2. Relationships ë³‘í•©
        if "relationships" in new_knowledge:
            existing_rels = {
                self._rel_key(r): r 
                for r in self.ontology.get("relationships", [])
            }
            
            for new_rel in new_knowledge["relationships"]:
                key = self._rel_key(new_rel)
                if key not in existing_rels:
                    existing_rels[key] = new_rel
                else:
                    if new_rel.get("confidence", 0) > existing_rels[key].get("confidence", 0):
                        existing_rels[key] = new_rel
            
            self.ontology["relationships"] = list(existing_rels.values())
        
        # 3. Hierarchy ë³‘í•©
        if "hierarchy" in new_knowledge:
            self._merge_hierarchy(new_knowledge["hierarchy"])
        
        # 4. File Tags ë³‘í•© (Neo4j ì €ìž¥ ë¡œì§ì—ëŠ” í˜„ìž¬ í¬í•¨ ì•ˆ ë¨, í•„ìš” ì‹œ ì¶”ê°€)
        if "file_tags" in new_knowledge:
            if "file_tags" not in self.ontology:
                self.ontology["file_tags"] = {}
            self.ontology["file_tags"].update(new_knowledge["file_tags"])
        
        # 5. Column Metadata ë³‘í•© (NEW)
        if "column_metadata" in new_knowledge:
            if "column_metadata" not in self.ontology:
                self.ontology["column_metadata"] = {}
            
            for table_name, columns in new_knowledge["column_metadata"].items():
                if table_name not in self.ontology["column_metadata"]:
                    self.ontology["column_metadata"][table_name] = {}
                
                # ì»¬ëŸ¼ë³„ë¡œ ë³‘í•© (confidenceê°€ ë†’ì€ ê²ƒ ìš°ì„ )
                for col_name, col_info in columns.items():
                    existing = self.ontology["column_metadata"][table_name].get(col_name)
                    if not existing or col_info.get("confidence", 0) > existing.get("confidence", 0):
                        self.ontology["column_metadata"][table_name][col_name] = col_info
        
        # DB ì €ìž¥
        self.save(self.ontology)
        
        return self.ontology
    
    def _rel_key(self, relationship: Dict) -> tuple:
        """ê´€ê³„ ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•œ í‚¤ ìƒì„±"""
        return (
            relationship.get("source_table", ""),
            relationship.get("target_table", ""),
            relationship.get("source_column", ""),
            relationship.get("target_column", "")
        )
    
    def _merge_hierarchy(self, new_hierarchy: List[Dict]):
        """ê³„ì¸µ êµ¬ì¡° ë³‘í•©"""
        if "hierarchy" not in self.ontology:
            self.ontology["hierarchy"] = []
        
        existing_entities = {h["entity_name"]: h for h in self.ontology["hierarchy"]}
        
        for new_level in new_hierarchy:
            entity = new_level["entity_name"]
            if entity not in existing_entities:
                self.ontology["hierarchy"].append(new_level)
                existing_entities[entity] = new_level
            else:
                if new_level.get("confidence", 0) > existing_entities[entity].get("confidence", 0):
                    # ê¸°ì¡´ ì œê±° í›„ ì¶”ê°€ (ë¦¬ìŠ¤íŠ¸ ê°±ì‹ )
                    self.ontology["hierarchy"] = [
                        h for h in self.ontology["hierarchy"]
                        if h["entity_name"] != entity
                    ]
                    self.ontology["hierarchy"].append(new_level)
                    existing_entities[entity] = new_level # ë§µë„ ê°±ì‹ 
        
        self.ontology["hierarchy"].sort(key=lambda x: x.get("level", 99))
    
    def _create_empty_ontology(self, dataset_id: Optional[str] = None) -> Dict[str, Any]:
        """ë¹ˆ ì˜¨í†¨ë¡œì§€ êµ¬ì¡° ìƒì„±"""
        return {
            "version": "2.1",  # Dataset-First + Enriched Definitions
            "dataset_id": dataset_id,  # NEW: ì†Œì† ë°ì´í„°ì…‹
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "definitions": {},  # ê¸°ë³¸ (enriched ìš°ì„ , ì—†ìœ¼ë©´ original)
            "definitions_detail": {},  # NEW: {name: {original_definition, enriched_definition, analysis_context}}
            "relationships": [],
            "hierarchy": [],
            "file_tags": {},
            "column_metadata": {},  # table_name -> {col_name -> metadata}
            "metadata": {
                "total_tables": 0,
                "total_definitions": 0,
                "total_relationships": 0,
                "total_columns": 0
            }
        }
    
    def set_dataset(self, dataset_id: str):
        """í˜„ìž¬ ìž‘ì—… ë°ì´í„°ì…‹ ì„¤ì •"""
        self.current_dataset_id = dataset_id
        if self.ontology.get("dataset_id") != dataset_id:
            # ìƒˆ ë°ì´í„°ì…‹ìœ¼ë¡œ ì „í™˜ - ì˜¨í†¨ë¡œì§€ ì´ˆê¸°í™” í›„ ë¡œë“œ
            self.ontology = self._create_empty_ontology(dataset_id)
            self.load(dataset_id)
    
    def get_dataset_list(self) -> List[str]:
        """ë“±ë¡ëœ ëª¨ë“  ë°ì´í„°ì…‹ ID ëª©ë¡ ì¡°íšŒ"""
        try:
            query = """
                MATCH (c:Concept)
                WHERE c.dataset_id IS NOT NULL
                RETURN DISTINCT c.dataset_id as dataset_id
                UNION
                MATCH (t:Table)
                WHERE t.dataset_id IS NOT NULL
                RETURN DISTINCT t.dataset_id as dataset_id
            """
            results = self.neo4j.execute_query(query)
            return list(set([r["dataset_id"] for r in results if r["dataset_id"]]))
        except Exception as e:
            print(f"âš ï¸ [Ontology] ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def export_summary(self) -> str:
        """ì˜¨í†¨ë¡œì§€ ìš”ì•½ ì¶œë ¥"""
        if not self.ontology:
            return "ì˜¨í†¨ë¡œì§€ ì—†ìŒ"
        
        summary = []
        summary.append("\n" + "="*60)
        summary.append("ðŸ“š Ontology Summary (from Neo4j)")
        summary.append("="*60)
        
        # Definitions
        defs = self.ontology.get("definitions", {})
        summary.append(f"\nðŸ”¤ Definitions: {len(defs)}ê°œ")
        if defs:
            for i, (key, val) in enumerate(list(defs.items())[:3]):
                summary.append(f"   {i+1}. {key}: {val[:50]}...")
        
        # Relationships
        rels = self.ontology.get("relationships", [])
        summary.append(f"\nðŸ”— Relationships: {len(rels)}ê°œ")
        if rels:
            for i, rel in enumerate(rels[:3]):
                summary.append(
                    f"   {i+1}. {rel['source_table']}.{rel['source_column']} "
                    f"â†’ {rel['target_table']}.{rel['target_column']} ({rel['relation_type']})"
                )
        
        # Hierarchy
        hier = self.ontology.get("hierarchy", [])
        summary.append(f"\nðŸ—ï¸  Hierarchy: {len(hier)}ê°œ ë ˆë²¨")
        if hier:
            for h in hier:
                summary.append(
                    f"   L{h['level']}: {h['entity_name']} ({h.get('anchor_column', 'N/A')})"
                )
        
        summary.append("="*60)
        return "\n".join(summary)


# ì „ì—­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_global_ontology_manager = None

def get_ontology_manager() -> OntologyManager:
    """ì „ì—­ ì˜¨í†¨ë¡œì§€ ë§¤ë‹ˆì € ë°˜í™˜"""
    global _global_ontology_manager
    if _global_ontology_manager is None:
        _global_ontology_manager = OntologyManager()
    return _global_ontology_manager
