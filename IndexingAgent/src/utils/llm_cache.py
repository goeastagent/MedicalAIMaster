# src/utils/llm_cache.py
"""
LLM ì‘ë‹µ ìºì‹± ì‹œìŠ¤í…œ (ë¹„ìš© ì ˆê°)

ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ + ì»¨í…ìŠ¤íŠ¸ ì¡°í•©ì€ ìºì‹œì—ì„œ ì¬ì‚¬ìš©
"""

import hashlib
import json
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime


class LLMCache:
    """LLM ì‘ë‹µ ìºì‹± (ë¹„ìš© ì ˆê° ë° ì†ë„ í–¥ìƒ)"""
    
    def __init__(self, cache_dir: str = "data/cache/llm"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.hit_count = 0
        self.miss_count = 0
    
    def _get_key(self, prompt: str, context: Dict[str, Any]) -> str:
        """
        í”„ë¡¬í”„íŠ¸ + ì»¨í…ìŠ¤íŠ¸ë¡œ ê³ ìœ  í‚¤ ìƒì„±
        
        Args:
            prompt: LLM í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
            context: ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬ (íŒŒì¼ëª…, ì»¬ëŸ¼ ë“±)
        
        Returns:
            MD5 í•´ì‹œ í‚¤
        """
        # ì»¨í…ìŠ¤íŠ¸ë¥¼ ì •ë ¬ëœ JSONìœ¼ë¡œ ë³€í™˜ (ìˆœì„œ ë…ë¦½ì„±)
        context_str = json.dumps(context, sort_keys=True)
        content = f"{prompt}::{context_str}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def get(self, prompt: str, context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ìºì‹œ ì¡°íšŒ
        
        Returns:
            ìºì‹œëœ ê²°ê³¼ ë˜ëŠ” None
        """
        key = self._get_key(prompt, context)
        cache_file = self.cache_dir / f"{key}.json"
        
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    self.hit_count += 1
                    # ìºì‹œëœ ê²°ê³¼ì—ì„œ ì‹¤ì œ result ì¶”ì¶œ
                    result = cached_data.get("result") if isinstance(cached_data, dict) and "result" in cached_data else cached_data
                    print(f"âœ… [Cache Hit] ìºì‹œ ì‚¬ìš© (ì´ {self.hit_count}íšŒ ì ˆì•½)")
                    return result
            except Exception as e:
                print(f"âš ï¸  [Cache Error] ìºì‹œ ì½ê¸° ì‹¤íŒ¨: {e}")
                self.miss_count += 1
                return None
        
        self.miss_count += 1
        return None
    
    def set(self, prompt: str, context: Dict[str, Any], result: Dict[str, Any]):
        """
        ìºì‹œ ì €ì¥
        
        Args:
            prompt: LLM í”„ë¡¬í”„íŠ¸
            context: ì»¨í…ìŠ¤íŠ¸
            result: LLM ì‘ë‹µ
        """
        key = self._get_key(prompt, context)
        cache_file = self.cache_dir / f"{key}.json"
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        cached_data = {
            "result": result,
            "prompt_hash": key,
            "cached_at": datetime.now().isoformat(),
            "context_summary": {
                "filename": context.get("filename", "unknown"),
                "num_columns": context.get("num_columns", 0)
            }
        }
        
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cached_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  [Cache Error] ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def clear(self):
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        import shutil
        if self.cache_dir.exists():
            shutil.rmtree(self.cache_dir)
            self.cache_dir.mkdir(parents=True)
        
        self.hit_count = 0
        self.miss_count = 0
        print("ğŸ—‘ï¸  ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ")
    
    def stats(self) -> Dict[str, Any]:
        """
        ìºì‹œ í†µê³„
        
        Returns:
            hits, misses, hit_rate, estimated_savings
        """
        total = self.hit_count + self.miss_count
        hit_rate = self.hit_count / total if total > 0 else 0
        
        return {
            "hits": self.hit_count,
            "misses": self.miss_count,
            "total_calls": total,
            "hit_rate": round(hit_rate, 2),
            "estimated_savings_usd": round(self.hit_count * 0.03, 2)  # $0.03/call ê°€ì •
        }
    
    def print_stats(self):
        """ìºì‹œ í†µê³„ ì¶œë ¥"""
        stats = self.stats()
        print("\n" + "="*60)
        print("ğŸ“Š LLM Cache Statistics")
        print("="*60)
        print(f"  Cache Hits:     {stats['hits']}")
        print(f"  Cache Misses:   {stats['misses']}")
        print(f"  Total Calls:    {stats['total_calls']}")
        print(f"  Hit Rate:       {stats['hit_rate']:.1%}")
        print(f"  Estimated Savings: ${stats['estimated_savings_usd']:.2f}")
        print("="*60)


# ì „ì—­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_global_cache = None

def get_llm_cache() -> LLMCache:
    """ì „ì—­ LLM ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_cache
    if _global_cache is None:
        _global_cache = LLMCache()
    return _global_cache

