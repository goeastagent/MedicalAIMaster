# src/knowledge/vector_store.py
"""
VectorDB ê´€ë¦¬ (ChromaDB)

ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ê³„ì¸µì  ì„ë² ë”© ë° Hybrid Search
"""

import os
from typing import List, Dict, Any, Optional
from pathlib import Path

from config import EmbeddingConfig, LLMConfig


class VectorStore:
    """
    ChromaDB ê¸°ë°˜ VectorDB ê´€ë¦¬
    
    ì „ë¬¸ê°€ í”¼ë“œë°± ë°˜ì˜:
    - ê³„ì¸µì  ì„ë² ë”© (Table + Column + Relationship)
    - Hybrid Search (Keyword + Vector)
    - í™•ì¥ì„± ê³ ë ¤ (ì„ë² ë”© ëª¨ë¸ êµì²´ ê°€ëŠ¥)
    """
    
    def __init__(self, db_path: str = "data/processed/vector_db"):
        """
        Args:
            db_path: ChromaDB ì €ì¥ ê²½ë¡œ
        """
        self.db_path = Path(db_path)
        self.client = None
        self.collection = None
        
        # ChromaDB import (ì„ íƒì )
        try:
            import chromadb
            self.chromadb = chromadb
        except ImportError:
            print("âš ï¸ ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install chromadb")
            self.chromadb = None
    
    def initialize(self, embedding_model: str = None):
        """
        ChromaDB ì´ˆê¸°í™”
        
        Args:
            embedding_model: "openai" ë˜ëŠ” "local" (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        """
        if not self.chromadb:
            raise ImportError("ChromaDB not installed")
        
        # configì—ì„œ ê¸°ë³¸ê°’ ê°€ì ¸ì˜¤ê¸°
        if embedding_model is None:
            embedding_model = EmbeddingConfig.PROVIDER
        
        # Persistent client
        self.client = self.chromadb.PersistentClient(path=str(self.db_path))
        
        # ì„ë² ë”© í•¨ìˆ˜ ì„ íƒ (configì—ì„œ ëª¨ë¸ëª… ê°€ì ¸ì˜´)
        if embedding_model == "openai":
            from chromadb.utils import embedding_functions
            model_name = EmbeddingConfig.OPENAI_MODEL
            embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
                api_key=LLMConfig.OPENAI_API_KEY,
                model_name=model_name
            )
        elif embedding_model == "local":
            from chromadb.utils import embedding_functions
            model_name = EmbeddingConfig.LOCAL_MODEL
            embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name=model_name
            )
        else:
            raise ValueError(f"Unknown embedding model: {embedding_model}")
        
        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ë¡œë“œ
        self.collection = self.client.get_or_create_collection(
            name="medical_ontology",
            embedding_function=embedding_fn,
            metadata={"description": "Medical data ontology for semantic search"}
        )
        
        print(f"âœ… VectorDB ì´ˆê¸°í™” ì™„ë£Œ: {self.db_path}")
        print(f"   - ì„ë² ë”© Provider: {embedding_model}")
        print(f"   - ëª¨ë¸: {model_name}")
    
    def build_index(self, ontology_context: Dict[str, Any]):
        """
        ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ê³„ì¸µì  ì„ë² ë”© ìƒì„±
        
        ì „ë¬¸ê°€ í”¼ë“œë°±:
        - Table Summary Embedding (ë¼ìš°íŒ…ìš©)
        - Column Definition Embedding (ë§¤í•‘ìš©)
        - Relationship Embedding (JOINìš©)
        
        Args:
            ontology_context: ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸
        """
        if not self.collection:
            raise ValueError("VectorStore not initialized. Call initialize() first.")
        
        documents = []
        metadatas = []
        ids = []
        
        print("\nğŸ“š [VectorDB] ì„ë² ë”© ìƒì„± ì¤‘...")
        
        # === 1. Table Summary Embedding (ì‹ ê·œ) ===
        print("   - Table Summary ì„ë² ë”©...")
        
        table_count = 0
        for file_path, tag_info in ontology_context.get("file_tags", {}).items():
            if tag_info.get("type") == "transactional_data":
                table_name = os.path.basename(file_path).replace(".csv", "")
                columns = tag_info.get("columns", [])
                
                # ê³„ì¸µ ì •ë³´ ì°¾ê¸°
                table_level = None
                entity_name = None
                for h in ontology_context.get("hierarchy", []):
                    mapping_table = h.get("mapping_table", "")
                    if mapping_table and table_name in mapping_table:
                        table_level = h["level"]
                        entity_name = h["entity_name"]
                
                # ê´€ê³„ ì •ë³´ ì°¾ê¸°
                related = []
                for rel in ontology_context.get("relationships", []):
                    if rel["source_table"] == table_name:
                        related.append(f"â†’ {rel['target_table']} (via {rel['source_column']})")
                    elif rel["target_table"] == table_name:
                        related.append(f"â† {rel['source_table']} (via {rel['target_column']})")
                
                # í…Œì´ë¸” ìš”ì•½ í…ìŠ¤íŠ¸
                table_text = f"""Table: {table_name}
Type: {'Hub Table' if len(related) > 1 else 'Data Table'}
Entity Level: {table_level if table_level else 'Unknown'} ({entity_name if entity_name else 'N/A'})
Columns ({len(columns)}): {', '.join(columns[:15])}{'...' if len(columns) > 15 else ''}
Relationships: {'; '.join(related) if related else 'None'}
Description: Contains {entity_name if entity_name else 'data'} information."""
                
                documents.append(table_text)
                metadatas.append({
                    "type": "table_summary",
                    "table_name": table_name,
                    "level": table_level,
                    "num_columns": len(columns)
                })
                ids.append(f"table_{table_name}")
                table_count += 1
        
        print(f"      â€¢ {table_count}ê°œ í…Œì´ë¸”")
        
        # === 2. Column Definition Embedding ===
        print("   - Column Definition ì„ë² ë”©...")
        
        col_count = 0
        for col_name, definition in ontology_context.get("definitions", {}).items():
            # í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸
            context_text = f"Column: {col_name}\n{definition}"
            
            # ê³„ì¸µ ì •ë³´ ì¶”ê°€
            for h in ontology_context.get("hierarchy", []):
                if h.get("anchor_column") == col_name:
                    context_text += f"\nEntity Level: {h['level']} ({h['entity_name']})"
            
            # ì–´ëŠ í…Œì´ë¸”ì— ì†í•˜ëŠ”ì§€
            for file_path, tag_info in ontology_context.get("file_tags", {}).items():
                if col_name in tag_info.get("columns", []):
                    table = os.path.basename(file_path).replace(".csv", "")
                    context_text += f"\nTable: {table}"
                    break
            
            documents.append(context_text)
            metadatas.append({
                "type": "column_definition",
                "column_name": col_name
            })
            ids.append(f"col_{col_name}")
            col_count += 1
        
        print(f"      â€¢ {col_count}ê°œ ì»¬ëŸ¼")
        
        # === 3. Relationship Embedding ===
        print("   - Relationship ì„ë² ë”©...")
        
        rel_count = 0
        for rel in ontology_context.get("relationships", []):
            rel_text = f"""Relationship: {rel['source_table']} â†’ {rel['target_table']}
Foreign Key: {rel['source_column']} references {rel['target_column']}
Type: {rel['relation_type']}
Description: {rel['description']}"""
            
            documents.append(rel_text)
            metadatas.append({
                "type": "relationship",
                "source": rel["source_table"],
                "target": rel["target_table"]
            })
            ids.append(f"rel_{rel['source_table']}_{rel['target_table']}")
            rel_count += 1
        
        print(f"      â€¢ {rel_count}ê°œ ê´€ê³„")
        
        # === 4. ë²¡í„° ì €ì¥ ===
        print(f"\nğŸ’¾ [VectorDB] ì„ë² ë”© ì €ì¥ ì¤‘...")
        
        if documents:
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            total_embeddings = len(documents)
            print(f"âœ… VectorDB êµ¬ì¶• ì™„ë£Œ: {total_embeddings}ê°œ ì„ë² ë”©")
            print(f"   - Table: {table_count}ê°œ")
            print(f"   - Column: {col_count}ê°œ")
            print(f"   - Relationship: {rel_count}ê°œ")
            
            # í™•ì¥ì„± ë©”ëª¨
            print(f"\nğŸ’¡ [í™•ì¥ì„±] í–¥í›„ ìµœì í™” ê°€ëŠ¥:")
            print(f"   - ì„ë² ë”© ëª¨ë¸ êµì²´ (OpenAI â†’ Local)")
            print(f"   - Re-ranking ì¶”ê°€")
            print(f"   - Hybrid Search ê³ ë„í™”")
        else:
            print("âš ï¸ ì„ë² ë”©í•  ë¬¸ì„œ ì—†ìŒ")
    
    def semantic_search(
        self, 
        query: str, 
        n_results: int = 5,
        filter_type: Optional[str] = None
    ) -> List[Dict]:
        """
        ì‹œë§¨í‹± ê²€ìƒ‰ (Hybrid Search)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ê²°ê³¼ ê°œìˆ˜
            filter_type: í•„í„° íƒ€ì… ("table", "column", "relationship" ë˜ëŠ” None)
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.collection:
            raise ValueError("VectorStore not initialized")
        
        # ë©”íƒ€ë°ì´í„° í•„í„°
        where_filter = {"type": filter_type} if filter_type else None
        
        # ë²¡í„° ê²€ìƒ‰
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results,
            where=where_filter
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        if results and results['documents'] and results['documents'][0]:
            for doc, meta in zip(results['documents'][0], results['metadatas'][0]):
                formatted_results.append({
                    "document": doc,
                    "metadata": meta
                })
        
        return formatted_results
    
    def assemble_context(
        self,
        search_results: List[Dict],
        ontology_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ê²€ìƒ‰ ê²°ê³¼ ì¡°ë¦½ (LLM ì „ë‹¬ìš©)
        
        ê²€ìƒ‰ëœ ì»¬ëŸ¼ + í•´ë‹¹ í…Œì´ë¸” + ê´€ë ¨ ê´€ê³„ë¥¼ ë¬¶ì–´ì„œ ë°˜í™˜
        
        Args:
            search_results: semantic_search() ê²°ê³¼
            ontology_context: ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸
        
        Returns:
            ì¡°ë¦½ëœ ì»¨í…ìŠ¤íŠ¸
        """
        assembled = {
            "primary_results": [],
            "related_tables": set(),
            "join_paths": []
        }
        
        for result in search_results:
            doc = result["document"]
            meta = result["metadata"]
            result_type = meta.get("type")
            
            if result_type == "column_definition":
                col_name = meta.get("column_name")
                
                # ì´ ì»¬ëŸ¼ì´ ì†í•œ í…Œì´ë¸” ì°¾ê¸°
                for file_path, tag_info in ontology_context.get("file_tags", {}).items():
                    if col_name in tag_info.get("columns", []):
                        table_name = os.path.basename(file_path).replace(".csv", "")
                        assembled["related_tables"].add(table_name)
                        
                        # ê´€ë ¨ ê´€ê³„ ì°¾ê¸°
                        for rel in ontology_context.get("relationships", []):
                            if rel["source_table"] == table_name or rel["target_table"] == table_name:
                                join_path = f"{rel['source_table']}.{rel['source_column']} = {rel['target_table']}.{rel['target_column']}"
                                if join_path not in assembled["join_paths"]:
                                    assembled["join_paths"].append(join_path)
            
            elif result_type == "table_summary":
                table_name = meta.get("table_name")
                assembled["related_tables"].add(table_name)
            
            assembled["primary_results"].append({
                "document": doc,
                "metadata": meta
            })
        
        # Setì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        assembled["related_tables"] = list(assembled["related_tables"])
        
        return assembled

