# src/knowledge/vector_store.py
"""
VectorDB ê´€ë¦¬ (PostgreSQL pgvector ê¸°ë°˜)

Dynamic Schema: ì„ë² ë”© ëª¨ë¸ì— ë”°ë¼ í…Œì´ë¸”ì„ ë™ì ìœ¼ë¡œ ìƒì„±
- ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ í…Œì´ë¸” ì‚¬ìš© (ì˜ˆ: column_embeddings_openai_3072)
- ëª¨ë¸ ë³€ê²½ ì‹œ í•´ë‹¹ ëª¨ë¸ì˜ í…Œì´ë¸” ì°¸ì¡°
"""

import os
from typing import List, Dict, Any, Optional

from config import EmbeddingConfig, LLMConfig


class VectorStore:
    """
    PostgreSQL pgvector ê¸°ë°˜ VectorDB ê´€ë¦¬ (Dynamic Schema)
    
    - ì„ë² ë”© ëª¨ë¸ì— ë”°ë¼ ë™ì ìœ¼ë¡œ í…Œì´ë¸” ìƒì„±
    - ëª¨ë¸ë³„ í…Œì´ë¸”ëª…: {base_name}_{provider}_{dimensions}
    - ëª¨ë¸ ë³€ê²½ ì‹œ í•´ë‹¹ í…Œì´ë¸” ìë™ ì°¸ì¡°
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.conn = None
        self.embedding_client = None
        self.embedding_model = None
        self.dimensions = None
        self.provider = None
        
        # ë™ì  í…Œì´ë¸”ëª… (ì´ˆê¸°í™” ì‹œ ì„¤ì •)
        self.column_table = None
        self.table_table = None
        self.relationship_table = None
    
    def _get_table_suffix(self) -> str:
        """í˜„ì¬ ëª¨ë¸ì— ë§ëŠ” í…Œì´ë¸” ì ‘ë¯¸ì‚¬ ë°˜í™˜"""
        return f"{self.provider}_{self.dimensions}"
    
    def _get_table_names(self) -> Dict[str, str]:
        """í˜„ì¬ ëª¨ë¸ì— ë§ëŠ” í…Œì´ë¸”ëª…ë“¤ ë°˜í™˜"""
        suffix = self._get_table_suffix()
        return {
            "column": f"column_embeddings_{suffix}",
            "table": f"table_embeddings_{suffix}",
            "relationship": f"relationship_embeddings_{suffix}"
        }
    
    def initialize(self, embedding_model: str = None):
        """
        pgvector ë° ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            embedding_model: "openai" ë˜ëŠ” "local" (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        """
        # configì—ì„œ ê¸°ë³¸ê°’ ê°€ì ¸ì˜¤ê¸°
        if embedding_model is None:
            embedding_model = EmbeddingConfig.PROVIDER
        
        self.embedding_model = embedding_model
        self.provider = embedding_model
        
        # 1. PostgreSQL ì—°ê²°
        try:
            import psycopg2
            from database.connection import get_db_manager
            
            db_manager = get_db_manager()
            self.conn = db_manager.get_connection()
            print(f"âœ… PostgreSQL ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
        
        # 2. ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if embedding_model == "openai":
            try:
                from openai import OpenAI
                self.embedding_client = OpenAI(api_key=LLMConfig.OPENAI_API_KEY)
                self.dimensions = EmbeddingConfig.OPENAI_DIMENSIONS
                print(f"âœ… OpenAI ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ({EmbeddingConfig.OPENAI_MODEL})")
            except Exception as e:
                print(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                raise
        elif embedding_model == "local":
            try:
                from sentence_transformers import SentenceTransformer
                self.embedding_client = SentenceTransformer(EmbeddingConfig.LOCAL_MODEL)
                self.dimensions = EmbeddingConfig.LOCAL_DIMENSIONS
                print(f"âœ… Local ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ({EmbeddingConfig.LOCAL_MODEL})")
            except Exception as e:
                print(f"âŒ Local ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                raise
        else:
            raise ValueError(f"Unknown embedding model: {embedding_model}")
        
        # 3. í…Œì´ë¸”ëª… ì„¤ì •
        table_names = self._get_table_names()
        self.column_table = table_names["column"]
        self.table_table = table_names["table"]
        self.relationship_table = table_names["relationship"]
        
        print(f"\nğŸ“‹ [Dynamic Schema] í…Œì´ë¸”ëª…:")
        print(f"   - Column: {self.column_table}")
        print(f"   - Table: {self.table_table}")
        print(f"   - Relationship: {self.relationship_table}")
        
        # 4. pgvector í™•ì¥ ë° ë©”íƒ€ë°ì´í„° í…Œì´ë¸” ìë™ ìƒì„±
        self._ensure_pgvector_extension()
        
        # 5. í…Œì´ë¸” ë™ì  ìƒì„±
        self._create_tables_if_not_exist()
        
        print(f"\nâœ… VectorStore ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - Provider: {embedding_model}")
        print(f"   - Dimensions: {self.dimensions}")
    
    def _ensure_pgvector_extension(self):
        """pgvector í™•ì¥ ì„¤ì¹˜ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)"""
        cursor = self.conn.cursor()
        
        # pgvector í™•ì¥ í™•ì¸ ë° ì„¤ì¹˜
        cursor.execute("SELECT 1 FROM pg_extension WHERE extname='vector'")
        if not cursor.fetchone():
            print(f"   - pgvector í™•ì¥ ì„¤ì¹˜ ì¤‘...")
            try:
                cursor.execute("CREATE EXTENSION IF NOT EXISTS vector")
                self.conn.commit()
                print(f"   - pgvector í™•ì¥ ì„¤ì¹˜ ì™„ë£Œ")
            except Exception as e:
                raise RuntimeError(f"pgvector í™•ì¥ ì„¤ì¹˜ ì‹¤íŒ¨: {e}\n"
                                   "í•´ê²°: brew install pgvector ë˜ëŠ” apt install postgresql-XX-pgvector")
        else:
            print(f"   - pgvector í™•ì¥ í™•ì¸ ì™„ë£Œ")
        
        # ë©”íƒ€ë°ì´í„° í…Œì´ë¸” ìƒì„±
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS embedding_metadata (
                id SERIAL PRIMARY KEY,
                table_name VARCHAR(255) NOT NULL UNIQUE,
                embedding_provider VARCHAR(50) NOT NULL,
                embedding_model VARCHAR(100) NOT NULL,
                dimensions INTEGER NOT NULL,
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            )
        """)
        
        # ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±° í•¨ìˆ˜ ìƒì„±
        cursor.execute("""
            CREATE OR REPLACE FUNCTION update_updated_at_column()
            RETURNS TRIGGER AS $$
            BEGIN
                NEW.updated_at = NOW();
                RETURN NEW;
            END;
            $$ language 'plpgsql'
        """)
        
        self.conn.commit()
    
    def _create_tables_if_not_exist(self):
        """í˜„ì¬ ëª¨ë¸ì— ë§ëŠ” í…Œì´ë¸” ë™ì  ìƒì„±"""
        cursor = self.conn.cursor()
        dims = self.dimensions
        
        # 1. Column Embeddings í…Œì´ë¸”
        cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {self.column_table} (
                id SERIAL PRIMARY KEY,
                table_name VARCHAR(255) NOT NULL,
                column_name VARCHAR(255) NOT NULL,
                full_name VARCHAR(500),
                description TEXT,
                description_kr TEXT,
                unit VARCHAR(100),
                typical_range VARCHAR(100),
                embedding vector({dims}),
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW(),
                UNIQUE(table_name, column_name)
            )
        """)
        
        # 2. Table Embeddings í…Œì´ë¸”
        cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {self.table_table} (
                id SERIAL PRIMARY KEY,
                table_name VARCHAR(255) NOT NULL UNIQUE,
                description TEXT,
                columns_summary TEXT,
                row_count INTEGER,
                embedding vector({dims}),
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            )
        """)
        
        # 3. Relationship Embeddings í…Œì´ë¸”
        cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {self.relationship_table} (
                id SERIAL PRIMARY KEY,
                source_table VARCHAR(255) NOT NULL,
                target_table VARCHAR(255) NOT NULL,
                source_column VARCHAR(255),
                target_column VARCHAR(255),
                relation_type VARCHAR(100),
                description TEXT,
                embedding vector({dims}),
                created_at TIMESTAMP DEFAULT NOW(),
                UNIQUE(source_table, target_table, source_column, target_column)
            )
        """)
        
        # Commit table creation before index attempt
        self.conn.commit()
        
        # 4. Vector index creation (HNSW for dims <= 2000, skip for higher dims)
        # HNSW has 2000 dimension limit
        if dims <= 2000:
            try:
                # HNSW index (faster, but limited to 2000 dimensions)
                print(f"   - Creating HNSW indices (dims={dims})")
                cursor.execute(f"""
                    CREATE INDEX IF NOT EXISTS {self.column_table}_hnsw_idx 
                    ON {self.column_table} USING hnsw (embedding vector_cosine_ops)
                """)
                cursor.execute(f"""
                    CREATE INDEX IF NOT EXISTS {self.table_table}_hnsw_idx 
                    ON {self.table_table} USING hnsw (embedding vector_cosine_ops)
                """)
                cursor.execute(f"""
                    CREATE INDEX IF NOT EXISTS {self.relationship_table}_hnsw_idx 
                    ON {self.relationship_table} USING hnsw (embedding vector_cosine_ops)
                """)
                self.conn.commit()
            except Exception as e:
                self.conn.rollback()  # Rollback to allow subsequent operations
                print(f"   âš ï¸ HNSW index creation warning: {e}")
        else:
            # Skip vector index for high dimensions
            # Brute-force search will be used (still fast for small datasets)
            print(f"   - Skipping vector index for dims={dims} (exceeds HNSW 2000 limit)")
            print(f"     Note: Using brute-force search (fast for datasets < 100k rows)")
        
        # 5. ì¼ë°˜ ì¸ë±ìŠ¤
        cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS idx_{self.column_table}_table 
            ON {self.column_table}(table_name)
        """)
        cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS idx_{self.column_table}_column 
            ON {self.column_table}(column_name)
        """)
        
        # 6. ë©”íƒ€ë°ì´í„° í…Œì´ë¸”ì— ë“±ë¡
        model_name = EmbeddingConfig.OPENAI_MODEL if self.provider == "openai" else EmbeddingConfig.LOCAL_MODEL
        
        for table_type, table_name in self._get_table_names().items():
            cursor.execute("""
                INSERT INTO embedding_metadata (table_name, embedding_provider, embedding_model, dimensions)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (table_name) DO UPDATE SET
                    embedding_provider = EXCLUDED.embedding_provider,
                    embedding_model = EXCLUDED.embedding_model,
                    dimensions = EXCLUDED.dimensions,
                    updated_at = NOW()
            """, (table_name, self.provider, model_name, self.dimensions))
        
        # 7. ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±° ì ìš©
        for table_name in [self.column_table, self.table_table]:
            trigger_name = f"update_{table_name}_updated_at"
            cursor.execute(f"DROP TRIGGER IF EXISTS {trigger_name} ON {table_name}")
            cursor.execute(f"""
                CREATE TRIGGER {trigger_name}
                BEFORE UPDATE ON {table_name}
                FOR EACH ROW
                EXECUTE FUNCTION update_updated_at_column()
            """)
        
        self.conn.commit()
        print(f"   - í…Œì´ë¸” ìƒì„±/í™•ì¸ ì™„ë£Œ (dimensions: {dims})")
    
    def _get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
        if self.embedding_model == "openai":
            response = self.embedding_client.embeddings.create(
                model=EmbeddingConfig.OPENAI_MODEL,
                input=text
            )
            return response.data[0].embedding
        else:  # local
            return self.embedding_client.encode(text).tolist()
    
    def build_index(self, ontology_context: Dict[str, Any]):
        """
        ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ê³„ì¸µì  ì„ë² ë”© ìƒì„± ë° PostgreSQL ì €ì¥
        
        Args:
            ontology_context: ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸
        """
        if not self.conn or not self.embedding_client:
            raise ValueError("VectorStore not initialized. Call initialize() first.")
        
        cursor = self.conn.cursor()
        
        print(f"\nğŸ“š [VectorDB] ì„ë² ë”© ìƒì„± ì¤‘... (í…Œì´ë¸”: {self._get_table_suffix()})")
        
        # === 1. Table Summary Embedding ===
        print("   - Table Summary ì„ë² ë”©...")
        table_count = 0
        
        for file_path, tag_info in ontology_context.get("file_tags", {}).items():
            if tag_info.get("type") == "transactional_data":
                table_name = os.path.basename(file_path).replace(".csv", "_table").replace(".", "_").replace("-", "_")
                columns = tag_info.get("columns", [])
                
                # ê³„ì¸µ ì •ë³´ ì°¾ê¸°
                table_level = None
                entity_name = None
                for h in ontology_context.get("hierarchy", []):
                    mapping_table = h.get("mapping_table", "")
                    if mapping_table and table_name in mapping_table:
                        table_level = h["level"]
                        entity_name = h["entity_name"]
                
                # ê´€ê³„ ì •ë³´ ì°¾ê¸°
                related = []
                for rel in ontology_context.get("relationships", []):
                    if rel["source_table"] == table_name:
                        related.append(f"â†’ {rel['target_table']} (via {rel['source_column']})")
                    elif rel["target_table"] == table_name:
                        related.append(f"â† {rel['source_table']} (via {rel['target_column']})")
                
                # í…Œì´ë¸” ìš”ì•½ í…ìŠ¤íŠ¸
                table_text = f"""Table: {table_name}
Type: {'Hub Table' if len(related) > 1 else 'Data Table'}
Entity Level: {table_level if table_level else 'Unknown'} ({entity_name if entity_name else 'N/A'})
Columns ({len(columns)}): {', '.join(columns[:15])}{'...' if len(columns) > 15 else ''}
Relationships: {'; '.join(related) if related else 'None'}
Description: Contains {entity_name if entity_name else 'data'} information."""
                
                # ì„ë² ë”© ìƒì„±
                embedding = self._get_embedding(table_text)
                
                # PostgreSQL ì €ì¥ (UPSERT)
                cursor.execute(f"""
                    INSERT INTO {self.table_table} (table_name, description, columns_summary, row_count, embedding)
                    VALUES (%s, %s, %s, %s, %s)
                    ON CONFLICT (table_name) DO UPDATE SET
                        description = EXCLUDED.description,
                        columns_summary = EXCLUDED.columns_summary,
                        embedding = EXCLUDED.embedding,
                        updated_at = NOW()
                """, (
                    table_name,
                    f"Contains {entity_name if entity_name else 'data'} information",
                    ', '.join(columns[:30]),
                    None,
                    embedding
                ))
                
                table_count += 1
        
        print(f"      â€¢ {table_count}ê°œ í…Œì´ë¸”")
        
        # === 2. Column Definition Embedding ===
        print("   - Column Definition ì„ë² ë”©...")
        col_count = 0
        
        for col_name, definition in ontology_context.get("definitions", {}).items():
            # í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸
            context_text = f"Column: {col_name}\nDefinition: {definition}"
            
            # ê³„ì¸µ ì •ë³´ ì¶”ê°€
            for h in ontology_context.get("hierarchy", []):
                if h.get("anchor_column") == col_name:
                    context_text += f"\nEntity Level: {h['level']} ({h['entity_name']})"
            
            # ì–´ëŠ í…Œì´ë¸”ì— ì†í•˜ëŠ”ì§€
            table_name = None
            for file_path, tag_info in ontology_context.get("file_tags", {}).items():
                if col_name in tag_info.get("columns", []):
                    table_name = os.path.basename(file_path).replace(".csv", "_table").replace(".", "_").replace("-", "_")
                    context_text += f"\nTable: {table_name}"
                    break
            
            # ì„ë² ë”© ìƒì„±
            embedding = self._get_embedding(context_text)
            
            # PostgreSQL ì €ì¥ (UPSERT)
            cursor.execute(f"""
                INSERT INTO {self.column_table} (table_name, column_name, description, embedding)
                VALUES (%s, %s, %s, %s)
                ON CONFLICT (table_name, column_name) DO UPDATE SET
                    description = EXCLUDED.description,
                    embedding = EXCLUDED.embedding,
                    updated_at = NOW()
            """, (
                table_name or 'unknown',
                col_name,
                definition,
                embedding
            ))
            
            col_count += 1
        
        print(f"      â€¢ {col_count}ê°œ ì»¬ëŸ¼ ì •ì˜")
        
        # === 3. Column Metadata Embedding (NEW) ===
        print("   - Column Metadata ì„ë² ë”©...")
        meta_count = 0
        
        for table_name, columns in ontology_context.get("column_metadata", {}).items():
            for col_name, col_info in columns.items():
                # í’ë¶€í•œ ë©”íƒ€ë°ì´í„° í…ìŠ¤íŠ¸
                meta_text = f"""Column: {col_name}
Full Name: {col_info.get('full_name', col_name)}
Table: {table_name}
Unit: {col_info.get('unit', 'N/A')}
Normal Range: {col_info.get('typical_range', 'N/A')}
Description: {col_info.get('description', '')}
í•œê¸€ ì„¤ëª…: {col_info.get('description_kr', '')}
Data Type: {col_info.get('data_type', 'unknown')}
Keywords: {col_name}, {col_info.get('full_name', '')}, {col_info.get('description_kr', '')}"""
                
                # ì„ë² ë”© ìƒì„±
                embedding = self._get_embedding(meta_text)
                
                # PostgreSQL ì €ì¥ (UPSERT)
                cursor.execute(f"""
                    INSERT INTO {self.column_table} 
                    (table_name, column_name, full_name, description, description_kr, unit, typical_range, embedding)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (table_name, column_name) DO UPDATE SET
                        full_name = EXCLUDED.full_name,
                        description = EXCLUDED.description,
                        description_kr = EXCLUDED.description_kr,
                        unit = EXCLUDED.unit,
                        typical_range = EXCLUDED.typical_range,
                        embedding = EXCLUDED.embedding,
                        updated_at = NOW()
                """, (
                    table_name,
                    col_name,
                    col_info.get('full_name'),
                    col_info.get('description'),
                    col_info.get('description_kr'),
                    col_info.get('unit'),
                    col_info.get('typical_range'),
                    embedding
                ))
                
                meta_count += 1
        
        print(f"      â€¢ {meta_count}ê°œ ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„°")
        
        # === 4. Relationship Embedding ===
        print("   - Relationship ì„ë² ë”©...")
        rel_count = 0
        
        for rel in ontology_context.get("relationships", []):
            rel_text = f"""Relationship: {rel['source_table']} â†’ {rel['target_table']}
Foreign Key: {rel['source_column']} references {rel['target_column']}
Type: {rel['relation_type']}
Description: {rel.get('description', 'FK relationship')}"""
            
            # ì„ë² ë”© ìƒì„±
            embedding = self._get_embedding(rel_text)
            
            # PostgreSQL ì €ì¥ (UPSERT)
            cursor.execute(f"""
                INSERT INTO {self.relationship_table} 
                (source_table, target_table, source_column, target_column, relation_type, description, embedding)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (source_table, target_table, source_column, target_column) DO UPDATE SET
                    relation_type = EXCLUDED.relation_type,
                    description = EXCLUDED.description,
                    embedding = EXCLUDED.embedding
            """, (
                rel["source_table"],
                rel["target_table"],
                rel.get("source_column"),
                rel.get("target_column"),
                rel["relation_type"],
                rel.get('description', 'FK relationship'),
                embedding
            ))
            
            rel_count += 1
        
        print(f"      â€¢ {rel_count}ê°œ ê´€ê³„")
        
        # ì»¤ë°‹
        self.conn.commit()
        
        total_embeddings = table_count + col_count + meta_count + rel_count
        print(f"\nâœ… VectorDB êµ¬ì¶• ì™„ë£Œ: {total_embeddings}ê°œ ì„ë² ë”©")
        print(f"   - Table: {table_count}ê°œ")
        print(f"   - Column Definition: {col_count}ê°œ")
        print(f"   - Column Metadata: {meta_count}ê°œ")
        print(f"   - Relationship: {rel_count}ê°œ")
        print(f"   - ì €ì¥ ìœ„ì¹˜: {self._get_table_suffix()} í…Œì´ë¸”ë“¤")
    
    def semantic_search(
        self, 
        query: str, 
        n_results: int = 10,
        filter_type: Optional[str] = None
    ) -> List[Dict]:
        """
        ì‹œë§¨í‹± ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ê²°ê³¼ ê°œìˆ˜
            filter_type: í•„í„° íƒ€ì… ("table", "column", "relationship" ë˜ëŠ” None)
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not self.conn or not self.embedding_client:
            raise ValueError("VectorStore not initialized")
        
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self._get_embedding(query)
        
        cursor = self.conn.cursor()
        results = []
        
        # í…Œì´ë¸”ë³„ë¡œ ê²€ìƒ‰ (ë™ì  í…Œì´ë¸”ëª… ì‚¬ìš©)
        if filter_type is None or filter_type == "column":
            cursor.execute(f"""
                SELECT table_name, column_name, full_name, description, description_kr, 
                       unit, typical_range,
                       1 - (embedding <=> %s::vector) as similarity
                FROM {self.column_table}
                ORDER BY embedding <=> %s::vector
                LIMIT %s
            """, (query_embedding, query_embedding, n_results))
            
            for row in cursor.fetchall():
                results.append({
                    "type": "column",
                    "table_name": row[0],
                    "column_name": row[1],
                    "full_name": row[2],
                    "description": row[3],
                    "description_kr": row[4],
                    "unit": row[5],
                    "typical_range": row[6],
                    "similarity": float(row[7]) if row[7] else 0
                })
        
        if filter_type is None or filter_type == "table":
            cursor.execute(f"""
                SELECT table_name, description, columns_summary,
                       1 - (embedding <=> %s::vector) as similarity
                FROM {self.table_table}
                ORDER BY embedding <=> %s::vector
                LIMIT %s
            """, (query_embedding, query_embedding, n_results))
            
            for row in cursor.fetchall():
                results.append({
                    "type": "table",
                    "table_name": row[0],
                    "description": row[1],
                    "columns_summary": row[2],
                    "similarity": float(row[3]) if row[3] else 0
                })
        
        if filter_type is None or filter_type == "relationship":
            cursor.execute(f"""
                SELECT source_table, target_table, source_column, target_column, 
                       relation_type, description,
                       1 - (embedding <=> %s::vector) as similarity
                FROM {self.relationship_table}
                ORDER BY embedding <=> %s::vector
                LIMIT %s
            """, (query_embedding, query_embedding, n_results))
            
            for row in cursor.fetchall():
                results.append({
                    "type": "relationship",
                    "source_table": row[0],
                    "target_table": row[1],
                    "source_column": row[2],
                    "target_column": row[3],
                    "relation_type": row[4],
                    "description": row[5],
                    "similarity": float(row[6]) if row[6] else 0
                })
        
        # similarity ê¸°ì¤€ ì •ë ¬
        results.sort(key=lambda x: x.get("similarity", 0), reverse=True)
        
        return results[:n_results]
    
    def get_stats(self) -> Dict[str, int]:
        """ì„ë² ë”© í†µê³„ ì¡°íšŒ"""
        if not self.conn:
            return {}
        
        cursor = self.conn.cursor()
        stats = {}
        
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {self.column_table}")
            stats["columns"] = cursor.fetchone()[0]
        except:
            stats["columns"] = 0
        
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {self.table_table}")
            stats["tables"] = cursor.fetchone()[0]
        except:
            stats["tables"] = 0
        
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {self.relationship_table}")
            stats["relationships"] = cursor.fetchone()[0]
        except:
            stats["relationships"] = 0
        
        stats["total"] = stats["columns"] + stats["tables"] + stats["relationships"]
        stats["provider"] = self.provider
        stats["dimensions"] = self.dimensions
        
        return stats
    
    def list_available_models(self) -> List[Dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸/í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        if not self.conn:
            return []
        
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT DISTINCT embedding_provider, embedding_model, dimensions, 
                   COUNT(*) as table_count
            FROM embedding_metadata
            GROUP BY embedding_provider, embedding_model, dimensions
            ORDER BY dimensions DESC
        """)
        
        results = []
        for row in cursor.fetchall():
            results.append({
                "provider": row[0],
                "model": row[1],
                "dimensions": row[2],
                "table_count": row[3]
            })
        
        return results
