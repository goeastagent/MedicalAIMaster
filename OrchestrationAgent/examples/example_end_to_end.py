#!/usr/bin/env python
"""
OrchestrationAgent End-to-End ì˜ˆì œ
===================================

ì´ ì˜ˆì œëŠ” ìì—°ì–´ ì¿¼ë¦¬ë¡œë¶€í„° ë°ì´í„° ë¶„ì„ê¹Œì§€ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

íŒŒì´í”„ë¼ì¸:
1. ìì—°ì–´ ì¿¼ë¦¬ â†’ ExtractionAgent â†’ Execution Plan
2. Execution Plan â†’ DataContext â†’ DataFrame ë¡œë“œ
3. DataFrame + ë¶„ì„ ìš”ì²­ â†’ AnalysisAgent â†’ ì½”ë“œ ìƒì„± + ì‹¤í–‰ â†’ ê²°ê³¼

ì‚¬ì „ ì¡°ê±´:
- PostgreSQLì— IndexingAgentë¡œ ì¸ë±ì‹±ëœ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
- .env íŒŒì¼ì— DB ì—°ê²° ì •ë³´ì™€ LLM API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
"""

import sys
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def setup_logging(level: str = "INFO"):
    """
    ë¡œê¹… ì„¤ì • - ëª¨ë“  Agentì˜ ë¡œê·¸ë¥¼ ì¶œë ¥
    
    Args:
        level: ë¡œê·¸ ë ˆë²¨ ("DEBUG", "INFO", "WARNING", "ERROR")
    """
    log_level = getattr(logging, level.upper(), logging.INFO)
    
    # ë¡œê·¸ í¬ë§· ì„¤ì •
    log_format = "%(asctime)s | %(name)-30s | %(levelname)-8s | %(message)s"
    date_format = "%H:%M:%S"
    
    # ê¸°ë³¸ ì„¤ì •
    logging.basicConfig(
        level=log_level,
        format=log_format,
        datefmt=date_format,
        handlers=[logging.StreamHandler()]
    )
    
    # ê° ëª¨ë“ˆë³„ ë¡œê±° ì„¤ì • (ì›í•˜ëŠ” ë ˆë²¨ë¡œ ì¡°ì • ê°€ëŠ¥)
    loggers_config = {
        # OrchestrationAgent
        "OrchestrationAgent": log_level,
        "OrchestrationAgent.orchestrator": log_level,
        
        # ExtractionAgent (LangGraph nodes)
        "ExtractionAgent": log_level,
        "ExtractionAgent.agents": log_level,
        "LangGraph": log_level,  # BaseNode ë¡œê±°
        "LangGraph.query_understanding": log_level,
        "LangGraph.parameter_resolver": log_level,
        "LangGraph.plan_builder": log_level,
        
        # AnalysisAgent
        "AnalysisAgent": log_level,
        "AnalysisAgent.code_gen": log_level,
        
        # Shared ëª¨ë“ˆ
        "shared.llm": log_level,
        "shared.llm.client": log_level,
        "shared.data.context": log_level,
        "shared.database": log_level,
        
        # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ë„ˆë¬´ verboseí•˜ë©´ WARNINGìœ¼ë¡œ)
        "httpx": logging.WARNING,
        "httpcore": logging.WARNING,
        "openai": logging.WARNING,
        "urllib3": logging.WARNING,
    }
    
    for logger_name, logger_level in loggers_config.items():
        logging.getLogger(logger_name).setLevel(logger_level)


def example_full_pipeline():
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜ˆì œ - Orchestrator.run() ì‚¬ìš©
    
    ê°€ì¥ ê°„ë‹¨í•œ ì‚¬ìš©ë²•: ì¿¼ë¦¬ í•˜ë‚˜ë¡œ ëª¨ë“  ê²ƒì„ ì²˜ë¦¬
    """
    print("=" * 60)
    print("ì˜ˆì œ 1: ì „ì²´ íŒŒì´í”„ë¼ì¸ (Orchestrator.run)")
    print("=" * 60)
    
    from OrchestrationAgent.src.orchestrator import Orchestrator
    
    # Orchestrator ìƒì„±
    orchestrator = Orchestrator()
    
    # ìì—°ì–´ ì¿¼ë¦¬ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    query = "ìœ„ì•” í™˜ìì˜ ìˆ˜ìˆ  ì¤‘ ì‹¬ë°•ìˆ˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ êµ¬í•´ì¤˜"
    
    print(f"\nğŸ“ Query: {query}\n")
    print("ğŸš€ Running full pipeline...")
    
    result = orchestrator.run(query)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… Status: {result.status}")
    print(f"â±ï¸  Execution time: {result.execution_time_ms:.2f}ms")
    
    if result.status == "success":
        print(f"\nğŸ“Š Result:")
        print(f"   {result.result}")
        
        print(f"\nğŸ’» Generated Code:")
        print("-" * 40)
        print(result.generated_code)
        print("-" * 40)
        
        if result.data_summary:
            print(f"\nğŸ“ˆ Data Summary:")
            print(f"   Cases: {result.data_summary.get('cohort', {}).get('total_cases', 'N/A')}")
            print(f"   Parameters: {result.data_summary.get('signals', {}).get('param_keys', [])[:5]}")
    else:
        print(f"\nâŒ Error: {result.error_message}")
        print(f"   Stage: {result.error_stage}")
    
    return result


def example_with_existing_plan():
    """
    ì´ë¯¸ ìˆëŠ” Execution Planìœ¼ë¡œ ë¶„ì„ (ExtractionAgent ìŠ¤í‚µ)
    
    Planì„ ìºì‹±í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ë§Œë“  ê²½ìš°ì— ìœ ìš©
    """
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 2: ê¸°ì¡´ Planìœ¼ë¡œ ë¶„ì„ (Orchestrator.run_with_plan)")
    print("=" * 60)
    
    from OrchestrationAgent.src.orchestrator import Orchestrator
    from ExtractionAgent.src.facade import ExtractionFacade
    
    # ë¨¼ì € ExtractionFacadeë¡œ Plan ìƒì„±
    extraction = ExtractionFacade()
    plan = extraction.extract("íì•” í™˜ìì˜ í˜ˆì•• ë°ì´í„°")
    
    print(f"\nğŸ“‹ Pre-generated Plan:")
    print(f"   Cohort: {plan.get('execution_plan', {}).get('cohort_source', {}).get('file_name', 'N/A')}")
    print(f"   Signal Group: {plan.get('execution_plan', {}).get('signal_source', {}).get('group_name', 'N/A')}")
    
    # Orchestratorë¡œ ë¶„ì„ë§Œ ì‹¤í–‰
    orchestrator = Orchestrator()
    
    result = orchestrator.run_with_plan(
        query="í˜ˆì••(ABP)ì˜ í‰ê· ê³¼ ìµœëŒ€ê°’ì„ êµ¬í•´ì¤˜",
        execution_plan=plan
    )
    
    print(f"\nâœ… Status: {result.status}")
    
    if result.status == "success":
        print(f"ğŸ“Š Result: {result.result}")
    else:
        print(f"âŒ Error: {result.error_message}")
    
    return result


def example_analysis_only():
    """
    ë°ì´í„°ê°€ ì´ë¯¸ ìˆì„ ë•Œ ë¶„ì„ë§Œ ì‹¤í–‰ (Extraction + DataLoad ìŠ¤í‚µ)
    
    ë°ì´í„°ë¥¼ ì§ì ‘ ì¤€ë¹„í•œ ê²½ìš°ì— ìœ ìš©
    """
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 3: ë¶„ì„ë§Œ ì‹¤í–‰ (Orchestrator.run_analysis_only)")
    print("=" * 60)
    
    import pandas as pd
    import numpy as np
    
    from OrchestrationAgent.src.orchestrator import Orchestrator
    
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±
    np.random.seed(42)
    
    df = pd.DataFrame({
        'Time': np.arange(0, 100, 0.1),
        'HR': np.random.normal(72, 8, 1000),      # ì‹¬ë°•ìˆ˜
        'SpO2': np.random.normal(98, 1, 1000),    # ì‚°ì†Œí¬í™”ë„
        'ABP': np.random.normal(90, 15, 1000),    # í˜ˆì••
        'caseid': np.repeat(['case1', 'case2', 'case3', 'case4', 'case5'], 200)
    })
    
    cohort = pd.DataFrame({
        'caseid': ['case1', 'case2', 'case3', 'case4', 'case5'],
        'age': [65, 58, 72, 45, 68],
        'sex': ['M', 'F', 'M', 'F', 'M'],
        'diagnosis': ['gastric_cancer', 'lung_cancer', 'gastric_cancer', 'lung_cancer', 'gastric_cancer']
    })
    
    print(f"\nğŸ“Š Test Data:")
    print(f"   Signal DataFrame: {df.shape}")
    print(f"   Cohort DataFrame: {cohort.shape}")
    
    # Runtime data êµ¬ì„±
    runtime_data = {
        'df': df,
        'cohort': cohort,
        'case_ids': ['case1', 'case2', 'case3', 'case4', 'case5'],
        'param_keys': ['HR', 'SpO2', 'ABP']
    }
    
    # Orchestratorë¡œ ë¶„ì„ ì‹¤í–‰
    orchestrator = Orchestrator()
    
    result = orchestrator.run_analysis_only(
        query="ì„±ë³„(sex)ì— ë”°ë¥¸ ì‹¬ë°•ìˆ˜(HR) í‰ê· ì„ ë¹„êµí•´ì¤˜",
        runtime_data=runtime_data
    )
    
    print(f"\nâœ… Status: {result.status}")
    print(f"â±ï¸  Execution time: {result.execution_time_ms:.2f}ms")
    
    if result.status == "success":
        print(f"\nğŸ“Š Result:")
        print(f"   {result.result}")
        
        print(f"\nğŸ’» Generated Code:")
        print("-" * 40)
        print(result.generated_code)
        print("-" * 40)
    else:
        print(f"\nâŒ Error: {result.error_message}")
    
    return result


def example_multiple_queries():
    """
    ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ ìˆœì°¨ ì‹¤í–‰
    
    ë™ì¼í•œ ë°ì´í„°ì— ëŒ€í•´ ì—¬ëŸ¬ ë¶„ì„ì„ ìˆ˜í–‰í•  ë•Œ ìœ ìš©
    """
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 4: ì—¬ëŸ¬ ì¿¼ë¦¬ ìˆœì°¨ ì‹¤í–‰")
    print("=" * 60)
    
    import pandas as pd
    import numpy as np
    
    from OrchestrationAgent.src.orchestrator import Orchestrator
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    np.random.seed(42)
    runtime_data = {
        'df': pd.DataFrame({
            'Time': np.arange(0, 50, 0.1),
            'HR': np.random.normal(72, 8, 500),
            'SpO2': np.random.normal(98, 1, 500),
        }),
        'case_ids': ['test_case'],
        'param_keys': ['HR', 'SpO2']
    }
    
    orchestrator = Orchestrator()
    
    queries = [
        "HRì˜ í‰ê· ê°’ì„ êµ¬í•´ì¤˜",
        "HRì´ 80 ì´ìƒì¸ êµ¬ê°„ì˜ ë¹„ìœ¨ì„ êµ¬í•´ì¤˜",
        "HRê³¼ SpO2ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ êµ¬í•´ì¤˜",
    ]
    
    results = []
    
    for i, query in enumerate(queries, 1):
        print(f"\n--- Query {i}: {query} ---")
        
        result = orchestrator.run_analysis_only(query, runtime_data)
        results.append(result)
        
        if result.status == "success":
            print(f"âœ… Result: {result.result}")
        else:
            print(f"âŒ Error: {result.error_message}")
    
    print(f"\nğŸ“Š Summary: {sum(1 for r in results if r.status == 'success')}/{len(results)} succeeded")
    
    return results


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="OrchestrationAgent End-to-End Examples")
    parser.add_argument(
        "--log-level", "-l",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="ë¡œê·¸ ë ˆë²¨ ì„¤ì • (default: INFO)"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="DEBUG ë ˆë²¨ë¡œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥"
    )
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    log_level = "DEBUG" if args.verbose else args.log_level
    setup_logging(log_level)
    
    print("\n" + "=" * 70)
    print("  OrchestrationAgent End-to-End Examples")
    print("=" * 70)
    print(f"  Log Level: {log_level}")
    print("=" * 70)
    
    # ì˜ˆì œ 3ë¶€í„° ì‹¤í–‰ (DB ì—°ê²° ì—†ì´ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥)
    example_analysis_only()
    example_multiple_queries()
    
    # DB ì—°ê²°ì´ í•„ìš”í•œ ì˜ˆì œ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰)
    # example_full_pipeline()
    # example_with_existing_plan()
    
    print("\n" + "=" * 70)
    print("  All examples completed!")
    print("=" * 70)
