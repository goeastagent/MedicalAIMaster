# OrchestrationAgent - ê²½ëŸ‰ ì„¤ê³„

## ğŸ“– ê°œìš”

OrchestrationAgentëŠ” **ExtractionAgent**ì™€ **AnalysisAgent(CodeGen)**ë¥¼ ì—°ê²°í•˜ëŠ” **ì–‡ì€ ì¡°ìœ¨ ë ˆì´ì–´**ì…ë‹ˆë‹¤.

### í•µì‹¬ ì² í•™

```
ìµœì†Œ êµ¬í˜„ (MVP First)
â”œâ”€â”€ ë³µì¡í•œ ê·¸ë˜í”„ ì—†ì´ ìˆœì°¨ ì‹¤í–‰
â”œâ”€â”€ 3ê°œ ì»´í¬ë„ŒíŠ¸ë§Œ ì—°ê²°: Extraction â†’ DataContext â†’ CodeGen
â””â”€â”€ í•„ìš”í•´ì§€ë©´ í™•ì¥
```

---

## ğŸ”„ ì „ì²´ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ì‚¬ìš©ì ì§ˆì˜                                      â”‚
â”‚          "2023ë…„ ìœ„ì•” í™˜ìì˜ ì‹¬ë°•ìˆ˜ í‰ê· ì„ ì„±ë³„ë¡œ ë¹„êµí•´ì¤˜"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Orchestrator                                      â”‚
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Step 1: ExtractionAgent í˜¸ì¶œ                                      â”‚  â”‚
â”‚   â”‚ â€¢ ì¿¼ë¦¬ â†’ Execution Plan ìƒì„±                                      â”‚  â”‚
â”‚   â”‚ â€¢ ì–´ë–¤ ë°ì´í„°ê°€ í•„ìš”í•œì§€, ì–´ë””ì„œ ê°€ì ¸ì˜¬ì§€ ê³„íš                       â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                         â”‚
â”‚                                â–¼                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Step 2: DataContextë¡œ ë°ì´í„° ë¡œë“œ                                  â”‚  â”‚
â”‚   â”‚ â€¢ Execution Plan í•´ì„                                             â”‚  â”‚
â”‚   â”‚ â€¢ Cohort + Signal ë°ì´í„° ë¡œë“œ                                     â”‚  â”‚
â”‚   â”‚ â€¢ runtime_data ì¤€ë¹„ (df, cohort, case_ids, param_keys)           â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                         â”‚
â”‚                                â–¼                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ Step 3: CodeGeneratorë¡œ ë¶„ì„ ì‹¤í–‰                                  â”‚  â”‚
â”‚   â”‚ â€¢ ë¶„ì„ íƒœìŠ¤í¬ â†’ Python ì½”ë“œ ìƒì„±                                   â”‚  â”‚
â”‚   â”‚ â€¢ Sandboxì—ì„œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰                                        â”‚  â”‚
â”‚   â”‚ â€¢ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ì¬ì‹œë„                               â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ë¶„ì„ ê²°ê³¼ ë°˜í™˜                                    â”‚
â”‚          {"status": "success", "result": {...}, "code": "..."}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
OrchestrationAgent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py          # ë©”ì¸ í´ë˜ìŠ¤ (í•µì‹¬)
â”‚   â”œâ”€â”€ models.py                # ì…ì¶œë ¥ ëª¨ë¸
â”‚   â””â”€â”€ config.py                # ì„¤ì •
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_orchestrator.py     # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_e2e.py              # E2E í…ŒìŠ¤íŠ¸
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ basic_usage.py
â”‚
â”œâ”€â”€ ARCHITECTURE.md              # ì´ ë¬¸ì„œ
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“‹ êµ¬í˜„ ìƒì„¸

### 1. ëª¨ë¸ ì •ì˜ (`src/models.py`)

```python
"""Orchestrator ì…ì¶œë ¥ ëª¨ë¸"""

from typing import Dict, List, Any, Optional, Literal
from pydantic import BaseModel, Field
from datetime import datetime


class OrchestrationRequest(BaseModel):
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ìš”ì²­"""
    
    query: str
    # "2023ë…„ ìœ„ì•” í™˜ìì˜ ì‹¬ë°•ìˆ˜ í‰ê· ì„ ì„±ë³„ë¡œ ë¹„êµí•´ì¤˜"
    
    # ì„ íƒì  ì˜µì…˜
    max_retries: int = Field(default=2, ge=0, le=5)
    timeout_seconds: int = Field(default=30, ge=5, le=120)
    auto_resolve_ambiguity: bool = True


class OrchestrationResult(BaseModel):
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê²°ê³¼"""
    
    status: Literal["success", "error", "partial"]
    
    # ì„±ê³µ ì‹œ
    result: Optional[Any] = None
    generated_code: Optional[str] = None
    
    # ì‹¤íŒ¨ ì‹œ
    error_message: Optional[str] = None
    error_stage: Optional[Literal["extraction", "data_load", "analysis"]] = None
    
    # ë©”íƒ€ë°ì´í„°
    execution_time_ms: Optional[float] = None
    data_summary: Optional[Dict[str, Any]] = None
    
    # ë””ë²„ê·¸ ì •ë³´ (ì„ íƒì )
    extraction_plan: Optional[Dict[str, Any]] = None
    retry_count: int = 0


class AnalysisTask(BaseModel):
    """ë¶„ì„ íƒœìŠ¤í¬ (CodeGenì— ì „ë‹¬)"""
    
    description: str
    # "ì‹¬ë°•ìˆ˜(HR)ì˜ í‰ê· ì„ ì„±ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê³„ì‚°"
    
    expected_output: str = "ë¶„ì„ ê²°ê³¼ë¥¼ result ë³€ìˆ˜ì— ì €ì¥"
    # "ë”•ì…”ë„ˆë¦¬ í˜•íƒœ: {sex: mean_hr}"
    
    hints: Optional[str] = None
    # "df.groupby() ì‚¬ìš©, cohortì—ì„œ sex ì»¬ëŸ¼ ì°¸ì¡°"
```

---

### 2. ë©”ì¸ í´ë˜ìŠ¤ (`src/orchestrator.py`)

```python
"""ê²½ëŸ‰ Orchestrator - ExtractionAgent + DataContext + CodeGen ì—°ê²°"""

import time
from typing import Dict, Any, Optional
from .models import OrchestrationRequest, OrchestrationResult, AnalysisTask
from .config import OrchestratorConfig


class Orchestrator:
    """
    ExtractionAgentì™€ AnalysisAgent(CodeGen)ë¥¼ ì—°ê²°í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    
    ì‚¬ìš©ë²•:
        orchestrator = Orchestrator()
        result = orchestrator.run("ìœ„ì•” í™˜ìì˜ ì‹¬ë°•ìˆ˜ í‰ê· ì„ êµ¬í•´ì¤˜")
        
        if result.status == "success":
            print(result.result)
            print(result.generated_code)
    """
    
    def __init__(self, config: Optional[OrchestratorConfig] = None):
        self.config = config or OrchestratorConfig()
        
        # Lazy initialization
        self._extraction_agent = None
        self._data_context = None
        self._code_generator = None
        self._sandbox = None
        self._llm_client = None
    
    # =========================================================================
    # Public API
    # =========================================================================
    
    def run(
        self, 
        query: str,
        max_retries: int = None,
        timeout_seconds: int = None
    ) -> OrchestrationResult:
        """
        ì§ˆì˜ ì‹¤í–‰ - ì „ì²´ íŒŒì´í”„ë¼ì¸
        
        Args:
            query: ìì—°ì–´ ì§ˆì˜
            max_retries: ì½”ë“œ ìƒì„± ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸: config ê°’)
            timeout_seconds: ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸: config ê°’)
        
        Returns:
            OrchestrationResult
        """
        start_time = time.time()
        
        max_retries = max_retries if max_retries is not None else self.config.max_retries
        timeout = timeout_seconds if timeout_seconds is not None else self.config.timeout_seconds
        
        try:
            # Step 1: Extraction - ì‹¤í–‰ ê³„íš ìƒì„±
            extraction_result = self._run_extraction(query)
            
            if not extraction_result.get("execution_plan"):
                return OrchestrationResult(
                    status="error",
                    error_message="Extraction failed: No execution plan generated",
                    error_stage="extraction",
                    extraction_plan=extraction_result
                )
            
            execution_plan = extraction_result["execution_plan"]
            
            # Step 2: Data Load - ë°ì´í„° ë¡œë“œ
            runtime_data, data_summary = self._load_data(execution_plan)
            
            if not runtime_data:
                return OrchestrationResult(
                    status="error",
                    error_message="Data loading failed: No data available",
                    error_stage="data_load",
                    extraction_plan=execution_plan
                )
            
            # Step 3: Analysis - ì½”ë“œ ìƒì„± ë° ì‹¤í–‰
            analysis_result = self._run_analysis(
                query=query,
                runtime_data=runtime_data,
                data_summary=data_summary,
                max_retries=max_retries,
                timeout=timeout
            )
            
            execution_time = (time.time() - start_time) * 1000
            
            return OrchestrationResult(
                status="success" if analysis_result["success"] else "error",
                result=analysis_result.get("result"),
                generated_code=analysis_result.get("code"),
                error_message=analysis_result.get("error"),
                error_stage="analysis" if not analysis_result["success"] else None,
                execution_time_ms=execution_time,
                data_summary=data_summary,
                extraction_plan=execution_plan,
                retry_count=analysis_result.get("retry_count", 0)
            )
        
        except Exception as e:
            return OrchestrationResult(
                status="error",
                error_message=str(e),
                execution_time_ms=(time.time() - start_time) * 1000
            )
    
    def run_with_plan(
        self,
        query: str,
        execution_plan: Dict[str, Any],
        max_retries: int = None
    ) -> OrchestrationResult:
        """
        ì´ë¯¸ ìˆëŠ” Execution Planìœ¼ë¡œ ë¶„ì„ ì‹¤í–‰
        (ExtractionAgent ìŠ¤í‚µ)
        
        Args:
            query: ë¶„ì„ ì§ˆì˜
            execution_plan: ë¯¸ë¦¬ ìƒì„±ëœ ì‹¤í–‰ ê³„íš
            max_retries: ì¬ì‹œë„ íšŸìˆ˜
        """
        start_time = time.time()
        max_retries = max_retries if max_retries is not None else self.config.max_retries
        
        try:
            # Data Load
            runtime_data, data_summary = self._load_data(execution_plan)
            
            if not runtime_data:
                return OrchestrationResult(
                    status="error",
                    error_message="Data loading failed",
                    error_stage="data_load"
                )
            
            # Analysis
            analysis_result = self._run_analysis(
                query=query,
                runtime_data=runtime_data,
                data_summary=data_summary,
                max_retries=max_retries
            )
            
            return OrchestrationResult(
                status="success" if analysis_result["success"] else "error",
                result=analysis_result.get("result"),
                generated_code=analysis_result.get("code"),
                error_message=analysis_result.get("error"),
                execution_time_ms=(time.time() - start_time) * 1000,
                data_summary=data_summary,
                retry_count=analysis_result.get("retry_count", 0)
            )
        
        except Exception as e:
            return OrchestrationResult(
                status="error",
                error_message=str(e)
            )
    
    def run_analysis_only(
        self,
        query: str,
        runtime_data: Dict[str, Any],
        max_retries: int = None
    ) -> OrchestrationResult:
        """
        ë°ì´í„°ê°€ ì´ë¯¸ ìˆì„ ë•Œ ë¶„ì„ë§Œ ì‹¤í–‰
        (Extraction + DataLoad ìŠ¤í‚µ)
        
        Args:
            query: ë¶„ì„ ì§ˆì˜
            runtime_data: ì´ë¯¸ ë¡œë“œëœ ë°ì´í„° {"df": ..., "cohort": ...}
            max_retries: ì¬ì‹œë„ íšŸìˆ˜
        """
        start_time = time.time()
        max_retries = max_retries if max_retries is not None else self.config.max_retries
        
        # ë°ì´í„° ìš”ì•½ ìƒì„±
        data_summary = self._create_data_summary(runtime_data)
        
        # Analysis
        analysis_result = self._run_analysis(
            query=query,
            runtime_data=runtime_data,
            data_summary=data_summary,
            max_retries=max_retries
        )
        
        return OrchestrationResult(
            status="success" if analysis_result["success"] else "error",
            result=analysis_result.get("result"),
            generated_code=analysis_result.get("code"),
            error_message=analysis_result.get("error"),
            execution_time_ms=(time.time() - start_time) * 1000,
            data_summary=data_summary,
            retry_count=analysis_result.get("retry_count", 0)
        )
    
    # =========================================================================
    # Step 1: Extraction
    # =========================================================================
    
    def _run_extraction(self, query: str) -> Dict[str, Any]:
        """ExtractionAgent í˜¸ì¶œí•˜ì—¬ Execution Plan ìƒì„±"""
        
        if self._extraction_agent is None:
            self._extraction_agent = self._create_extraction_agent()
        
        # ExtractionAgent ì‹¤í–‰
        result = self._extraction_agent.invoke({"user_query": query})
        
        # ê²°ê³¼ì—ì„œ plan ì¶”ì¶œ
        return {
            "execution_plan": result.get("validated_plan") or result.get("execution_plan"),
            "confidence": result.get("overall_confidence", 0.0),
            "ambiguities": result.get("ambiguities", []),
            "intent": result.get("intent")
        }
    
    def _create_extraction_agent(self):
        """ExtractionAgent ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        from ExtractionAgent.src.agents.graph import create_extraction_graph
        return create_extraction_graph()
    
    # =========================================================================
    # Step 2: Data Load
    # =========================================================================
    
    def _load_data(
        self, 
        execution_plan: Dict[str, Any]
    ) -> tuple[Dict[str, Any], Dict[str, Any]]:
        """DataContextë¡œ ë°ì´í„° ë¡œë“œ"""
        
        from shared.data.context import DataContext
        
        ctx = DataContext()
        ctx.load_from_plan(execution_plan, preload_cohort=True)
        
        # runtime_data êµ¬ì„±
        runtime_data = {}
        
        # Cohort
        cohort = ctx.get_cohort()
        if not cohort.empty:
            runtime_data["cohort"] = cohort
        
        # Signals
        signals = ctx.get_signals()
        if not signals.empty:
            runtime_data["df"] = signals
        
        # ë©”íƒ€ë°ì´í„°
        runtime_data["case_ids"] = ctx.get_case_ids()
        runtime_data["param_keys"] = ctx.get_available_parameters()
        
        # ìš”ì•½ ìƒì„±
        data_summary = ctx.summary()
        
        # DataContext ì €ì¥ (ì¬ì‚¬ìš© ê°€ëŠ¥)
        self._data_context = ctx
        
        return runtime_data, data_summary
    
    def _create_data_summary(self, runtime_data: Dict[str, Any]) -> Dict[str, Any]:
        """runtime_dataì—ì„œ ìš”ì•½ ìƒì„±"""
        summary = {}
        
        if "df" in runtime_data:
            df = runtime_data["df"]
            summary["signals"] = {
                "shape": df.shape,
                "columns": list(df.columns)
            }
        
        if "cohort" in runtime_data:
            cohort = runtime_data["cohort"]
            summary["cohort"] = {
                "shape": cohort.shape,
                "columns": list(cohort.columns)
            }
        
        summary["case_count"] = len(runtime_data.get("case_ids", []))
        summary["param_keys"] = runtime_data.get("param_keys", [])
        
        return summary
    
    # =========================================================================
    # Step 3: Analysis (CodeGen)
    # =========================================================================
    
    def _run_analysis(
        self,
        query: str,
        runtime_data: Dict[str, Any],
        data_summary: Dict[str, Any],
        max_retries: int = 2,
        timeout: int = 30
    ) -> Dict[str, Any]:
        """CodeGeneratorë¡œ ë¶„ì„ ì½”ë“œ ìƒì„± ë° ì‹¤í–‰"""
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        if self._code_generator is None:
            self._init_code_gen_components()
        
        # ExecutionContext ìƒì„±
        exec_context = self._build_execution_context(runtime_data, data_summary)
        
        # CodeRequest ìƒì„±
        request = self._build_code_request(query, exec_context, data_summary)
        
        # ìƒì„± + ì‹¤í–‰ (with retry)
        last_error = None
        generated_code = None
        
        for attempt in range(max_retries + 1):
            # ì²« ì‹œë„ ë˜ëŠ” ì¬ì‹œë„
            if attempt == 0:
                gen_result = self._code_generator.generate(request)
            else:
                gen_result = self._code_generator.generate_with_fix(
                    request, 
                    generated_code, 
                    last_error
                )
            
            generated_code = gen_result.code
            
            # ê²€ì¦ ì‹¤íŒ¨
            if not gen_result.is_valid:
                last_error = f"Validation failed: {gen_result.validation_errors}"
                continue
            
            # ì‹¤í–‰
            exec_result = self._sandbox.execute(gen_result.code, runtime_data)
            
            if exec_result.success:
                return {
                    "success": True,
                    "result": exec_result.result,
                    "code": gen_result.code,
                    "retry_count": attempt
                }
            
            last_error = exec_result.error
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        return {
            "success": False,
            "error": last_error,
            "code": generated_code,
            "retry_count": max_retries + 1
        }
    
    def _init_code_gen_components(self):
        """CodeGeneratorì™€ Sandbox ì´ˆê¸°í™”"""
        from AnalysisAgent.src.code_gen import CodeGenerator, SandboxExecutor
        from shared.llm import get_llm_client
        
        if self._llm_client is None:
            self._llm_client = get_llm_client()
        
        self._code_generator = CodeGenerator(llm_client=self._llm_client)
        self._sandbox = SandboxExecutor(timeout_seconds=self.config.timeout_seconds)
    
    def _build_execution_context(
        self, 
        runtime_data: Dict[str, Any],
        data_summary: Dict[str, Any]
    ):
        """CodeGenìš© ExecutionContext ìƒì„±"""
        from AnalysisAgent.src.models import ExecutionContext
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ë³€ìˆ˜ ì„¤ëª…
        available_variables = {}
        
        if "df" in runtime_data:
            df = runtime_data["df"]
            available_variables["df"] = (
                f"pandas DataFrame - Signal ë°ì´í„°, "
                f"shape: {df.shape}, columns: {list(df.columns)[:10]}"
            )
        
        if "cohort" in runtime_data:
            cohort = runtime_data["cohort"]
            available_variables["cohort"] = (
                f"pandas DataFrame - Cohort ë©”íƒ€ë°ì´í„°, "
                f"shape: {cohort.shape}, columns: {list(cohort.columns)[:10]}"
            )
        
        available_variables["case_ids"] = f"List[str] - {len(runtime_data.get('case_ids', []))}ê°œ ì¼€ì´ìŠ¤ ID"
        available_variables["param_keys"] = f"List[str] - íŒŒë¼ë¯¸í„° í‚¤ ëª©ë¡: {runtime_data.get('param_keys', [])}"
        
        # ìƒ˜í”Œ ë°ì´í„° (LLM ì°¸ê³ ìš©)
        sample_data = {}
        if "df" in runtime_data and not runtime_data["df"].empty:
            sample_data["df_head"] = runtime_data["df"].head(3).to_dict(orient="records")
        if "cohort" in runtime_data and not runtime_data["cohort"].empty:
            sample_data["cohort_head"] = runtime_data["cohort"].head(3).to_dict(orient="records")
        
        return ExecutionContext(
            available_variables=available_variables,
            sample_data=sample_data if sample_data else None
        )
    
    def _build_code_request(
        self, 
        query: str,
        exec_context,
        data_summary: Dict[str, Any]
    ):
        """CodeRequest ìƒì„±"""
        from AnalysisAgent.src.models import CodeRequest
        
        # íŒíŠ¸ ìƒì„±
        hints = self._generate_hints(query, data_summary)
        
        return CodeRequest(
            task_description=query,
            expected_output="ë¶„ì„ ê²°ê³¼ë¥¼ result ë³€ìˆ˜ì— ì €ì¥. ë”•ì…”ë„ˆë¦¬, ìˆ«ì, ë˜ëŠ” DataFrame í˜•íƒœ.",
            execution_context=exec_context,
            hints=hints,
            constraints=[
                "NaN ê°’ì€ dropna() ë˜ëŠ” fillna()ë¡œ ì²˜ë¦¬",
                "result ë³€ìˆ˜ì— ìµœì¢… ê²°ê³¼ ì €ì¥ í•„ìˆ˜",
                "ë£¨í”„ ëŒ€ì‹  pandas/numpy ë²¡í„° ì—°ì‚° ì‚¬ìš©"
            ]
        )
    
    def _generate_hints(self, query: str, data_summary: Dict[str, Any]) -> str:
        """ì§ˆì˜ ê¸°ë°˜ êµ¬í˜„ íŒíŠ¸ ìƒì„±"""
        hints = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ íŒíŠ¸
        query_lower = query.lower()
        
        if "í‰ê· " in query_lower or "mean" in query_lower:
            hints.append("df['column'].mean() ë˜ëŠ” df.groupby('group')['column'].mean() ì‚¬ìš©")
        
        if "ë¹„êµ" in query_lower or "ê·¸ë£¹" in query_lower or "ì„±ë³„" in query_lower:
            hints.append("cohort DataFrameì—ì„œ ê·¸ë£¹ ì •ë³´ ì°¸ì¡° (ì˜ˆ: cohort['sex'])")
            hints.append("dfì™€ cohortë¥¼ case_idë¡œ ì¡°ì¸ í•„ìš”í•  ìˆ˜ ìˆìŒ")
        
        if "ìƒê´€" in query_lower or "correlation" in query_lower:
            hints.append("scipy.stats.pearsonr() ë˜ëŠ” df.corr() ì‚¬ìš©")
        
        if "ë¶„í¬" in query_lower or "distribution" in query_lower:
            hints.append("df['column'].describe() ë˜ëŠ” value_counts() ì‚¬ìš©")
        
        # ë°ì´í„° êµ¬ì¡° íŒíŠ¸
        if data_summary.get("param_keys"):
            hints.append(f"ì‚¬ìš© ê°€ëŠ¥í•œ signal íŒŒë¼ë¯¸í„°: {data_summary['param_keys'][:5]}")
        
        return "\n".join(hints) if hints else None
    
    # =========================================================================
    # Utility
    # =========================================================================
    
    def get_data_context(self):
        """í˜„ì¬ DataContext ë°˜í™˜ (ë°ì´í„° ì¬ì‚¬ìš©ìš©)"""
        return self._data_context
    
    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        from shared.data.context import DataContext
        DataContext.clear_cache()
        self._data_context = None
```

---

### 3. ì„¤ì • (`src/config.py`)

```python
"""Orchestrator ì„¤ì •"""

from dataclasses import dataclass


@dataclass
class OrchestratorConfig:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„¤ì •"""
    
    # ì½”ë“œ ìƒì„±
    max_retries: int = 2
    timeout_seconds: int = 30
    
    # ExtractionAgent
    auto_resolve_ambiguity: bool = True
    
    # DataContext
    preload_cohort: bool = True
    cache_signals: bool = True
```

---

### 4. íŒ¨í‚¤ì§€ ì´ˆê¸°í™” (`src/__init__.py`)

```python
"""OrchestrationAgent - ê²½ëŸ‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

from .orchestrator import Orchestrator
from .models import OrchestrationRequest, OrchestrationResult, AnalysisTask
from .config import OrchestratorConfig

__all__ = [
    "Orchestrator",
    "OrchestrationRequest",
    "OrchestrationResult",
    "AnalysisTask",
    "OrchestratorConfig",
]
```

---

## ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ì‚¬ìš©

```python
from OrchestrationAgent.src import Orchestrator

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
orchestrator = Orchestrator()

# ì§ˆì˜ ì‹¤í–‰
result = orchestrator.run(
    "2023ë…„ ìœ„ì•” í™˜ìì˜ ì‹¬ë°•ìˆ˜ í‰ê· ì„ ì„±ë³„ë¡œ ë¹„êµí•´ì¤˜"
)

# ê²°ê³¼ í™•ì¸
if result.status == "success":
    print("ë¶„ì„ ê²°ê³¼:", result.result)
    print("ìƒì„±ëœ ì½”ë“œ:")
    print(result.generated_code)
else:
    print("ì—ëŸ¬:", result.error_message)
    print("ì‹¤íŒ¨ ë‹¨ê³„:", result.error_stage)
```

### ë‹¨ê³„ë³„ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)

```python
orchestrator = Orchestrator()

# Step 1: Extractionë§Œ ì‹¤í–‰
extraction_result = orchestrator._run_extraction(
    "ìœ„ì•” í™˜ìì˜ ì‹¬ë°•ìˆ˜ ë°ì´í„°"
)
print("Execution Plan:", extraction_result["execution_plan"])

# Step 2: ë°ì´í„° ë¡œë“œ
runtime_data, summary = orchestrator._load_data(
    extraction_result["execution_plan"]
)
print("ë¡œë“œëœ ì¼€ì´ìŠ¤ ìˆ˜:", len(runtime_data["case_ids"]))
print("Signal shape:", runtime_data["df"].shape)

# Step 3: ë¶„ì„ë§Œ ì‹¤í–‰
result = orchestrator.run_analysis_only(
    query="ì‹¬ë°•ìˆ˜ í‰ê· ì„ êµ¬í•´ì¤˜",
    runtime_data=runtime_data
)
print("ê²°ê³¼:", result.result)
```

### ë°ì´í„° ì¬ì‚¬ìš©

```python
orchestrator = Orchestrator()

# ì²« ë²ˆì§¸ ì§ˆì˜ (ë°ì´í„° ë¡œë“œ í¬í•¨)
result1 = orchestrator.run("ìœ„ì•” í™˜ìì˜ ì‹¬ë°•ìˆ˜ í‰ê· ")

# ê°™ì€ ë°ì´í„°ë¡œ ì¶”ê°€ ë¶„ì„ (ë°ì´í„° ë¡œë“œ ìŠ¤í‚µ)
ctx = orchestrator.get_data_context()
runtime_data = {
    "df": ctx.get_signals(),
    "cohort": ctx.get_cohort(),
    "case_ids": ctx.get_case_ids(),
    "param_keys": ctx.get_available_parameters()
}

result2 = orchestrator.run_analysis_only(
    query="SpO2ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì¤˜",
    runtime_data=runtime_data
)
```

---

## âœ… êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
=== Phase 1: í•µì‹¬ êµ¬í˜„ (ìš°ì„ ) ===
[ ] 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
[ ] 2. src/models.py
[ ] 3. src/config.py
[ ] 4. src/orchestrator.py
[ ] 5. src/__init__.py

=== Phase 2: í…ŒìŠ¤íŠ¸ ===
[ ] 6. tests/test_orchestrator.py (Mock ì‚¬ìš©)
[ ] 7. tests/test_e2e.py (ì‹¤ì œ LLM ì‚¬ìš©)

=== Phase 3: ë¬¸ì„œí™” ===
[ ] 8. examples/basic_usage.py
[ ] 9. README.md
[ ] 10. requirements.txt
```

---

## ğŸ”— ì˜ì¡´ì„±

```python
# í•„ìš”í•œ importë“¤

# ExtractionAgent
from ExtractionAgent.src.agents.graph import create_extraction_graph

# AnalysisAgent (CodeGen)
from AnalysisAgent.src.code_gen import CodeGenerator, SandboxExecutor
from AnalysisAgent.src.models import CodeRequest, ExecutionContext

# Shared
from shared.data.context import DataContext
from shared.llm import get_llm_client
```

---

## ğŸ“ í™•ì¥ í¬ì¸íŠ¸

ë‚˜ì¤‘ì— í•„ìš”í•˜ë©´ ì¶”ê°€:

| ê¸°ëŠ¥ | ì„¤ëª… | ìš°ì„ ìˆœìœ„ |
|------|------|---------|
| **IntentRouter** | ì§ˆì˜ ìœ í˜• ë¶„ë¥˜ (extraction_only vs analysis) | ë‚®ìŒ |
| **SessionManager** | ë©€í‹°í„´ ëŒ€í™”, follow-up ì§€ì› | ì¤‘ê°„ |
| **ToolRegistry** | ë¯¸ë¦¬ ì •ì˜ëœ ë¶„ì„ Tool ë“±ë¡/ì‚¬ìš© | ë‚®ìŒ |
| **ResultCache** | ë™ì¼ ì§ˆì˜ ê²°ê³¼ ìºì‹± | ì¤‘ê°„ |
| **StreamingResult** | ëŒ€ìš©ëŸ‰ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ | ë‚®ìŒ |

---

## ìš”ì•½

```
Orchestrator = ì–‡ì€ ì—°ê²° ë ˆì´ì–´

run(query)
â”œâ”€â”€ _run_extraction(query)      # ExtractionAgent â†’ Plan
â”œâ”€â”€ _load_data(plan)            # DataContext â†’ runtime_data  
â””â”€â”€ _run_analysis(query, data)  # CodeGenerator â†’ result

ì´ ~300ì¤„, í•µì‹¬ ë¡œì§ë§Œ êµ¬í˜„
```
