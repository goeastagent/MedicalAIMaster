#!/usr/bin/env python3
"""
OrchestrationAgent ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
==========================================

ExtractionAgent â†’ DataContext â†’ CodeGen ì „ì²´ íë¦„ í…ŒìŠ¤íŠ¸

Usage:
    cd /path/to/MedicalAIMaster
    python OrchestrationAgent/test_full_pipeline.py

í•„ìš” ì¡°ê±´:
    - LLM API í‚¤ ì„¤ì • (OPENAI_API_KEY ë˜ëŠ” ANTHROPIC_API_KEY)
    - PostgreSQL DB ì—°ê²°
    - Neo4j DB ì—°ê²° (ì‹œê·¸ë„ ë§¤í•‘ìš©)
    - Indexing ì™„ë£Œëœ ìƒíƒœ
"""

import sys
import time
from pathlib import Path
from typing import Dict, Any, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def print_header(title: str):
    """ì„¹ì…˜ í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)


def print_subheader(title: str):
    """ì„œë¸Œ í—¤ë” ì¶œë ¥"""
    print(f"\n  ğŸ“Œ {title}")
    print("  " + "-" * 50)


def check_prerequisites() -> bool:
    """í•„ìˆ˜ ì¡°ê±´ í™•ì¸"""
    print_header("í•„ìˆ˜ ì¡°ê±´ í™•ì¸")
    
    all_ok = True
    
    # 1. LLM API í‚¤ í™•ì¸
    print_subheader("LLM API í‚¤")
    try:
        from shared.config import LLMConfig
        has_openai = bool(LLMConfig.OPENAI_API_KEY)
        has_anthropic = bool(LLMConfig.ANTHROPIC_API_KEY)
        
        if has_openai or has_anthropic:
            print(f"     âœ… OpenAI: {'ì„¤ì •ë¨' if has_openai else 'ë¯¸ì„¤ì •'}")
            print(f"     âœ… Anthropic: {'ì„¤ì •ë¨' if has_anthropic else 'ë¯¸ì„¤ì •'}")
        else:
            print("     âŒ LLM API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            all_ok = False
    except Exception as e:
        print(f"     âŒ LLM ì„¤ì • í™•ì¸ ì‹¤íŒ¨: {e}")
        all_ok = False
    
    # 2. DB ì—°ê²° í™•ì¸
    print_subheader("Database ì—°ê²°")
    try:
        from shared.database.connection import get_db_manager
        db = get_db_manager()
        
        # PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸
        conn = db.get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        cursor.close()
        print("     âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
        
    except Exception as e:
        print(f"     âŒ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        all_ok = False
    
    try:
        # Neo4j ì—°ê²° í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
        from shared.database.neo4j_connection import get_neo4j_manager
        neo4j = get_neo4j_manager()
        
        with neo4j.driver.session() as session:
            session.run("RETURN 1")
        print("     âœ… Neo4j ì—°ê²° ì„±ê³µ")
        
    except Exception as e:
        print(f"     âš ï¸ Neo4j ì—°ê²° ì‹¤íŒ¨ (ì„ íƒì‚¬í•­): {type(e).__name__}")
    
    # 3. Indexing ìƒíƒœ í™•ì¸
    print_subheader("Indexing ìƒíƒœ")
    try:
        conn = db.get_connection()
        conn.rollback()  # ì´ì „ íŠ¸ëœì­ì…˜ ì •ë¦¬
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM file_catalog")
        file_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM parameter")
        param_count = cursor.fetchone()[0]
        
        cursor.close()
        
        print(f"     - file_catalog: {file_count} files")
        print(f"     - parameter: {param_count} parameters")
        
        if file_count == 0:
            print("     âš ï¸ íŒŒì¼ì´ ì¸ë±ì‹±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        if param_count == 0:
            print("     âš ï¸ íŒŒë¼ë¯¸í„°ê°€ ì¸ë±ì‹±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            print("     â†’ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ê°€ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
    except Exception as e:
        print(f"     âš ï¸ Indexing ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # 3. ëª¨ë“ˆ ì„í¬íŠ¸ í™•ì¸
    print_subheader("ëª¨ë“ˆ ì„í¬íŠ¸")
    try:
        from OrchestrationAgent.src import Orchestrator
        print("     âœ… Orchestrator ì„í¬íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"     âŒ Orchestrator ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        all_ok = False
    
    try:
        from ExtractionAgent.src.agents.graph import build_agent
        print("     âœ… ExtractionAgent ì„í¬íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"     âŒ ExtractionAgent ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        all_ok = False
    
    try:
        from shared.data.context import DataContext
        print("     âœ… DataContext ì„í¬íŠ¸ ì„±ê³µ")
    except Exception as e:
        print(f"     âŒ DataContext ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        all_ok = False
    
    return all_ok


def test_extraction_only(query: str) -> Dict[str, Any]:
    """ExtractionAgentë§Œ í…ŒìŠ¤íŠ¸"""
    print_subheader(f"ExtractionAgent í…ŒìŠ¤íŠ¸")
    print(f"     Query: \"{query}\"")
    
    try:
        # ExtractionAgentë¥¼ sys.path ì•ì— ì¶”ê°€ (src.agents import ìœ„í•´)
        extraction_path = str(project_root / "ExtractionAgent")
        if extraction_path not in sys.path:
            sys.path.insert(0, extraction_path)
        
        # src.agentsë¡œ import (ExtractionAgent ë‚´ë¶€ import ê²½ë¡œì™€ ì¼ì¹˜)
        from src.agents.graph import build_agent
        
        agent = build_agent()
        
        initial_state = {
            "user_query": query,
            "schema_context": None,
            "intent": None,
            "requested_parameters": None,
            "cohort_filters": None,
            "temporal_context": None,
            "resolved_parameters": None,
            "ambiguities": None,
            "has_ambiguity": None,
            "execution_plan": None,
            "validation": None,
            "logs": [],
            "error_message": None
        }
        
        start_time = time.time()
        result = agent.invoke(initial_state)
        elapsed = (time.time() - start_time) * 1000
        
        execution_plan = result.get("execution_plan")
        
        if execution_plan:
            print(f"     âœ… Execution Plan ìƒì„± ì™„ë£Œ ({elapsed:.0f}ms)")
            
            plan = execution_plan.get("execution_plan", {})
            cohort = plan.get("cohort_source") or {}
            signals = plan.get("signal_source") or {}
            
            cohort_id = cohort.get('file_id', 'N/A')
            signal_id = signals.get('group_id', 'N/A')
            
            print(f"        - cohort_file_id: {cohort_id[:8] if cohort_id and cohort_id != 'N/A' else 'N/A'}...")
            print(f"        - filters: {len(cohort.get('filters', []))}ê°œ")
            print(f"        - signal_group_id: {signal_id[:8] if signal_id and signal_id != 'N/A' else 'N/A'}...")
            print(f"        - parameters: {len(signals.get('parameters', []))}ê°œ")
            
            # Validation ì²´í¬
            validation = result.get("validation", {})
            confidence = validation.get("confidence", 0)
            warnings = validation.get("warnings", [])
            
            if confidence < 0.5 or not cohort or not signals:
                print(f"\n     âš ï¸ Planì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤ (confidence: {confidence:.2f})")
                if warnings:
                    for w in warnings[:3]:
                        print(f"        - {w}")
                
                # ë¶ˆì™„ì „í•œ planì´ì§€ë§Œ êµ¬ì¡°ëŠ” ìƒì„±ë¨
                return {"success": False, "plan": execution_plan, "result": result, "error": "Incomplete plan"}
            
            return {"success": True, "plan": execution_plan, "result": result}
        else:
            error = result.get("error_message", "Unknown error")
            print(f"     âŒ Extraction ì‹¤íŒ¨: {error}")
            return {"success": False, "error": error}
            
    except Exception as e:
        print(f"     âŒ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def test_data_load(execution_plan: Dict[str, Any]) -> Dict[str, Any]:
    """DataContext ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    print_subheader("DataContext ë¡œë“œ í…ŒìŠ¤íŠ¸")
    
    try:
        from shared.data.context import DataContext
        
        ctx = DataContext()
        
        start_time = time.time()
        ctx.load_from_plan(execution_plan, preload_cohort=True)
        elapsed = (time.time() - start_time) * 1000
        
        if ctx.is_loaded():
            print(f"     âœ… DataContext ë¡œë“œ ì™„ë£Œ ({elapsed:.0f}ms)")
            
            # Cohort ë°ì´í„°
            cohort = ctx.get_cohort()
            if cohort is not None:
                print(f"        - Cohort: {len(cohort)} rows")
            
            # Signal íŒŒì¼ ì •ë³´
            case_ids = ctx.get_case_ids()
            print(f"        - Case IDs: {len(case_ids)}ê°œ")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°
            params = ctx.get_available_parameters()
            print(f"        - Parameters: {params}")
            
            return {
                "success": True,
                "context": ctx,
                "case_count": len(case_ids),
                "param_keys": params
            }
        else:
            print("     âŒ DataContext ë¡œë“œ ì‹¤íŒ¨")
            return {"success": False, "error": "Load failed"}
            
    except Exception as e:
        print(f"     âŒ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def test_full_orchestration(query: str) -> Dict[str, Any]:
    """ì „ì²´ Orchestration í…ŒìŠ¤íŠ¸"""
    print_subheader(f"ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print(f"     Query: \"{query}\"")
    
    try:
        from OrchestrationAgent.src import Orchestrator
        from OrchestrationAgent.src.config import OrchestratorConfig
        
        config = OrchestratorConfig(
            max_retries=2,
            timeout_seconds=60
        )
        
        orch = Orchestrator(config=config)
        
        start_time = time.time()
        result = orch.run(query)
        elapsed = (time.time() - start_time) * 1000
        
        print(f"\n     ğŸ“Š ê²°ê³¼:")
        print(f"        - Status: {result.status}")
        print(f"        - Time: {elapsed:.0f}ms")
        
        if result.status == "success":
            print(f"        - Result: {result.result}")
            print(f"\n     ğŸ“ Generated Code:")
            if result.generated_code:
                for line in result.generated_code.split('\n')[:10]:
                    print(f"        {line}")
                if len(result.generated_code.split('\n')) > 10:
                    print("        ...")
            
            return {"success": True, "result": result}
        else:
            print(f"        - Error Stage: {result.error_stage}")
            print(f"        - Error: {result.error_message}")
            return {"success": False, "result": result}
            
    except Exception as e:
        print(f"     âŒ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def test_analysis_with_loaded_data(
    query: str, 
    ctx, 
    analysis_query: str
) -> Dict[str, Any]:
    """ë¡œë“œëœ ë°ì´í„°ë¡œ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    print_subheader(f"ë¶„ì„ í…ŒìŠ¤íŠ¸ (CodeGen)")
    print(f"     Query: \"{analysis_query}\"")
    
    try:
        from OrchestrationAgent.src import Orchestrator
        
        # DataContextì—ì„œ runtime_data ì¤€ë¹„
        case_ids = ctx.get_case_ids()
        
        if not case_ids:
            print("     âŒ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {"success": False, "error": "No cases"}
        
        # ì²« ë²ˆì§¸ ì¼€ì´ìŠ¤ì˜ ì‹œê·¸ë„ ë¡œë“œ
        first_case = case_ids[0]
        signals = ctx.get_signals(first_case)
        cohort = ctx.get_cohort()
        
        if signals is None or signals.empty:
            print(f"     âš ï¸ Case {first_case}ì˜ ì‹œê·¸ë„ì´ ì—†ìŠµë‹ˆë‹¤")
            return {"success": False, "error": "No signals"}
        
        print(f"        - ì‚¬ìš© ì¼€ì´ìŠ¤: {first_case}")
        print(f"        - ì‹œê·¸ë„ shape: {signals.shape}")
        
        runtime_data = {
            'df': signals,
            'cohort': cohort,
            'case_ids': case_ids,
            'param_keys': ctx.get_available_parameters()
        }
        
        orch = Orchestrator()
        
        start_time = time.time()
        result = orch.run_analysis_only(
            query=analysis_query,
            runtime_data=runtime_data,
            max_retries=2
        )
        elapsed = (time.time() - start_time) * 1000
        
        print(f"\n     ğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"        - Status: {result.status}")
        print(f"        - Time: {elapsed:.0f}ms")
        
        if result.status == "success":
            print(f"        - Result: {result.result}")
            return {"success": True, "result": result}
        else:
            print(f"        - Error: {result.error_message}")
            return {"success": False, "result": result}
            
    except Exception as e:
        print(f"     âŒ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def run_interactive_test():
    """ì¸í„°ë™í‹°ë¸Œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ"""
    print_header("ì¸í„°ë™í‹°ë¸Œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    
    from OrchestrationAgent.src import Orchestrator
    
    orch = Orchestrator()
    
    print("\n  ëª…ë ¹ì–´:")
    print("    - ìì—°ì–´ ì§ˆì˜ ì…ë ¥ â†’ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
    print("    - 'q' ë˜ëŠ” 'quit' â†’ ì¢…ë£Œ")
    print("    - 'help' â†’ ë„ì›€ë§")
    
    while True:
        print("\n" + "-" * 50)
        query = input("  Query> ").strip()
        
        if not query:
            continue
        
        if query.lower() in ['q', 'quit', 'exit']:
            print("  ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if query.lower() == 'help':
            print("\n  ì˜ˆì‹œ ì§ˆì˜:")
            print("    - ìœ„ì•” í™˜ìì˜ ì‹¬ë°•ìˆ˜ í‰ê· ì„ êµ¬í•´ì¤˜")
            print("    - ìˆ˜ìˆ  ì¤‘ í˜ˆì••ì´ 90 ì´í•˜ì¸ êµ¬ê°„ì˜ ë¹„ìœ¨")
            print("    - HRê³¼ SpO2ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•´ì¤˜")
            continue
        
        result = orch.run(query)
        
        print(f"\n  ğŸ“Š ê²°ê³¼:")
        print(f"     Status: {result.status}")
        
        if result.status == "success":
            print(f"     Result: {result.result}")
            if result.generated_code:
                print(f"\n  ğŸ“ ì½”ë“œ:")
                for line in result.generated_code.split('\n'):
                    print(f"     {line}")
        else:
            print(f"     Error: {result.error_message}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print_header("OrchestrationAgent ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    
    # 1. í•„ìˆ˜ ì¡°ê±´ í™•ì¸
    if not check_prerequisites():
        print("\n  âŒ í•„ìˆ˜ ì¡°ê±´ì´ ì¶©ì¡±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False
    
    results = {}
    
    # 2. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜
    test_queries = [
        # (extraction_query, analysis_query)
        ("ìœ„ì•” í™˜ìì˜ ìˆ˜ìˆ  ì¤‘ ì‹¬ë°•ìˆ˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì¤˜", "ì‹¬ë°•ìˆ˜ì˜ í‰ê· ì„ êµ¬í•´ì¤˜"),
        ("ì „ì²´ í™˜ìì˜ í˜ˆì•• ë°ì´í„°", "í˜ˆì••ì´ 90 ì´í•˜ì¸ ë¹„ìœ¨"),
    ]
    
    # 3. ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸
    for i, (extract_query, analyze_query) in enumerate(test_queries, 1):
        print_header(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #{i}")
        print(f"  Extraction: \"{extract_query}\"")
        print(f"  Analysis: \"{analyze_query}\"")
        
        # Step 1: Extraction
        extract_result = test_extraction_only(extract_query)
        results[f"case{i}_extraction"] = extract_result["success"]
        
        if not extract_result["success"]:
            print(f"\n  âš ï¸ Extraction ì‹¤íŒ¨, ë‹¤ìŒ ì¼€ì´ìŠ¤ë¡œ...")
            continue
        
        # Step 2: Data Load
        load_result = test_data_load(extract_result["plan"])
        results[f"case{i}_data_load"] = load_result["success"]
        
        if not load_result["success"]:
            print(f"\n  âš ï¸ Data Load ì‹¤íŒ¨, ë‹¤ìŒ ì¼€ì´ìŠ¤ë¡œ...")
            continue
        
        # Step 3: Analysis
        analysis_result = test_analysis_with_loaded_data(
            extract_query,
            load_result["context"],
            analyze_query
        )
        results[f"case{i}_analysis"] = analysis_result["success"]
    
    # 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (í•œ ë²ˆì—)
    print_header("ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸")
    full_result = test_full_orchestration(
        "ìœ„ì•” í™˜ìì˜ ìˆ˜ìˆ  ì¤‘ ì‹¬ë°•ìˆ˜ í‰ê· ì„ ê³„ì‚°í•´ì¤˜"
    )
    results["full_pipeline"] = full_result["success"]
    
    # 5. ê²°ê³¼ ìš”ì•½
    print_header("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for name, success in results.items():
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"  {status} - {name}")
    
    print(f"\n  ì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    # 6. ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ ì œì•ˆ
    print("\n" + "-" * 70)
    try:
        response = input("  ì¸í„°ë™í‹°ë¸Œ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        
        if response == 'y':
            run_interactive_test()
    except EOFError:
        # ë¹„ëŒ€í™”í˜• ëª¨ë“œì—ì„œëŠ” ìŠ¤í‚µ
        print("  (ë¹„ëŒ€í™”í˜• ëª¨ë“œ - ì¸í„°ë™í‹°ë¸Œ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ)")
        pass
    
    print_header("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

