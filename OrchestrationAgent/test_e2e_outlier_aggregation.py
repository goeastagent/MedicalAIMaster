#!/usr/bin/env python
"""
End-to-End Test: Outlier Removal + Time-based Aggregation
==========================================================

ÌÖåÏä§Ìä∏ Î™©Ìëú:
  - HRÏóêÏÑú IQR Î∞©ÏãùÏúºÎ°ú outlier Ï†úÍ±∞
  - 5Î∂Ñ(300Ï¥à) Îã®ÏúÑÎ°ú ÏãúÍ∞Ñ Í∏∞Î∞ò ÌèâÍ∑† Í≥ÑÏÇ∞
  - Ï†ÑÏ≤¥ ÏºÄÏù¥Ïä§Ïùò ÌèâÍ∑† Î∞òÌôò

ÌÖåÏä§Ìä∏ÌïòÎäî Í∏∞Îä•:
  - IQR Í∏∞Î∞ò Ïù¥ÏÉÅÏπò Ï†úÍ±∞ (Q1 - 1.5*IQR, Q3 + 1.5*IQR)
  - ÏãúÍ∞Ñ Í∏∞Î∞ò Î¶¨ÏÉòÌîåÎßÅ/ÏßëÍ≥Ñ
  - ÌÜµÍ≥ÑÏ†Å Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨

ÏÇ¨Ïö©Î≤ï:
    python test_e2e_outlier_aggregation.py
    python test_e2e_outlier_aggregation.py --verbose
"""

import sys
import os
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
import time
import numpy as np
import pandas as pd

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ Ï∂îÍ∞Ä
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


def setup_logging(verbose: bool = False):
    """Î°úÍπÖ ÏÑ§Ï†ï"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s | %(levelname)-8s | %(message)s",
        datefmt="%H:%M:%S"
    )
    for logger_name in ["httpx", "httpcore", "openai", "urllib3"]:
        logging.getLogger(logger_name).setLevel(logging.WARNING)


# =============================================================================
# ÌÖåÏä§Ìä∏ ÏÑ§Ï†ï
# =============================================================================

# ÌÖåÏä§Ìä∏ ÏºÄÏù¥Ïä§ (ÏÉòÌîå ÌååÏùº Í∏∞Ï§Ä: 0001~0020.vital)
TEST_CASE_IDS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

# Signal Ïª¨Îüº
HR_COLUMN = "Solar8000/HR"

# ÏßëÍ≥Ñ Îã®ÏúÑ (Ï¥à)
AGGREGATION_WINDOW = 300  # 5Î∂Ñ


# =============================================================================
# Ground Truth Í≥ÑÏÇ∞
# =============================================================================

def remove_outliers_iqr(values: np.ndarray) -> np.ndarray:
    """IQR Î∞©ÏãùÏúºÎ°ú outlier Ï†úÍ±∞"""
    if len(values) == 0:
        return values
    
    q1 = np.percentile(values, 25)
    q3 = np.percentile(values, 75)
    iqr = q3 - q1
    
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    
    mask = (values >= lower_bound) & (values <= upper_bound)
    return values[mask]


def calculate_ground_truth(case_ids: List[int]) -> Dict[str, Any]:
    """
    Ground Truth Í≥ÑÏÇ∞: IQR outlier Ï†úÍ±∞ ÌõÑ 5Î∂Ñ Îã®ÏúÑ ÌèâÍ∑†
    
    Returns:
        {
            "case_means": {caseid: mean_value, ...},
            "overall_mean": float,
            "valid_cases": int,
            "total_outliers_removed": int
        }
    """
    import vitaldb
    
    data_dir = Path(__file__).parent.parent / "IndexingAgent" / "data" / "test" / "vitaldb_sample" / "vital_files"
    case_means = {}
    total_outliers_removed = 0
    
    for case_id in case_ids:
        vital_path = data_dir / f"{case_id:04d}.vital"
        if not vital_path.exists():
            continue
        
        try:
            vf = vitaldb.read_vital(str(vital_path), [HR_COLUMN])
            vals = vf.to_numpy([HR_COLUMN], 1)  # 1Ï¥à Í∞ÑÍ≤©
            
            if vals is not None and hasattr(vals, 'ndim') and vals.ndim == 2:
                vals = vals.flatten()
            
            if vals is None or len(vals) == 0:
                continue
            
            # Time Ïù∏Îç±Ïä§ ÏÉùÏÑ± (0, 1, 2, ... Ï¥à)
            time_idx = np.arange(len(vals))
            
            # NaN Ï†úÍ±∞
            mask = ~np.isnan(vals)
            vals = vals[mask]
            time_idx = time_idx[mask]
            
            if len(vals) == 0:
                continue
            
            original_count = len(vals)
            
            # IQR outlier Ï†úÍ±∞
            q1 = np.percentile(vals, 25)
            q3 = np.percentile(vals, 75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            
            outlier_mask = (vals >= lower_bound) & (vals <= upper_bound)
            vals_clean = vals[outlier_mask]
            time_clean = time_idx[outlier_mask]
            
            outliers_removed = original_count - len(vals_clean)
            total_outliers_removed += outliers_removed
            
            if len(vals_clean) == 0:
                continue
            
            # 5Î∂Ñ Îã®ÏúÑ ÏßëÍ≥Ñ (Time Í∞í Í∏∞Ï§Ä)
            segment_means = []
            segment_indices = time_clean // AGGREGATION_WINDOW
            
            for seg_idx in np.unique(segment_indices):
                seg_mask = segment_indices == seg_idx
                seg_vals = vals_clean[seg_mask]
                if len(seg_vals) > 0:
                    segment_means.append(np.mean(seg_vals))
            
            if segment_means:
                case_mean = np.mean(segment_means)
                case_means[str(case_id)] = case_mean
                
        except Exception as e:
            logging.warning(f"Error processing case {case_id}: {e}")
            continue
    
    valid_cases = len(case_means)
    overall_mean = np.mean(list(case_means.values())) if case_means else 0.0
    
    return {
        "case_means": case_means,
        "overall_mean": overall_mean,
        "valid_cases": valid_cases,
        "total_outliers_removed": total_outliers_removed
    }


# =============================================================================
# ÌÖåÏä§Ìä∏ Ïã§Ìñâ
# =============================================================================

def run_test(verbose: bool = False) -> bool:
    """ÌÖåÏä§Ìä∏ Ïã§Ìñâ"""
    from OrchestrationAgent.src.orchestrator import Orchestrator
    from shared.llm import enable_llm_logging
    
    # LLM Î°úÍπÖ ÌôúÏÑ±Ìôî
    log_session_dir = enable_llm_logging("./data/llm_logs")
    logging.info(f"üìù LLM Logs: {log_session_dir}")
    
    # Ground Truth Í≥ÑÏÇ∞
    logging.info("üìä Calculating Ground Truth...")
    ground_truth = calculate_ground_truth(TEST_CASE_IDS)
    logging.info(f"   Valid cases: {ground_truth['valid_cases']}")
    logging.info(f"   Total outliers removed: {ground_truth['total_outliers_removed']}")
    logging.info(f"   Overall mean HR: {ground_truth['overall_mean']:.4f}")
    
    # ÌÖåÏä§Ìä∏ ÏøºÎ¶¨
    case_ids_str = str(TEST_CASE_IDS)
    query = f"""caseidÍ∞Ä {case_ids_str} Ï§ë ÌïòÎÇòÏù∏ ÏºÄÏù¥Ïä§Îì§Ïóê ÎåÄÌï¥ÏÑú:
Í∞Å ÏºÄÏù¥Ïä§Ïùò HR(Solar8000/HR) Í∞íÏóêÏÑú IQR Î∞©ÏãùÏúºÎ°ú outlierÎ•º Ï†úÍ±∞Ìï¥Ï§ò.
(Q1 - 1.5*IQR ÎØ∏Îßå, Q3 + 1.5*IQR Ï¥àÍ≥ºÏù∏ Í∞í Ï†úÍ±∞)
Í∑∏ Îã§Ïùå Time Í∞íÏùÑ Í∏∞Ï§ÄÏúºÎ°ú 5Î∂Ñ(300Ï¥à) Îã®ÏúÑÎ°ú ÌèâÍ∑†ÏùÑ Íµ¨ÌïòÍ≥†,
Î™®Îì† segment ÌèâÍ∑†Îì§Ïùò ÌèâÍ∑†ÏùÑ ÏºÄÏù¥Ïä§Î≥ÑÎ°ú Íµ¨Ìïú ÌõÑ,
Ï†ÑÏ≤¥ ÏºÄÏù¥Ïä§Ïùò ÌèâÍ∑†ÏùÑ Íµ¨Ìï¥Ï§ò.
Í≤∞Í≥ºÎäî Îã®Ïùº float Í∞íÏúºÎ°ú Î∞òÌôòÌï¥Ï§ò."""

    logging.info(f"üîç Query: {query[:100]}...")
    
    # Orchestrator Ïã§Ìñâ
    orchestrator = Orchestrator()
    start_time = time.time()
    
    try:
        result = orchestrator.run(query)
        elapsed = time.time() - start_time
        
        if result.status == "success":
            analysis_result = result.result
            logging.info(f"‚úÖ Execution SUCCESS ({elapsed:.2f}s)")
            logging.info(f"   Result: {analysis_result}")
            
            # Í≤ÄÏ¶ù
            if isinstance(analysis_result, (int, float)):
                expected = ground_truth["overall_mean"]
                diff_pct = abs(analysis_result - expected) / expected * 100 if expected > 0 else 0
                
                logging.info(f"\nüìä Ground Truth Validation:")
                logging.info(f"   Result: {analysis_result:.4f}")
                logging.info(f"   Expected: {expected:.4f}")
                logging.info(f"   Diff: {diff_pct:.2f}%")
                
                # 10% Ïù¥ÎÇ¥Î©¥ ÌÜµÍ≥º (outlier Ï†úÍ±∞ Î∞©ÏãùÏóê Îî∞Î•∏ Ï∞®Ïù¥ ÌóàÏö©)
                if diff_pct <= 10.0:
                    logging.info("   ‚úÖ VALIDATION PASSED")
                    return True
                else:
                    logging.error("   ‚ùå VALIDATION FAILED (diff > 10%)")
                    return False
            else:
                logging.warning(f"   ‚ö†Ô∏è Unexpected result type: {type(analysis_result)}")
                return False
        else:
            logging.error(f"‚ùå Execution FAILED: {result.error_message}")
            return False
            
    except Exception as e:
        logging.error(f"‚ùå Exception: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    import argparse
    parser = argparse.ArgumentParser(description="E2E Test: Outlier Removal + Aggregation")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose logging")
    args = parser.parse_args()
    
    setup_logging(args.verbose)
    
    logging.info("=" * 60)
    logging.info("E2E Test: IQR Outlier Removal + 5min Aggregation")
    logging.info("=" * 60)
    
    success = run_test(args.verbose)
    
    logging.info("=" * 60)
    if success:
        logging.info("‚úÖ TEST PASSED")
    else:
        logging.info("‚ùå TEST FAILED")
    logging.info("=" * 60)
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
