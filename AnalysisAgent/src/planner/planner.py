# AnalysisAgent/src/planner/planner.py
"""
Analysis Planner

Creates analysis execution plans using LLM.

Usage:
    from AnalysisAgent.src.planner import AnalysisPlanner
    from AnalysisAgent.src.context import ContextBuilder, AnalysisContext
    from shared.llm import get_llm_client
    
    # Build context
    builder = ContextBuilder()
    context = builder.build_from_dataframes({"df": signal_df})
    
    # Create planner
    llm = get_llm_client()
    planner = AnalysisPlanner(llm_client=llm)
    
    # Create plan
    result = planner.plan("Calculate mean of HR", context)
    
    if result.success:
        print(result.plan.describe())
"""

import logging
import json
import re
import time
from typing import Dict, List, Any, Optional, TYPE_CHECKING

from ..models.plan import PlanStep, AnalysisPlan, PlanningResult
from .prompts import build_planning_prompt
from ..context.schema import AnalysisContext

if TYPE_CHECKING:
    from shared.llm.client import LLMClient

logger = logging.getLogger(__name__)


class AnalysisPlanner:
    """LLM ê¸°ë°˜ ë¶„ì„ ê³„íš ìˆ˜ë¦½ê¸°"""
    
    def __init__(
        self,
        llm_client: Optional["LLMClient"] = None,
        max_tokens: int = 2000,
        temperature: float = 0.0,
        max_retries: int = 2,
    ):
        """
        Args:
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸ (Noneì´ë©´ lazy init)
            max_tokens: ìµœëŒ€ ì‘ë‹µ í† í° ìˆ˜
            temperature: LLM ì˜¨ë„ (0.0 = deterministic)
            max_retries: íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜
        """
        self._llm_client = llm_client
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.max_retries = max_retries
    
    def _get_llm_client(self) -> "LLMClient":
        """Lazy LLM client initialization"""
        if self._llm_client is None:
            from shared.llm import get_llm_client
            self._llm_client = get_llm_client()
        return self._llm_client
    
    def plan(
        self,
        query: str,
        context: AnalysisContext,
        additional_context: Optional[str] = None,
    ) -> PlanningResult:
        """
        ë¶„ì„ ê³„íš ìˆ˜ë¦½
        
        Args:
            query: ì‚¬ìš©ìž ë¶„ì„ ì¿¼ë¦¬ (ì˜ˆ: "HRì˜ í‰ê· ì„ êµ¬í•´ì¤˜")
            context: AnalysisContext (ë°ì´í„° ìŠ¤í‚¤ë§ˆ, Tool ëª©ë¡ ë“±)
            additional_context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ)
        
        Returns:
            PlanningResult (success=Trueì´ë©´ plan í¬í•¨)
        """
        logger.info(f"ðŸ“ Planning analysis for: '{query}'")
        start_time = time.time()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt, user_prompt = build_planning_prompt(
            query=query,
            context=context,
            additional_context=additional_context,
        )
        
        logger.debug(f"   System prompt: {len(system_prompt)} chars")
        logger.debug(f"   User prompt: {len(user_prompt)} chars")
        
        # LLM í˜¸ì¶œ ë° íŒŒì‹± (ìž¬ì‹œë„ í¬í•¨)
        last_error = None
        raw_response = None
        
        for attempt in range(self.max_retries + 1):
            try:
                # LLM í˜¸ì¶œ
                llm = self._get_llm_client()
                
                full_prompt = f"{system_prompt}\n\n{user_prompt}"
                raw_response = llm.ask_text(full_prompt, max_tokens=self.max_tokens)
                
                logger.debug(f"   LLM response ({attempt + 1}): {len(raw_response)} chars")
                
                # JSON íŒŒì‹±
                plan_dict = self._parse_response(raw_response)
                
                # AnalysisPlan ê°ì²´ ìƒì„±
                plan = self._build_plan(query, plan_dict)
                
                # ê³„íš ê²€ì¦
                validation_errors = plan.validate()
                if validation_errors:
                    raise ValueError(f"Plan validation failed: {validation_errors}")
                
                # ì„±ê³µ
                planning_time = (time.time() - start_time) * 1000
                plan.planning_time_ms = planning_time
                
                logger.info(f"âœ… Plan created: {plan.step_count} steps, "
                           f"complexity={plan.estimated_complexity}, "
                           f"confidence={plan.confidence:.0%}")
                
                return PlanningResult.from_plan(plan)
            
            except json.JSONDecodeError as e:
                last_error = f"JSON parsing error: {e}"
                logger.warning(f"   Attempt {attempt + 1} failed: {last_error}")
            
            except KeyError as e:
                last_error = f"Missing required field: {e}"
                logger.warning(f"   Attempt {attempt + 1} failed: {last_error}")
            
            except ValueError as e:
                last_error = str(e)
                logger.warning(f"   Attempt {attempt + 1} failed: {last_error}")
            
            except Exception as e:
                last_error = f"Unexpected error: {e}"
                logger.error(f"   Attempt {attempt + 1} failed: {last_error}")
        
        # ëª¨ë“  ìž¬ì‹œë„ ì‹¤íŒ¨
        logger.error(f"âŒ Planning failed after {self.max_retries + 1} attempts: {last_error}")
        return PlanningResult.from_error(last_error, raw_response)
    
    def _parse_response(self, response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹±"""
        # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # ì½”ë“œ ë¸”ë¡ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ JSONìœ¼ë¡œ ì‹œë„
            json_str = response.strip()
            
            # í˜¹ì‹œ ë‹¤ë¥¸ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì´ ìžˆë‹¤ë©´
            json_match = re.search(r'```\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
        
        # ì•žë’¤ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        # JSON ê°ì²´ ì‹œìž‘/ë ì°¾ê¸°
        start_idx = json_str.find('{')
        end_idx = json_str.rfind('}')
        
        if start_idx == -1 or end_idx == -1:
            raise json.JSONDecodeError("No JSON object found", json_str, 0)
        
        json_str = json_str[start_idx:end_idx + 1]
        
        return json.loads(json_str)
    
    def _build_plan(self, query: str, plan_dict: Dict[str, Any]) -> AnalysisPlan:
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ AnalysisPlan ê°ì²´ ìƒì„±"""
        
        # PlanStep ê°ì²´ë“¤ ìƒì„±
        steps = []
        for i, step_dict in enumerate(plan_dict.get("steps", [])):
            step = PlanStep(
                id=step_dict.get("id", f"step_{i + 1}"),
                order=step_dict.get("order", i),
                action=step_dict.get("action", "unknown"),
                description=step_dict.get("description", ""),
                execution_mode=step_dict.get("execution_mode", "code"),
                tool_name=step_dict.get("tool_name"),
                inputs=step_dict.get("inputs", []),
                input_columns=step_dict.get("input_columns", []),
                parameters=step_dict.get("parameters", {}),
                output_key=step_dict.get("output_key", f"step_{i + 1}_result"),
                expected_output_type=step_dict.get("expected_output_type", "any"),
                code_hint=step_dict.get("code_hint"),
                depends_on=step_dict.get("depends_on", []),
            )
            steps.append(step)
        
        # execution_mode ê²°ì •
        has_tool = any(s.execution_mode == "tool" for s in steps)
        has_code = any(s.execution_mode == "code" for s in steps)
        
        if has_tool and has_code:
            execution_mode = "hybrid"
        elif has_tool:
            execution_mode = "tool_only"
        else:
            execution_mode = "code_only"
        
        # AnalysisPlan ìƒì„±
        plan = AnalysisPlan(
            query=query,
            analysis_type=plan_dict.get("analysis_type", "general"),
            steps=steps,
            expected_output=plan_dict.get("expected_output", {}),
            execution_mode=execution_mode,
            estimated_complexity=plan_dict.get("estimated_complexity", "simple"),
            confidence=plan_dict.get("confidence", 0.8),
            reasoning=plan_dict.get("reasoning"),
            warnings=plan_dict.get("warnings", []),
        )
        
        return plan
    
    def plan_simple(
        self,
        query: str,
        context: AnalysisContext,
    ) -> PlanningResult:
        """
        Fast planning for simple queries (minimizes LLM calls)
        
        For simple statistical queries, creates plan using rule-based approach.
        Falls back to plan() for complex queries.
        
        Args:
            query: User query
            context: AnalysisContext
        
        Returns:
            PlanningResult
        """
        # Detect simple query patterns
        simple_patterns = self._detect_simple_patterns(query, context)
        
        if simple_patterns:
            logger.info(f"ðŸ“ Using rule-based planning for simple query")
            return self._create_simple_plan(query, simple_patterns, context)
        
        # Complex queries use LLM-based planning
        return self.plan(query, context)
    
    def _detect_simple_patterns(
        self,
        query: str,
        context: AnalysisContext,
    ) -> Optional[Dict[str, Any]]:
        """Detect simple query patterns"""
        query_lower = query.lower()
        
        # ì»¬ëŸ¼ ì´ë¦„ ì¶”ì¶œ
        all_columns = []
        for schema in context.data_schemas.values():
            all_columns.extend(schema.column_names)
        
        mentioned_columns = [
            col for col in all_columns
            if col.lower() in query_lower or col in query
        ]
        
        # í‰ê·  ì¿¼ë¦¬
        if any(kw in query_lower for kw in ["í‰ê· ", "mean", "average"]):
            if mentioned_columns:
                return {
                    "type": "mean",
                    "columns": mentioned_columns,
                }
        
        # ìƒê´€ê´€ê³„ ì¿¼ë¦¬
        if any(kw in query_lower for kw in ["ìƒê´€", "correlation", "corr"]):
            if len(mentioned_columns) >= 2:
                return {
                    "type": "correlation",
                    "columns": mentioned_columns[:2],
                }
        
        # í‘œì¤€íŽ¸ì°¨ ì¿¼ë¦¬
        if any(kw in query_lower for kw in ["í‘œì¤€íŽ¸ì°¨", "std", "standard deviation"]):
            if mentioned_columns:
                return {
                    "type": "std",
                    "columns": mentioned_columns,
                }
        
        return None
    
    def _create_simple_plan(
        self,
        query: str,
        patterns: Dict[str, Any],
        context: AnalysisContext,
    ) -> PlanningResult:
        """Create simple plan using rule-based approach"""
        pattern_type = patterns["type"]
        columns = patterns["columns"]
        
        # DataFrame variable name (default: df)
        df_var = "df"
        for name, schema in context.data_schemas.items():
            if any(col in schema.column_names for col in columns):
                df_var = name
                break
        
        if pattern_type == "mean":
            col = columns[0]
            step = PlanStep(
                id="step_1",
                order=0,
                action="compute_mean",
                description=f"Calculate mean of {col}",
                execution_mode="code",
                inputs=[df_var],
                input_columns=[col],
                output_key="mean_result",
                expected_output_type="numeric",
                code_hint=f"result = {df_var}['{col}'].mean()",
            )
            expected_output = {
                "type": "numeric",
                "description": f"Mean value of {col}",
            }
        
        elif pattern_type == "std":
            col = columns[0]
            step = PlanStep(
                id="step_1",
                order=0,
                action="compute_std",
                description=f"Calculate standard deviation of {col}",
                execution_mode="code",
                inputs=[df_var],
                input_columns=[col],
                output_key="std_result",
                expected_output_type="numeric",
                code_hint=f"result = {df_var}['{col}'].std()",
            )
            expected_output = {
                "type": "numeric",
                "description": f"Standard deviation of {col}",
            }
        
        elif pattern_type == "correlation":
            col1, col2 = columns[:2]
            step = PlanStep(
                id="step_1",
                order=0,
                action="compute_correlation",
                description=f"Calculate correlation between {col1} and {col2}",
                execution_mode="code",
                inputs=[df_var],
                input_columns=[col1, col2],
                output_key="correlation_result",
                expected_output_type="dict",
                code_hint=f"from scipy import stats; r = stats.pearsonr({df_var}['{col1}'].dropna(), {df_var}['{col2}'].dropna()); result = {{'correlation': r.statistic, 'pvalue': r.pvalue}}",
            )
            expected_output = {
                "type": "dict",
                "schema": {"correlation": "float", "pvalue": "float"},
                "description": "Correlation coefficient and p-value",
            }
        
        else:
            # fallback: LLM-based planning
            return self.plan(query, context)
        
        plan = AnalysisPlan(
            query=query,
            analysis_type=pattern_type,
            steps=[step],
            expected_output=expected_output,
            execution_mode="code_only",
            estimated_complexity="simple",
            confidence=0.95,
            reasoning=f"Rule-based simple plan ({pattern_type})",
        )
        
        logger.info(f"âœ… Simple plan created: {plan.step_count} step, type={pattern_type}")
        
        return PlanningResult.from_plan(plan)
