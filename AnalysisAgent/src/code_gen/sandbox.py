"""ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰ê¸° - ì•ˆì „í•œ ì½”ë“œ ì‹¤í–‰ë§Œ ë‹´ë‹¹

ì±…ì„: ì½”ë“œ ì‹¤í–‰ë§Œ ë‹´ë‹¹. ìƒì„±/ê²€ì¦ì€ í•˜ì§€ ì•ŠìŒ.
Agentê°€ ê²€ì¦ëœ ì½”ë“œì™€ runtime_dataë¥¼ ì „ë‹¬í•˜ë©´ ì‹¤í–‰ í›„ ê²°ê³¼ ë°˜í™˜.

ì§€ì› ëª¨ë“œ:
- ê¸°ë³¸ ëª¨ë“œ: ë‹¨ì¼ ì½”ë“œ ë¸”ë¡ ì‹¤í–‰
- Map-Reduce ëª¨ë“œ: map_func / reduce_func í•¨ìˆ˜ ì‹¤í–‰
"""

import sys
import time
import traceback
import threading
import logging
from io import StringIO
from typing import Dict, Any, Optional, Tuple, List, TYPE_CHECKING
from contextlib import contextmanager

from ..models import ExecutionResult
from ..config import DEFAULT_CONFIG

if TYPE_CHECKING:
    from ..config import SandboxConfig
    import pandas as pd

logger = logging.getLogger("AnalysisAgent.code_gen.sandbox")

# RestrictedPython ì‚¬ìš© ì—¬ë¶€
try:
    from RestrictedPython import compile_restricted
    from RestrictedPython.Guards import (
        safe_builtins,
        guarded_iter_unpack_sequence,
        safer_getattr,
    )
    from RestrictedPython.Eval import default_guarded_getiter, default_guarded_getitem
    from RestrictedPython.PrintCollector import PrintCollector
    HAS_RESTRICTED_PYTHON = True
except ImportError:
    HAS_RESTRICTED_PYTHON = False


def _flexible_iter_unpack_sequence(it, spec, _getiter_):
    """ë²”ìš© tuple unpacking guard - ë‹¤ì–‘í•œ íƒ€ì… ì§€ì›
    
    RestrictedPythonì˜ guarded_iter_unpack_sequenceëŠ” ì¼ë¶€ ê°ì²´ì—ì„œ ì‹¤íŒ¨í•¨:
    - scipy.stats ê²°ê³¼ ê°ì²´ (PearsonRResult, SpearmanrResult ë“±)
    - numpy íŠ¹ìˆ˜ ë°˜í™˜ íƒ€ì…
    - NamedTuple ìœ ì‚¬ ê°ì²´
    
    ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒ ìˆœì„œë¡œ unpacking ì‹œë„:
    1. tuple/listë¡œ ì§ì ‘ ë³€í™˜
    2. __iter__ ë©”ì„œë“œ ì‚¬ìš©
    3. ì¸ë±ì‹± ì‚¬ìš© (Result ê°ì²´ ë“±)
    4. ê¸°ì¡´ guarded_iter_unpack_sequence fallback
    
    Args:
        it: unpackingí•  ê°ì²´
        spec: ì˜ˆìƒ ìš”ì†Œ ìˆ˜ (int ë˜ëŠ” tuple)
        _getiter_: iterator guard í•¨ìˆ˜
    
    Returns:
        unpackingëœ ê°’ë“¤ì˜ tuple
    """
    # specì´ intë©´ ë‹¨ìˆœ ê°œìˆ˜, tupleì´ë©´ (min, max) ë˜ëŠ” ë³µì¡í•œ ìŠ¤í™
    if isinstance(spec, int):
        expected_len = spec
    elif isinstance(spec, tuple) and len(spec) >= 1:
        expected_len = spec[0] if isinstance(spec[0], int) else len(spec)
    else:
        expected_len = None
    
    # ë°©ë²• 1: ì´ë¯¸ tuple/listì¸ ê²½ìš° ì§ì ‘ ì‚¬ìš©
    if isinstance(it, (tuple, list)):
        result = tuple(it)
        if expected_len is not None and len(result) != expected_len:
            raise ValueError(f"not enough values to unpack (expected {expected_len}, got {len(result)})")
        return result
    
    # ë°©ë²• 2: scipy.stats Result ê°ì²´ ë“± íŠ¹ìˆ˜ íƒ€ì… ì²˜ë¦¬
    # ì´ë“¤ì€ __iter__ê°€ ìˆì§€ë§Œ RestrictedPython guardì™€ ì¶©ëŒ
    obj_type = type(it).__name__
    if 'Result' in obj_type or hasattr(it, '_fields') or hasattr(it, 'statistic'):
        try:
            # ì¸ë±ì‹±ìœ¼ë¡œ ì ‘ê·¼ ì‹œë„
            if expected_len is not None:
                result = tuple(it[i] for i in range(expected_len))
                return result
            # ê¸¸ì´ë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë©´ listë¡œ ë³€í™˜ ì‹œë„
            result = tuple(list(it))
            return result
        except (TypeError, IndexError):
            pass
    
    # ë°©ë²• 3: numpy array ë˜ëŠ” ndarray ì²˜ë¦¬
    try:
        import numpy as np
        if isinstance(it, np.ndarray):
            result = tuple(it.tolist() if it.ndim > 0 else [it.item()])
            if expected_len is not None and len(result) != expected_len:
                raise ValueError(f"not enough values to unpack (expected {expected_len}, got {len(result)})")
            return result
    except ImportError:
        pass
    
    # ë°©ë²• 4: __iter__ë¥¼ í†µí•œ ì¼ë°˜ì ì¸ iterable ì²˜ë¦¬
    try:
        # ì§ì ‘ tuple ë³€í™˜ ì‹œë„ (guard ìš°íšŒ)
        result = tuple(it)
        if expected_len is not None and len(result) != expected_len:
            raise ValueError(f"not enough values to unpack (expected {expected_len}, got {len(result)})")
        return result
    except TypeError:
        pass
    
    # ë°©ë²• 5: ê¸°ì¡´ guarded_iter_unpack_sequence fallback
    if HAS_RESTRICTED_PYTHON:
        return guarded_iter_unpack_sequence(it, spec, _getiter_)
    
    raise TypeError(f"cannot unpack non-iterable {type(it).__name__} object")


class ExecutionTimeoutError(Exception):
    """ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ ì—ëŸ¬"""
    pass


class SandboxExecutor:
    """ì•ˆì „í•œ ì½”ë“œ ì‹¤í–‰ í™˜ê²½
    
    ì±…ì„:
    - ì½”ë“œ ì‹¤í–‰ë§Œ ë‹´ë‹¹
    - íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
    - ì•ˆì „í•œ ì‹¤í–‰ í™˜ê²½ êµ¬ì„±
    
    ì‚¬ìš©í•˜ì§€ ì•ŠìŒ:
    - ì½”ë“œ ìƒì„± (Generator ë‹´ë‹¹)
    - ì½”ë“œ ê²€ì¦ (Validator ë‹´ë‹¹)
    
    Example:
        executor = SandboxExecutor(timeout_seconds=30)
        
        runtime_data = {
            "df": signal_dataframe,
            "cohort": cohort_dataframe,
            "case_ids": ["1", "2", "3"],
        }
        
        result = executor.execute(
            code="result = df['HR'].mean()",
            runtime_data=runtime_data
        )
        
        if result.success:
            print(f"Result: {result.result}")
        else:
            print(f"Error: {result.error}")
    """
    
    def __init__(
        self,
        timeout_seconds: int = None,
        max_output_size: int = None,
        capture_stdout: bool = None,
        config: Optional["SandboxConfig"] = None,
    ):
        """
        Args:
            timeout_seconds: ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
            max_output_size: ê²°ê³¼ í¬ê¸° ì œí•œ (bytes)
            capture_stdout: print ì¶œë ¥ ìº¡ì²˜ ì—¬ë¶€
            config: SandboxConfig (ê°œë³„ íŒŒë¼ë¯¸í„°ë³´ë‹¤ ìš°ì„ )
        """
        _config = config or DEFAULT_CONFIG.sandbox
        
        self.timeout_seconds = timeout_seconds if timeout_seconds is not None else _config.timeout_seconds
        self.max_output_size = max_output_size if max_output_size is not None else _config.max_result_size
        self.capture_stdout = capture_stdout if capture_stdout is not None else _config.capture_stdout
    
    def execute(
        self,
        code: str,
        runtime_data: Dict[str, Any],
    ) -> ExecutionResult:
        """ì½”ë“œ ì‹¤í–‰
        
        Args:
            code: ì‹¤í–‰í•  Python ì½”ë“œ (ì´ë¯¸ ê²€ì¦ëœ ì½”ë“œì—¬ì•¼ í•¨)
            runtime_data: ì‹¤í–‰ ì‹œ ì‚¬ìš©í•  ë³€ìˆ˜ë“¤
                {
                    "df": pandas.DataFrame (Signal ë°ì´í„°),
                    "cohort": pandas.DataFrame (Cohort ë°ì´í„°),
                    "case_ids": List[str],
                    "param_keys": List[str],
                    ...
                }
        
        Returns:
            ExecutionResult: ì‹¤í–‰ ê²°ê³¼
        """
        start_time = time.time()
        stdout_capture = StringIO() if self.capture_stdout else None
        
        logger.info("âš™ï¸ Executing generated code in sandbox...")
        logger.debug(f"   Code preview: {code[:100]}{'...' if len(code) > 100 else ''}")
        
        try:
            # ì‹¤í–‰ í™˜ê²½ êµ¬ì„±
            exec_globals = self._create_exec_globals(runtime_data)
            
            # stdout ìº¡ì²˜ ì„¤ì •
            if self.capture_stdout:
                old_stdout = sys.stdout
                sys.stdout = stdout_capture
            
            try:
                # íƒ€ì„ì•„ì›ƒ ì ìš©í•˜ì—¬ ì‹¤í–‰
                result, printed_output = self._execute_with_timeout(code, exec_globals)
                
                execution_time_ms = (time.time() - start_time) * 1000
                
                # ê²°ê³¼ í¬ê¸° ì²´í¬
                result = self._truncate_result(result)
                
                # stdout ê²°í•© (sys.stdout ìº¡ì²˜ + RestrictedPython PrintCollector)
                stdout_output = ""
                if stdout_capture:
                    stdout_output = stdout_capture.getvalue()
                if printed_output:
                    stdout_output = (stdout_output + printed_output).strip()
                
                logger.info(f"âœ… Code executed successfully ({execution_time_ms:.1f}ms)")
                logger.debug(f"   Result type: {type(result).__name__}")
                
                return ExecutionResult(
                    success=True,
                    result=result,
                    execution_time_ms=execution_time_ms,
                    stdout=stdout_output if stdout_output else None,
                )
            
            finally:
                if self.capture_stdout:
                    sys.stdout = old_stdout
        
        except ExecutionTimeoutError:
            logger.error(f"â° Execution timed out after {self.timeout_seconds}s")
            return ExecutionResult(
                success=False,
                error=f"Execution timed out after {self.timeout_seconds} seconds",
                error_type="timeout",
                execution_time_ms=self.timeout_seconds * 1000,
            )
        
        except MemoryError:
            logger.error("ğŸ’¾ Memory limit exceeded")
            return ExecutionResult(
                success=False,
                error="Memory limit exceeded",
                error_type="memory",
            )
        
        except Exception as e:
            execution_time_ms = (time.time() - start_time) * 1000
            error_msg = f"{type(e).__name__}: {str(e)}"
            logger.error(f"âŒ Runtime error: {error_msg}")
            
            return ExecutionResult(
                success=False,
                error=error_msg,
                error_type="runtime",
                execution_time_ms=execution_time_ms,
            )
    
    def _create_exec_globals(self, runtime_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤í–‰ í™˜ê²½ì˜ globals êµ¬ì„±
        
        ì•ˆì „í•œ builtins + í—ˆìš©ëœ ëª¨ë“ˆ + ëŸ°íƒ€ì„ ë°ì´í„°
        """
        # ì•ˆì „í•œ builtins
        allowed_builtins = self._get_safe_builtins()
        
        # í—ˆìš©ëœ ëª¨ë“ˆ ë¡œë“œ
        allowed_modules = self._get_allowed_modules()
        
        exec_globals = {
            '__builtins__': allowed_builtins,
            **allowed_modules,
        }
        
        # RestrictedPython guards ì¶”ê°€
        if HAS_RESTRICTED_PYTHON:
            exec_globals['_getiter_'] = default_guarded_getiter
            exec_globals['_getitem_'] = default_guarded_getitem
            exec_globals['_getattr_'] = safer_getattr
            
            # write guard (item assignment: obj[key] = value)
            def guarded_write(obj):
                return obj
            exec_globals['_write_'] = guarded_write
            
            # ì»¤ìŠ¤í…€ unpack sequence guard - ë” ë§ì€ íƒ€ì… ì§€ì›
            exec_globals['_iter_unpack_sequence_'] = _flexible_iter_unpack_sequence
            exec_globals['_unpack_sequence_'] = lambda it, spec, _getiter_: _flexible_iter_unpack_sequence(it, spec, _getiter_)
            
            # print guard - PrintCollector ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
            exec_globals['_print_'] = PrintCollector
        
        # ëŸ°íƒ€ì„ ë°ì´í„° ì¶”ê°€ (ë®ì–´ì“°ê¸° í—ˆìš©)
        exec_globals.update(runtime_data)
        
        return exec_globals
    
    def _get_safe_builtins(self) -> Dict[str, Any]:
        """ì•ˆì „í•œ built-in í•¨ìˆ˜ë“¤"""
        if HAS_RESTRICTED_PYTHON:
            # RestrictedPythonì˜ safe_builtins ê¸°ë°˜
            builtins = dict(safe_builtins)
        else:
            # ì§ì ‘ ì •ì˜
            builtins = {}
        
        # ê³µí†µìœ¼ë¡œ í—ˆìš©í•˜ëŠ” builtins
        allowed = {
            # ìƒìˆ˜
            'True': True,
            'False': False,
            'None': None,
            
            # íƒ€ì…
            'bool': bool,
            'int': int,
            'float': float,
            'str': str,
            'list': list,
            'dict': dict,
            'tuple': tuple,
            'set': set,
            'frozenset': frozenset,
            'type': type,
            
            # ìˆ˜í•™
            'abs': abs,
            'round': round,
            'min': min,
            'max': max,
            'sum': sum,
            'pow': pow,
            'divmod': divmod,
            
            # ì´í„°ë ˆì´ì…˜
            'len': len,
            'range': range,
            'enumerate': enumerate,
            'zip': zip,
            'map': map,
            'filter': filter,
            'sorted': sorted,
            'reversed': reversed,
            'all': all,
            'any': any,
            
            # ê¸°íƒ€ ìœ í‹¸
            'isinstance': isinstance,
            'issubclass': issubclass,
            'hasattr': hasattr,
            'getattr': getattr,
            'slice': slice,
            'iter': iter,
            'next': next,
            'callable': callable,
            'repr': repr,
            'hash': hash,
            'id': id,
            
            # ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            'print': print,
        }
        
        builtins.update(allowed)
        return builtins
    
    def _get_allowed_modules(self) -> Dict[str, Any]:
        """í—ˆìš©ëœ ëª¨ë“ˆ ë¡œë“œ"""
        modules = {}
        
        # pandas
        try:
            import pandas as pd
            modules['pd'] = pd
            modules['pandas'] = pd
        except ImportError:
            pass
        
        # numpy
        try:
            import numpy as np
            modules['np'] = np
            modules['numpy'] = np
        except ImportError:
            pass
        
        # scipy.stats
        try:
            from scipy import stats
            import scipy
            modules['stats'] = stats
            modules['scipy'] = scipy
        except ImportError:
            pass
        
        # math
        import math
        modules['math'] = math
        
        # datetime
        import datetime
        modules['datetime'] = datetime
        
        # statistics (í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬)
        import statistics
        modules['statistics'] = statistics
        
        return modules
    
    def _execute_with_timeout(self, code: str, exec_globals: Dict) -> tuple:
        """íƒ€ì„ì•„ì›ƒì„ ì ìš©í•˜ì—¬ ì½”ë“œ ì‹¤í–‰
        
        Unix: signal.alarm ì‚¬ìš©
        Windows/ê¸°íƒ€: threading ì‚¬ìš© (ì™„ë²½í•˜ì§€ ì•ŠìŒ)
        
        Returns:
            tuple: (result, printed_output)
        """
        result_container = {'result': None, 'error': None, 'printed': None}
        
        def run_code():
            try:
                if HAS_RESTRICTED_PYTHON:
                    # RestrictedPython 6.x: compile_restrictedëŠ” ì§ì ‘ code ê°ì²´ ë°˜í™˜
                    # ì—ëŸ¬ ë°œìƒ ì‹œ SyntaxError ì˜ˆì™¸ ë°œìƒ
                    byte_code = compile_restricted(code, '<generated>', 'exec')
                    exec(byte_code, exec_globals)
                else:
                    exec(code, exec_globals)
                
                result_container['result'] = exec_globals.get('result')
                
                # RestrictedPython PrintCollector ì¶œë ¥ ìˆ˜ì§‘
                if '_print_' in exec_globals and 'printed' in exec_globals:
                    result_container['printed'] = exec_globals.get('printed', '')
            except Exception as e:
                result_container['error'] = e
        
        # Unixì—ì„œëŠ” signal.alarmì´ ë” ì •í™•í•˜ì§€ë§Œ,
        # í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„±ì„ ìœ„í•´ threading ì‚¬ìš©
        thread = threading.Thread(target=run_code)
        thread.start()
        thread.join(timeout=self.timeout_seconds)
        
        if thread.is_alive():
            # íƒ€ì„ì•„ì›ƒ - ìŠ¤ë ˆë“œê°€ ì•„ì§ ì‹¤í–‰ ì¤‘
            # ì°¸ê³ : Pythonì—ì„œëŠ” ìŠ¤ë ˆë“œë¥¼ ê°•ì œ ì¢…ë£Œí•  ìˆ˜ ì—†ìŒ
            # ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë³„ë„ í”„ë¡œì„¸ìŠ¤ ì‚¬ìš© ê¶Œì¥
            raise ExecutionTimeoutError()
        
        if result_container['error']:
            raise result_container['error']
        
        return result_container['result'], result_container['printed']
    
    def _truncate_result(self, result: Any) -> Any:
        """ê²°ê³¼ í¬ê¸° ì œí•œ
        
        ë„ˆë¬´ í° ê²°ê³¼ëŠ” ì˜ë¼ì„œ ë°˜í™˜
        """
        if result is None:
            return None
        
        # DataFrameì¸ ê²½ìš° í¬ê¸° ì²´í¬
        try:
            import pandas as pd
            if isinstance(result, pd.DataFrame):
                if len(result) > 10000:
                    # ë„ˆë¬´ í° DataFrameì€ ìš”ì•½ ì •ë³´ë§Œ ë°˜í™˜
                    return {
                        '_type': 'DataFrame',
                        '_truncated': True,
                        'shape': result.shape,
                        'columns': list(result.columns),
                        'head': result.head(10).to_dict(),
                        'tail': result.tail(10).to_dict(),
                    }
        except ImportError:
            pass
        
        # ë¬¸ìì—´ì¸ ê²½ìš° ê¸¸ì´ ì œí•œ
        if isinstance(result, str):
            if len(result) > self.max_output_size:
                return result[:self.max_output_size] + f"... (truncated, total {len(result)} chars)"
        
        # ë¦¬ìŠ¤íŠ¸/ë°°ì—´ì¸ ê²½ìš° ê¸¸ì´ ì œí•œ
        if isinstance(result, (list, tuple)):
            if len(result) > 1000:
                return {
                    '_type': type(result).__name__,
                    '_truncated': True,
                    'length': len(result),
                    'first_10': list(result[:10]),
                    'last_10': list(result[-10:]),
                }
        
        return result
    
    # =========================================================================
    # Map-Reduce íŒ¨í„´ ì‹¤í–‰ ë©”ì„œë“œ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬)
    # =========================================================================
    
    def execute_map(
        self,
        map_code: str,
        entity_id: str,
        entity_data: "pd.DataFrame",
        metadata_row: "pd.Series",
    ) -> Tuple[bool, Any, Optional[str]]:
        """map_func ì‹¤í–‰ (ë‹¨ì¼ ì—”í‹°í‹° ì²˜ë¦¬)
        
        map_funcë¥¼ ì •ì˜í•˜ê³  í˜¸ì¶œí•˜ì—¬ ì¤‘ê°„ ê²°ê³¼ ë°˜í™˜.
        
        Args:
            map_code: map_func ì •ì˜ ì½”ë“œ
            entity_id: ì—”í‹°í‹° ì‹ë³„ì
            entity_data: ì—”í‹°í‹° ë°ì´í„° DataFrame
            metadata_row: ì—”í‹°í‹° ë©”íƒ€ë°ì´í„° Series
        
        Returns:
            (success, result, error_message) íŠœí”Œ
            - success: ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€
            - result: map_func ë°˜í™˜ê°’ (ì‹¤íŒ¨ ì‹œ None)
            - error_message: ì—ëŸ¬ ë©”ì‹œì§€ (ì„±ê³µ ì‹œ None)
        
        Example:
            success, result, error = executor.execute_map(
                map_code="def map_func(entity_id, entity_data, metadata_row):\\n    return entity_data['HR'].mean()",
                entity_id="patient_001",
                entity_data=signal_df,
                metadata_row=patient_info,
            )
        """
        import pandas as pd
        
        # map_func ì •ì˜ + í˜¸ì¶œ ì½”ë“œ ì¡°í•©
        exec_code = f"""
{map_code}

# Call map_func with provided arguments
_map_result = map_func(entity_id, entity_data, metadata_row)
result = _map_result
"""
        
        # ëŸ°íƒ€ì„ ë°ì´í„° ì¤€ë¹„
        runtime_data = {
            "entity_id": entity_id,
            "entity_data": entity_data if entity_data is not None else pd.DataFrame(),
            "metadata_row": metadata_row if metadata_row is not None else pd.Series(),
        }
        
        # ì‹¤í–‰
        exec_result = self.execute(exec_code, runtime_data)
        
        if exec_result.success:
            return True, exec_result.result, None
        else:
            return False, None, exec_result.error
    
    def execute_reduce(
        self,
        reduce_code: str,
        intermediate_results: List[Any],
        full_metadata: "pd.DataFrame",
    ) -> Tuple[bool, Any, Optional[str]]:
        """reduce_func ì‹¤í–‰ (ì¤‘ê°„ ê²°ê³¼ ì§‘ê³„)
        
        reduce_funcë¥¼ ì •ì˜í•˜ê³  í˜¸ì¶œí•˜ì—¬ ìµœì¢… ê²°ê³¼ ë°˜í™˜.
        
        Args:
            reduce_code: reduce_func ì •ì˜ ì½”ë“œ
            intermediate_results: map_func ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (None ê°’ ì œì™¸ë¨)
            full_metadata: ì „ì²´ ë©”íƒ€ë°ì´í„° DataFrame
        
        Returns:
            (success, result, error_message) íŠœí”Œ
            - success: ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€
            - result: reduce_func ë°˜í™˜ê°’ (ì‹¤íŒ¨ ì‹œ None)
            - error_message: ì—ëŸ¬ ë©”ì‹œì§€ (ì„±ê³µ ì‹œ None)
        
        Example:
            success, final_result, error = executor.execute_reduce(
                reduce_code="def reduce_func(intermediate_results, full_metadata):\\n    return sum(intermediate_results) / len(intermediate_results)",
                intermediate_results=[72.5, 68.3, 75.1, ...],
                full_metadata=cohort_df,
            )
        """
        import pandas as pd
        
        # None ê°’ í•„í„°ë§
        filtered_results = [r for r in intermediate_results if r is not None]
        
        # reduce_func ì •ì˜ + í˜¸ì¶œ ì½”ë“œ ì¡°í•©
        exec_code = f"""
{reduce_code}

# Call reduce_func with provided arguments
_reduce_result = reduce_func(intermediate_results, full_metadata)
result = _reduce_result
"""
        
        # ëŸ°íƒ€ì„ ë°ì´í„° ì¤€ë¹„
        runtime_data = {
            "intermediate_results": filtered_results,
            "full_metadata": full_metadata if full_metadata is not None else pd.DataFrame(),
        }
        
        # ì‹¤í–‰
        exec_result = self.execute(exec_code, runtime_data)
        
        if exec_result.success:
            return True, exec_result.result, None
        else:
            return False, None, exec_result.error
    
    def execute_mapreduce_batch(
        self,
        map_code: str,
        reduce_code: str,
        batch_data: List[Dict[str, Any]],
        full_metadata: "pd.DataFrame",
        parallel: bool = True,
        max_workers: int = 4,
    ) -> Tuple[List[Any], List[Dict[str, str]], float]:
        """ë°°ì¹˜ ë‹¨ìœ„ Map-Reduce ì‹¤í–‰
        
        ë°°ì¹˜ ë‚´ ëª¨ë“  ì—”í‹°í‹°ì— ëŒ€í•´ map_func ì‹¤í–‰ í›„ ê²°ê³¼ ë°˜í™˜.
        reduce_funcëŠ” í˜¸ì¶œí•˜ì§€ ì•ŠìŒ (Orchestratorì—ì„œ ìµœì¢… ì§‘ê³„).
        
        Args:
            map_code: map_func ì •ì˜ ì½”ë“œ
            reduce_code: reduce_func ì •ì˜ ì½”ë“œ (í˜„ì¬ ë¯¸ì‚¬ìš©)
            batch_data: ë°°ì¹˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
                [{"entity_id": str, "entity_data": DataFrame, "metadata_row": Series}, ...]
            full_metadata: ì „ì²´ ë©”íƒ€ë°ì´í„° DataFrame
            parallel: ë³‘ë ¬ ì²˜ë¦¬ ì—¬ë¶€
            max_workers: ë³‘ë ¬ ì›Œì»¤ ìˆ˜
        
        Returns:
            (results, errors, elapsed_ms) íŠœí”Œ
            - results: map_func ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (None í¬í•¨ ê°€ëŠ¥)
            - errors: ì—ëŸ¬ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{"entity_id": str, "error": str}, ...]
            - elapsed_ms: ì‹¤í–‰ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
        
        Example:
            batch = [
                {"entity_id": "p1", "entity_data": df1, "metadata_row": m1},
                {"entity_id": "p2", "entity_data": df2, "metadata_row": m2},
            ]
            results, errors, elapsed = executor.execute_mapreduce_batch(
                map_code, reduce_code, batch, cohort_df
            )
        """
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        start_time = time.time()
        results = []
        errors = []
        
        if parallel and len(batch_data) > 1:
            # ë³‘ë ¬ ì‹¤í–‰
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = {}
                
                for item in batch_data:
                    future = executor.submit(
                        self.execute_map,
                        map_code,
                        item["entity_id"],
                        item["entity_data"],
                        item["metadata_row"],
                    )
                    futures[future] = item["entity_id"]
                
                for future in as_completed(futures):
                    entity_id = futures[future]
                    try:
                        success, result, error = future.result()
                        if success:
                            results.append(result)
                        else:
                            results.append(None)
                            errors.append({"entity_id": entity_id, "error": error})
                    except Exception as e:
                        results.append(None)
                        errors.append({"entity_id": entity_id, "error": str(e)})
        else:
            # ìˆœì°¨ ì‹¤í–‰
            for item in batch_data:
                success, result, error = self.execute_map(
                    map_code,
                    item["entity_id"],
                    item["entity_data"],
                    item["metadata_row"],
                )
                if success:
                    results.append(result)
                else:
                    results.append(None)
                    errors.append({"entity_id": item["entity_id"], "error": error})
        
        elapsed_ms = (time.time() - start_time) * 1000
        
        return results, errors, elapsed_ms

