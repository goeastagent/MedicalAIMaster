#!/usr/bin/env python3
"""
DataContext í†µí•© í…ŒìŠ¤íŠ¸
========================

í…ŒìŠ¤íŠ¸ í•­ëª©:
1. Processor import í™•ì¸
2. DataContext ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
3. ExtractionAgent â†’ DataContext ì—°ë™ í…ŒìŠ¤íŠ¸
4. ìºì‹œ ë™ì‘ í™•ì¸

Usage:
    cd /path/to/MedicalAIMaster
    python shared/test_datacontext.py
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

print("=" * 70)
print("  DataContext í†µí•© í…ŒìŠ¤íŠ¸")
print("=" * 70)


# =============================================================================
# Test 1: Processor Import (ì§ì ‘ import)
# =============================================================================
def test_processor_import():
    """shared.processorsì—ì„œ ì§ì ‘ import í…ŒìŠ¤íŠ¸"""
    print("\n[Test 1] Processor Import")
    print("-" * 50)
    
    try:
        # ì§ì ‘ processorsë§Œ import (shared ì „ì²´ ì•„ë‹˜)
        from shared.processors import SignalProcessor, TabularProcessor, BaseDataProcessor
        
        print("  âœ… SignalProcessor import ì„±ê³µ")
        print("  âœ… TabularProcessor import ì„±ê³µ")
        print("  âœ… BaseDataProcessor import ì„±ê³µ")
        
        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        sig_proc = SignalProcessor()
        tab_proc = TabularProcessor()
        
        print(f"\n  ğŸ“Š SignalProcessor:")
        print(f"     - SUPPORTED_EXTENSIONS: {sig_proc.SUPPORTED_EXTENSIONS}")
        print(f"     - has can_handle: {hasattr(sig_proc, 'can_handle')}")
        print(f"     - has extract_metadata: {hasattr(sig_proc, 'extract_metadata')}")
        print(f"     - has load_data: {hasattr(sig_proc, 'load_data')}")
        
        print(f"\n  ğŸ“Š TabularProcessor:")
        print(f"     - SUPPORTED_EXTENSIONS: {tab_proc.SUPPORTED_EXTENSIONS}")
        print(f"     - has can_handle: {hasattr(tab_proc, 'can_handle')}")
        print(f"     - has extract_metadata: {hasattr(tab_proc, 'extract_metadata')}")
        print(f"     - has load_data: {hasattr(tab_proc, 'load_data')}")
        
        return True
    except Exception as e:
        print(f"  âŒ Import ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


# =============================================================================
# Test 2: DataContext ê¸°ë³¸ ê¸°ëŠ¥
# =============================================================================
def test_datacontext_basic():
    """DataContext í´ë˜ìŠ¤ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n[Test 2] DataContext ê¸°ë³¸ ê¸°ëŠ¥")
    print("-" * 50)
    
    try:
        # ì§ì ‘ contextë§Œ import
        from shared.data.context import DataContext
        
        print("  âœ… DataContext import ì„±ê³µ")
        
        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        ctx = DataContext()
        print("  âœ… DataContext ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # ë©”ì„œë“œ ì¡´ì¬ í™•ì¸
        methods = [
            'load_from_plan',
            'get_cohort',
            'get_signals',
            'get_merged_data',
            'iter_cases',
            'get_case_ids',
            'get_available_parameters',
            'summary',
            'clear_cache',
            'get_analysis_context',
            'compute_statistics',
            'get_sample_data',
            'get_parameter_info'
        ]
        
        missing = []
        for method in methods:
            if hasattr(ctx, method):
                print(f"     âœ… {method}()")
            else:
                print(f"     âŒ {method}() - ì—†ìŒ")
                missing.append(method)
        
        if missing:
            print(f"  âš ï¸ ëˆ„ë½ëœ ë©”ì„œë“œ: {missing}")
            return False
        
        # is_loaded í™•ì¸
        print(f"\n  ğŸ“Š is_loaded(): {ctx.is_loaded()}")
        
        return True
    except Exception as e:
        print(f"  âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


# =============================================================================
# Test 3: ExtractionAgent â†’ DataContext ì—°ë™ (Plan íŒŒì‹±ë§Œ)
# =============================================================================
def test_extraction_to_datacontext():
    """ExtractionAgentì˜ execution_planìœ¼ë¡œ DataContext ë¡œë“œ í…ŒìŠ¤íŠ¸ (DB ì—†ì´)"""
    print("\n[Test 3] ExtractionAgent â†’ DataContext ì—°ë™ (Plan íŒŒì‹±)")
    print("-" * 50)
    
    try:
        from shared.data.context import DataContext
        
        # ìƒ˜í”Œ execution_plan (ExtractionAgent ì¶œë ¥ í˜•ì‹)
        sample_plan = {
            "version": "1.0",
            "generated_at": "2024-01-01T00:00:00Z",
            "agent": "VitalExtractionAgent",
            "original_query": "ìœ„ì•” í™˜ìì˜ ìˆ˜ìˆ  ì¤‘ ì‹¬ë°•ìˆ˜ ë°ì´í„°",
            "execution_plan": {
                "cohort_source": {
                    "file_id": "test-file-id-123",
                    "file_name": "clinical_data.csv",
                    "entity_identifier": "caseid",
                    "filters": [
                        {"column": "diagnosis", "operator": "LIKE", "value": "%gastric%"}
                    ]
                },
                "signal_source": {
                    "group_id": "test-group-id-456",
                    "group_name": "vital_files",
                    "parameters": [
                        {
                            "term": "ì‹¬ë°•ìˆ˜",
                            "param_keys": ["Solar8000/HR"],
                            "semantic_name": "Heart Rate",
                            "unit": "bpm",
                            "resolution_mode": "all_sources",
                            "confidence": 0.95
                        },
                        {
                            "term": "í˜ˆì••",
                            "param_keys": ["Solar8000/NIBP_SBP", "Solar8000/NIBP_DBP"],
                            "semantic_name": "Blood Pressure",
                            "unit": "mmHg",
                            "resolution_mode": "all_sources",
                            "confidence": 0.90
                        }
                    ],
                    "temporal_alignment": {
                        "type": "surgery_window",
                        "start_column": "op_start",
                        "end_column": "op_end",
                        "margin_seconds": 300
                    }
                },
                "join_specification": {
                    "type": "inner",
                    "cohort_key": "caseid",
                    "signal_key": "caseid"
                }
            }
        }
        
        ctx = DataContext()
        
        # Plan ë¡œë“œ (DB ì ‘ê·¼ ì—†ì´ íŒŒì‹±ë§Œ - preload_cohort=False)
        # DB ì—°ê²° ì—†ì´ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ _dbë¥¼ Noneìœ¼ë¡œ ìœ ì§€
        ctx._plan = sample_plan
        plan = sample_plan.get("execution_plan", {})
        
        # Cohort source íŒŒì‹±
        cohort_source = plan.get("cohort_source", {})
        ctx._cohort_file_id = cohort_source.get("file_id")
        ctx._cohort_entity_id = cohort_source.get("entity_identifier", "caseid")
        ctx._cohort_filters = cohort_source.get("filters", [])
        
        # Signal source íŒŒì‹±
        signal_source = plan.get("signal_source", {})
        ctx._signal_group_id = signal_source.get("group_id")
        ctx._temporal_config = signal_source.get("temporal_alignment", {})
        
        parameters = signal_source.get("parameters", [])
        ctx._param_info = parameters
        ctx._param_keys = []
        for p in parameters:
            ctx._param_keys.extend(p.get("param_keys", []))
        
        # Join ì„¤ì •
        join_spec = plan.get("join_specification", {})
        ctx._join_config = {
            "cohort_key": join_spec.get("cohort_key", ctx._cohort_entity_id),
            "signal_key": join_spec.get("signal_key", ctx._cohort_entity_id),
            "type": join_spec.get("type", "inner")
        }
        
        print("  âœ… Plan íŒŒì‹± ì„±ê³µ")
        
        # íŒŒì‹± ê²°ê³¼ í™•ì¸
        print(f"\n  ğŸ“‹ íŒŒì‹±ëœ Plan ì •ë³´:")
        print(f"     - cohort_file_id: {ctx._cohort_file_id}")
        print(f"     - cohort_entity_id: {ctx._cohort_entity_id}")
        print(f"     - cohort_filters: {len(ctx._cohort_filters)}ê°œ")
        print(f"     - signal_group_id: {ctx._signal_group_id}")
        print(f"     - param_keys: {ctx._param_keys}")
        print(f"     - temporal_type: {ctx._temporal_config.get('type')}")
        print(f"     - join_config: {ctx._join_config}")
        
        # get_analysis_context í…ŒìŠ¤íŠ¸
        analysis_ctx = ctx.get_analysis_context()
        print(f"\n  ğŸ“Š get_analysis_context() ê²°ê³¼:")
        print(f"     - description: {analysis_ctx['description'][:60]}...")
        print(f"     - original_query: {analysis_ctx['original_query']}")
        print(f"     - cohort.filters_applied: {len(analysis_ctx['cohort']['filters_applied'])}ê°œ")
        print(f"     - signals.param_keys: {analysis_ctx['signals']['param_keys']}")
        print(f"     - signals.temporal_setting.type: {analysis_ctx['signals']['temporal_setting']['type']}")
        
        # get_parameter_info í…ŒìŠ¤íŠ¸
        param_info = ctx.get_parameter_info("Solar8000/HR")
        if param_info:
            print(f"\n  ğŸ“Š get_parameter_info('Solar8000/HR'):")
            print(f"     - term: {param_info['term']}")
            print(f"     - semantic_name: {param_info['semantic_name']}")
            print(f"     - unit: {param_info['unit']}")
        
        return True
    except Exception as e:
        print(f"  âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


# =============================================================================
# Test 4: ìºì‹œ ë™ì‘ í™•ì¸
# =============================================================================
def test_cache_behavior():
    """ìºì‹œ ë™ì‘ í™•ì¸"""
    print("\n[Test 4] ìºì‹œ ë™ì‘ í™•ì¸")
    print("-" * 50)
    
    try:
        from shared.data.context import DataContext
        
        # ìºì‹œ ì´ˆê¸°í™”
        DataContext.clear_cache()
        print("  âœ… clear_cache() í˜¸ì¶œ ì„±ê³µ")
        
        # ìºì‹œ ìƒíƒœ í™•ì¸
        print(f"  ğŸ“Š ìºì‹œ ìƒíƒœ:")
        print(f"     - _signal_cache í¬ê¸°: {len(DataContext._signal_cache)}")
        print(f"     - _cohort_cache í¬ê¸°: {len(DataContext._cohort_cache)}")
        
        # ë‘ ê°œì˜ DataContext ì¸ìŠ¤í„´ìŠ¤ê°€ ê°™ì€ ìºì‹œë¥¼ ê³µìœ í•˜ëŠ”ì§€ í™•ì¸
        ctx1 = DataContext()
        ctx2 = DataContext()
        
        # ìºì‹œì— í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€ (ctx1 í†µí•´)
        import pandas as pd
        test_df = pd.DataFrame({"test": [1, 2, 3]})
        DataContext._signal_cache["test_case"] = test_df
        
        # ctx2ì—ì„œ í™•ì¸
        if "test_case" in DataContext._signal_cache:
            print("  âœ… ìºì‹œ ê³µìœ  í™•ì¸: ctx1ê³¼ ctx2ê°€ ê°™ì€ ìºì‹œ ì‚¬ìš©")
        else:
            print("  âŒ ìºì‹œ ê³µìœ  ì‹¤íŒ¨")
            return False
        
        # ì •ë¦¬
        DataContext.clear_cache()
        
        if len(DataContext._signal_cache) == 0:
            print("  âœ… clear_cache() í›„ ìºì‹œ ë¹„ì›Œì§ í™•ì¸")
        
        # ë¶€ë¶„ ìºì‹œ í´ë¦¬ì–´ í…ŒìŠ¤íŠ¸
        DataContext._signal_cache["test1"] = test_df
        DataContext._cohort_cache["test2"] = test_df
        
        DataContext.clear_cache("signals")
        if len(DataContext._signal_cache) == 0 and len(DataContext._cohort_cache) == 1:
            print("  âœ… clear_cache('signals') ë¶€ë¶„ í´ë¦¬ì–´ ë™ì‘ í™•ì¸")
        
        DataContext.clear_cache("all")
        
        return True
    except Exception as e:
        print(f"  âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


# =============================================================================
# Test 5: Processor load_data ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
# =============================================================================
def test_processor_load_data():
    """Processorì˜ load_data ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸"""
    print("\n[Test 5] Processor load_data ë©”ì„œë“œ í™•ì¸")
    print("-" * 50)
    
    try:
        from shared.processors import SignalProcessor, TabularProcessor
        import inspect
        
        # SignalProcessor
        sig_proc = SignalProcessor()
        sig_params = inspect.signature(sig_proc.load_data).parameters
        print(f"  ğŸ“Š SignalProcessor.load_data() íŒŒë¼ë¯¸í„°:")
        for name, param in sig_params.items():
            default = param.default if param.default != inspect.Parameter.empty else "required"
            print(f"     - {name}: {default}")
        
        # TabularProcessor
        tab_proc = TabularProcessor()
        tab_params = inspect.signature(tab_proc.load_data).parameters
        print(f"\n  ğŸ“Š TabularProcessor.load_data() íŒŒë¼ë¯¸í„°:")
        for name, param in tab_params.items():
            default = param.default if param.default != inspect.Parameter.empty else "required"
            print(f"     - {name}: {default}")
        
        return True
    except Exception as e:
        print(f"  âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


# =============================================================================
# Main
# =============================================================================
def main():
    results = {}
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results["test1_processor_import"] = test_processor_import()
    results["test2_datacontext_basic"] = test_datacontext_basic()
    results["test3_extraction_to_dc"] = test_extraction_to_datacontext()
    results["test4_cache"] = test_cache_behavior()
    results["test5_processor_load"] = test_processor_load_data()
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {status} - {name}")
    
    print(f"\n  ì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")
    print("=" * 70)
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
